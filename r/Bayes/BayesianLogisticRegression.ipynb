{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression with rstanarm \n",
    "\n",
    "Preprocessing of Pima Indian dataset is from a [noteebok][4] by [Lao Zhang][5]\n",
    "\n",
    "The introduction to Bayesian logistic regression and **rstanarm** is from a \n",
    "[CRAN vignette][1] by Jonah Gabry and Ben Goodrich.\n",
    "\n",
    "[CRAN vignette][1] was ported by [Aki Vehtari][2]. *Instead of wells data in CRAN vignette, Pima Indians data is used.* The end of this notebook differs significantly from the CRAN vignette.\n",
    "\n",
    "You can read more about how to use **rstanarm** in [several vignettes at CRAN][3].\n",
    "\n",
    "  [1]: https://cran.r-project.org/web/packages/rstanarm/vignettes/binomial.html\n",
    "  [2]: https://users.aalto.fi/~ave/\n",
    "  [3]: https://cran.r-project.org/web/packages/rstanarm/\n",
    "  [4]: https://www.kaggle.com/laozhang/d/uciml/pima-indians-diabetes-database/statistical-learning-with-r/run/445129\n",
    "  [5]: https://www.kaggle.com/laozhang\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This vignette explains how to estimate generalized linear models (GLMs) for \n",
    "binary (Bernoulli) and Binomial response variables using the `stan_glm`\n",
    "function in the __rstanarm__ package.\n",
    "\n",
    "The four steps of a Bayesian analysis are\n",
    "\n",
    "1. Specify a joint distribution for the outcome(s) and all the unknowns, which\n",
    "  typically takes the form of a marginal prior distribution for the unknowns\n",
    "  multiplied by a likelihood for the outcome(s) conditional on the unknowns.\n",
    "  This joint distribution is proportional to a posterior distribution of the\n",
    "  unknowns conditional on the observed data.\n",
    "2. Draw from posterior distribution using Markov Chain Monte Carlo (MCMC).\n",
    "3. Evaluate how well the model fits the data and possibly revise the model.\n",
    "4. Draw from the posterior predictive distribution of the outcome(s) given\n",
    "  interesting values of the predictors in order to visualize how a manipulation\n",
    "  of a predictor affects (a function of) the outcome(s).\n",
    "\n",
    "Steps 3 and 4 are covered in more depth by the vignette entitled [\"How to Use the\n",
    "__rstanarm__ Package\"](https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html). This vignette focuses on Step 1 when the likelihood is\n",
    "the product of conditionally independent binomial distributions (possibly with\n",
    "only one trial per observation).\n",
    "\n",
    "[Other vignettes are also available](https://cran.r-project.org/web/packages/rstanarm/vignettes/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "## Likelihood\n",
    "\n",
    "For a binomial GLM the likelihood for one observation $y$ can be written as a conditionally binomial PMF\n",
    "\n",
    "$$\\binom{n}{y} \\pi^{y} (1 - \\pi)^{n - y}$$\n",
    "\n",
    "where:\n",
    "* $n$ is the known number of trials.\n",
    "* $\\pi = g^{-1}(\\eta)$ is the probability of success.\n",
    "* $\\eta = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}$ is a linear predictor that is used to calculate the probability of success.\n",
    "\n",
    "For a sample of size $N$, the likelihood of the entire sample is the product of $N$ individual likelihood contributions, which can be stated as:\n",
    "\n",
    "$$\n",
    "  \\prod_{i=1}^N {\n",
    "  g^{-1}\\left(\\eta_i\\right)^{y_i} \n",
    "  \\left(1 - g^{-1}\\left(\\eta_i\\right)\\right)^{n_i-y_i}}$$\n",
    "  \n",
    "Or the fully expanded form including the linear predictor: \n",
    "  \n",
    "\n",
    "$$\n",
    "  \\prod_{i=1}^N {\n",
    "  g^{-1}\\left((\\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta})_i\\right)^{y_i} \n",
    "  \\left(1 - g^{-1}\\left((\\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta})_i\\right)\\right)^{n_i-y_i}}$$\n",
    "  \n",
    "One could read this as:\n",
    "\"The total likelihood for a general binomial model is the product of the probability of success and failures for for every observation in a sample size $N$. \"\n",
    "\n",
    "Because $\\pi$ is a probability, for a binomial model the _link_ function $g$ maps between the unit interval (`0,1` as necessitated to support probability $\\pi$) and the set of all real numbers $\\mathbb{R}$. When applied to a linear predictor $\\eta$ with values in $\\mathbb{R}$, the inverse link function $g^{-1}(\\eta)$ therefore returns a valid probability between 0 and 1 (Using real values $\\mathbb{R}$, map *back* to a unit interval for $\\eta$). \n",
    "\n",
    "These link functions are therefore how we describe these probability distributions, and are necessary to the success of this formula. The two most common link functions used for binomial GLMs are the [logit](https://en.wikipedia.org/wiki/Logit) and [probit](https://en.wikipedia.org/wiki/Probit) functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit:\n",
    "The logit function is the inverse of the sigmoidal \"logistic\" function, and maps real values ($\\mathbb{R}$) to an activation range between 0 and 1. We could use any base, but the natural logarithm $e$ is typically used:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Logit.svg/350px-Logit.svg.png)\n",
    "\n",
    "With the logit (or log-odds) link function $g(x) = \\ln{\\left(\\frac{x}{1-x}\\right)}$, the likelihood for a single observation in our model now becomes:\n",
    "\n",
    "$$\\binom{n}{y}\\left(\\text{logit}^{-1}(\\eta)\\right)^y \n",
    "\\left(1 - \\text{logit}^{-1}(\\eta)\\right)^{n-y} = \n",
    "\\binom{n}{y} \\left(\\frac{e^{\\eta}}{1 + e^{\\eta}}\\right)^{y}\n",
    "\\left(\\frac{1}{1 + e^{\\eta}}\\right)^{n - y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probit: \n",
    "The probit function is the quantile function associated with the standard normal distribution, which is commonly denoted as N(0,1). \n",
    "\n",
    "One could think of it like a function to map via the 'z-table' method; a means to convert a real value into an probability on a standard normal curve using the inverse of the cumulative distribution function of a standard normal distribution\"\n",
    "\n",
    "\n",
    "$$\\Phi^{-1} (X = 1.96)=0.025$$\n",
    "$$\\Phi^{-1} (X = 1.96)=0.975$$\n",
    "\n",
    "Mathematically, it is the inverse of the cumulative distribution function of the standard normal distribution, which is denoted as $\\Phi (z)$, so the probit is denoted as ${\\Phi ^{-1}(p)}$: \n",
    "\n",
    "When we use the probit as the link function $g(x) = \\Phi^{-1}(x)$, we yield the new likelihood likelihood:\n",
    "\n",
    "$$\\binom{n}{y} \\left(\\Phi(\\eta)\\right)^{y}\n",
    "\\left(1 - \\Phi(\\eta)\\right)^{n - y},$$\n",
    "\n",
    "where $\\Phi$ is the CDF of the standard normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference\n",
    "\n",
    "The differences between the logit and probit functions are minor and -- if, as __rstanarm__ does by default, the probit is scaled so its slope at the origin matches the logit's -- the two link functions should yield similar results. (This is also intuitive, since the sigmoidal logistic function is the typical shape of a CDF, which is what the probit inverts to calculate) \n",
    "\n",
    "With `stan_glm`, binomial models with a logit link function can typically be fit **slightly faster** than the identical model with a probit link because of how the two models are  implemented in Stan. Unless the user has a *specific reason* to prefer the probit link, **we recommend the logit simply because it will be slightly faster and more numerically stable**.\n",
    "\n",
    "In theory, there are infinitely many possible link functions, although in practice only a few are typically used. \n",
    "\n",
    "Other common choices are the:\n",
    "* `cauchit` link function: Uses the cauchy distribution. \n",
    "* `cloglog` link function: The complementary log-log model. \n",
    "\n",
    "And others [explored here](http://www.stats.uwo.ca/faculty/bellhouse/Links.pdf), which can also be used with `stan_glm` (every link  function compatible with`glm` will work with `stan_glm`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian General Linear Model\n",
    "\n",
    "A full Bayesian analysis using the General Linear Model (GLM): $\\eta = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}$ requires us to specify the prior distributions $f(\\alpha)$ and $f(\\boldsymbol{\\beta})$  for the intercept and vector of regression coefficients.\n",
    "\n",
    "These can generally be thought of as the 'distributions' of these variables, which we will use to inform the posterior.  \n",
    "\n",
    "When using `stan_glm`, these distributions can be set using the `prior_intercept` and `prior` arguments. The `stan_glm` function supports a variety of prior distributions, which are explained in the __rstanarm__\n",
    "documentation (`help(priors, package = 'rstanarm')`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for priors {rstanarm}\"><tr><td>priors {rstanarm}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Prior distributions and options</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>The functions described on this page are used to specify the prior-related\n",
       "arguments of the various modeling functions in the <span class=\"pkg\">rstanarm</span> package (to\n",
       "view the priors used for an existing model see <code>prior_summary</code>). \n",
       "The default priors used in the various <span class=\"pkg\">rstanarm</span> modeling functions are\n",
       "intended to be <em>weakly informative</em> in that they provide moderate\n",
       "regularlization and help stabilize computation. For many applications the\n",
       "defaults will perform well, but prudent use of more informative priors is\n",
       "encouraged. Uniform prior distributions are possible (e.g. by setting\n",
       "<code>stan_glm</code>'s <code>prior</code> argument to <code>NULL</code>) but, unless\n",
       "the data is very strong, they are not recommended and are <em>not</em>\n",
       "non-informative, giving the same probability mass to implausible values as\n",
       "plausible ones.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "normal(location = 0, scale = NULL)\n",
       "\n",
       "student_t(df = 1, location = 0, scale = NULL)\n",
       "\n",
       "cauchy(location = 0, scale = NULL)\n",
       "\n",
       "hs(df = 3)\n",
       "\n",
       "hs_plus(df1 = 3, df2 = 3)\n",
       "\n",
       "decov(regularization = 1, concentration = 1, shape = 1, scale = 1)\n",
       "\n",
       "dirichlet(concentration = 1)\n",
       "\n",
       "R2(location = NULL, what = c(\"mode\", \"mean\", \"median\", \"log\"))\n",
       "\n",
       "prior_options(prior_scale_for_dispersion = 5, min_prior_scale = 1e-12,\n",
       "  scaled = TRUE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>location</code></td>\n",
       "<td>\n",
       "<p>Prior location. For <code>normal</code> and <code>student_t</code> \n",
       "(provided that <code>df &gt; 1</code>) this is the prior mean. For <code>cauchy</code> \n",
       "(which is equivalent to <code>student_t</code> with <code>df=1</code>), the mean does \n",
       "not exist and <code>location</code> is the prior median. The default value is \n",
       "<i>0</i>, except for <code>R2</code> which has no default value for\n",
       "<code>location</code>. For <code>R2</code>, <code>location</code> pertains to the prior\n",
       "location of the <i>R^2</i> under a Beta distribution, but the interpretation\n",
       "of the <code>location</code> parameter depends on the specified value of the\n",
       "<code>what</code> argument (see the &quot;R2 family&quot; section in Details).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>scale</code></td>\n",
       "<td>\n",
       "<p>Prior scale. The default depends on the family (see Details).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>df, df1, df2</code></td>\n",
       "<td>\n",
       "<p>Prior degrees of freedom. The default is <i>1</i> for \n",
       "<code>student_t</code>, in which case it is equivalent to <code>cauchy</code>. For the\n",
       "hierarchical shrinkage priors (<code>hs</code> and <code>hs_plus</code>) the degrees of\n",
       "freedom parameter(s) default to <i>3</i>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>regularization</code></td>\n",
       "<td>\n",
       "<p>Exponent for an LKJ prior on the correlation matrix in\n",
       "the <code>decov</code> prior. The default is <i>1</i>, implying a joint uniform\n",
       "prior.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>concentration</code></td>\n",
       "<td>\n",
       "<p>Concentration parameter for a symmetric Dirichlet \n",
       "distribution. The default is <i>1</i>, implying a joint uniform prior.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>shape</code></td>\n",
       "<td>\n",
       "<p>Shape parameter for a gamma prior on the scale parameter in the\n",
       "<code>decov</code> prior. If <code>shape</code> and <code>scale</code> are both <i>1</i> (the\n",
       "default) then the gamma prior simplifies to the unit-exponential\n",
       "distribution.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>what</code></td>\n",
       "<td>\n",
       "<p>A character string among <code>'mode'</code> (the default),\n",
       "<code>'mean'</code>, <code>'median'</code>, or <code>'log'</code> indicating how the\n",
       "<code>location</code> parameter is interpreted in the <code>LKJ</code> case. If\n",
       "<code>'log'</code>, then <code>location</code> is interpreted as the expected\n",
       "logarithm of the <i>R^2</i> under a Beta distribution. Otherwise,\n",
       "<code>location</code> is interpreted as the <code>what</code> of the <i>R^2</i>\n",
       "under a Beta distribution. If the number of predictors is less than\n",
       "or equal to two, the mode of this Beta distribution does not exist\n",
       "and an error will prompt the user to specify another choice for\n",
       "<code>what</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior_scale_for_dispersion</code></td>\n",
       "<td>\n",
       "<p>Prior scale for the standard error of the \n",
       "regression in Gaussian models, which is given a half-Cauchy prior truncated\n",
       "at zero.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>min_prior_scale</code></td>\n",
       "<td>\n",
       "<p>Minimum prior scale for the intercept and \n",
       "coefficients.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>scaled</code></td>\n",
       "<td>\n",
       "<p>A logical scalar, defaulting to <code>TRUE</code>. If <code>TRUE</code> \n",
       "then the scales of the priors on the regression coefficients may be \n",
       "additionally modified internally by <span class=\"pkg\">rstanarm</span> as follows. First, if\n",
       "<em>response</em> is Gaussian, the prior scales also multiplied by \n",
       "<code>2*sd(y)</code>. Additionally, if the <code>QR</code> argument to the model\n",
       "fitting function (e.g. <code>stan_glm</code>) is <code>FALSE</code> then: for a \n",
       "predictor with only one value nothing is changed; for a predictor <code>x</code> \n",
       "with exactly two unique values, we take the user-specified (or default) \n",
       "scale(s) for the selected priors and divide by the range of <code>x</code>; for a\n",
       "predictor <code>x</code> with more than two unique values, we divide the prior \n",
       "scale(s) by <code>2*sd(x)</code>.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The details depend on the family of the prior being used:\n",
       "</p>\n",
       "\n",
       "\n",
       "<h4>Student t family</h4>\n",
       "\n",
       "<p>Family members:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>normal(location, scale)</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>student_t(df, location, scale)</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>cauchy(location, scale)</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>For the prior distribution for the intercept, <code>location</code>, \n",
       "<code>scale</code>, and <code>df</code> should be scalars. For the prior for the other\n",
       "coefficients they can either be vectors of length equal to the number of\n",
       "coefficients (not including the intercept), or they can be scalars, in \n",
       "which case they will be recycled to the appropriate length. As the \n",
       "degrees of freedom approaches infinity, the Student t distribution \n",
       "approaches the normal distribution and if the degrees of freedom are one,\n",
       "then the Student t distribution is the Cauchy distribution.\n",
       "</p>\n",
       "<p>If <code>scale</code> is not specified it will default to 10 for the intercept\n",
       "and 2.5 for the other coefficients, unless the probit link function is\n",
       "used, in which case these defaults are scaled by a factor of \n",
       "<code>dnorm(0)/dlogis(0)</code>, which is roughly 1.6.\n",
       "</p>\n",
       "<p>If the <code>scaled</code> argument to <code>prior_options</code> is <code>TRUE</code> (the\n",
       "default), then the scales will be further adjusted as described above in\n",
       "the documentation of the <code>scaled</code> argument in the <strong>Arguments</strong> \n",
       "section.\n",
       "</p>\n",
       "\n",
       "\n",
       "\n",
       "<h4>Hierarchical shrinkage family</h4>\n",
       "\n",
       "<p>Family members:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>hs(df)</code>\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>hs_plus(df1, df2)</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>The hierarchical shrinkage priors are normal with a mean of zero and a \n",
       "standard deviation that is also a random variable. The traditional \n",
       "hierarchical shrinkage prior utilizes a standard deviation that is \n",
       "distributed half Cauchy with a median of zero and a scale parameter that is\n",
       "also half Cauchy. This is called the &quot;horseshoe prior&quot;. The hierarchical \n",
       "shrinkage (<code>hs</code>) prior in the <span class=\"pkg\">rstanarm</span> package instead utilizes \n",
       "a half Student t distribution for the standard deviation (with 3 degrees of\n",
       "freedom by default), scaled by a half Cauchy parameter, as described by\n",
       "Piironen and Vehtari (2015). It is possible to change the <code>df</code>\n",
       "argument, the prior degrees of freedom, to obtain less or more shrinkage.\n",
       "</p>\n",
       "<p>The hierarhical shrinkpage plus (<code>hs_plus</code>) prior is a normal with a \n",
       "mean of zero and a standard deviation that is distributed as the product of\n",
       "two independent half Student t parameters (both with 3 degrees of freedom\n",
       "(<code>df1</code>, <code>df2</code>) by default) that are each scaled by the same\n",
       "square root of a half Cauchy parameter.\n",
       "</p>\n",
       "<p>These hierarchical shrinkage priors have very tall modes and very fat \n",
       "tails. Consequently, they tend to produce posterior distributions that are\n",
       "very concentrated near zero, unless the predictor has a strong influence on\n",
       "the outcome, in which case the prior has little influence. Hierarchical\n",
       "shrinkage priors often require you to increase the \n",
       "<code>adapt_delta</code> tuning parameter in order to diminish the number\n",
       "of divergent transitions. For more details on tuning parameters and\n",
       "divergent transitions see the Troubleshooting section of the \n",
       "<em>How to Use the rstanarm Package</em> vignette.\n",
       "</p>\n",
       "\n",
       "\n",
       "\n",
       "<h4>Dirichlet family</h4>\n",
       "\n",
       "<p>Family members:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>dirichlet(concentration)</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>The Dirichlet distribution is a multivariate generalization of the beta\n",
       "distribution. It is perhaps the easiest prior distribution to specify\n",
       "because the concentration parameters can be interpreted as prior counts\n",
       "(although they need not be integers) of a multinomial random variable.\n",
       "</p>\n",
       "<p>The Dirichlet distribution is used in <code>stan_polr</code> for an \n",
       "implicit prior on the cutpoints in an ordinal regression model. More\n",
       "specifically, the Dirichlet prior pertains to the prior probability of\n",
       "observing each category of the ordinal outcome when the predictors are at\n",
       "their sample means. Given these prior probabilities, it is straightforward\n",
       "to add them to form cumulative probabilities and then use an inverse CDF\n",
       "transformation of the cumulative probabilities to define the cutpoints.\n",
       "</p>\n",
       "<p>If a scalar is passed to the <code>concentration</code> argument of the \n",
       "<code>dirichlet</code> function, then it is replicated to the appropriate length \n",
       "and the Dirichlet distribution is symmetric. If <code>concentration</code> is a\n",
       "vector and all elements are <i>1</i>, then the Dirichlet distribution is\n",
       "jointly uniform. If all concentration parameters are equal but greater than\n",
       "<i>1</i> then the prior mode is that the categories are equiprobable, and\n",
       "the larger the value of the identical concentration parameters, the more\n",
       "sharply peaked the distribution is at the mode. The elements in \n",
       "<code>concentration</code> can also be given different values to represent that \n",
       "not all outcome categories are a priori equiprobable.\n",
       "</p>\n",
       "\n",
       "\n",
       "\n",
       "<h4>Covariance matrices</h4>\n",
       "\n",
       "<p>Family members:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>decov(regularization, concentration, shape, scale)</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>(Also see vignette for <code>stan_glmer</code>)\n",
       "</p>\n",
       "<p>Covariance matrices are decomposed into correlation matrices and \n",
       "variances. The variances are in turn decomposed into the product of a\n",
       "simplex vector and the trace of the matrix. Finally, the trace is the\n",
       "product of the order of the matrix and the square of a scale parameter.\n",
       "This prior on a covariance matrix is represented by the <code>decov</code> \n",
       "function.\n",
       "</p>\n",
       "<p>The prior for a correlation matrix is called LKJ whose density is \n",
       "proportional to the determinant of the correlation matrix raised to the \n",
       "power of a positive regularization parameter minus one. If\n",
       "<code>regularization = 1</code> (the default), then this prior is jointly \n",
       "uniform over all correlation matrices of that size. If \n",
       "<code>regularization &gt; 1</code>, then the identity matrix is the mode and in the\n",
       "unlikely case that <code>regularization &lt; 1</code>, the identity matrix is the\n",
       "trough.\n",
       "</p>\n",
       "<p>The trace of a covariance matrix is equal to the sum of the variances. We\n",
       "set the trace equal to the product of the order of the covariance matrix\n",
       "and the <em>square</em> of a positive scale parameter. The particular\n",
       "variances are set equal to the product of a simplex vector &mdash; which is\n",
       "non-negative and sums to <i>1</i> &mdash; and the scalar trace. In other words,\n",
       "each element of the simplex vector represents the proportion of the trace\n",
       "attributable to the corresponding variable.\n",
       "</p>\n",
       "<p>A symmetric Dirichlet prior is used for the simplex vector, which has a \n",
       "single (positive) <code>concentration</code> parameter, which defaults to\n",
       "<i>1</i> and implies that the prior is jointly uniform over the space of\n",
       "simplex vectors of that size. If <code>concentration &gt; 1</code>, then the prior\n",
       "mode corresponds to all variables having the same (proportion of total)\n",
       "variance, which can be used to ensure the the posterior variances are not\n",
       "zero. As the <code>concentration</code> parameter approaches infinity, this\n",
       "mode becomes more pronounced. In the unlikely case that \n",
       "<code>concentration &lt; 1</code>, the variances are more polarized.\n",
       "</p>\n",
       "<p>If all the variables were multiplied by a number, the trace of their \n",
       "covariance matrix would increase by that number squared. Thus, it is \n",
       "reasonable to use a scale-invariant prior distribution for the positive\n",
       "scale parameter, and in this case we utilize a Gamma distribution, whose\n",
       "<code>shape</code> and <code>scale</code> are both <i>1</i> by default, implying a\n",
       "unit-exponential distribution. Set the <code>shape</code> hyperparameter to some\n",
       "value greater than <i>1</i> to ensure that the posterior trace is not zero.\n",
       "</p>\n",
       "<p>If <code>regularization</code>, <code>concentration</code>, <code>shape</code> and / or \n",
       "<code>scale</code> are positive scalars, then they are recycled to the \n",
       "appropriate length. Otherwise, each can be a positive vector of the \n",
       "appropriate length, but the appropriate length depends on the number of \n",
       "covariance matrices in the model and their sizes. A one-by-one covariance \n",
       "matrix is just a variance and thus does not have <code>regularization</code> or \n",
       "<code>concentration</code> parameters, but does have <code>shape</code> and \n",
       "<code>scale</code> parameters for the prior standard deviation of that \n",
       "variable.\n",
       "</p>\n",
       "\n",
       "\n",
       "\n",
       "<h4>R2 family</h4>\n",
       "\n",
       "<p>Family members:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>R2(location, what)</code>\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>The <code>stan_lm</code>, <code>stan_aov</code>, and \n",
       "<code>stan_polr</code> functions allow the user to utilize a function \n",
       "called <code>R2</code> to convey prior information about all the parameters. \n",
       "This prior hinges on prior beliefs about the location of <i>R^2</i>, the \n",
       "proportion of variance in the outcome attributable to the predictors, \n",
       "which has a <code>Beta</code> prior with first shape \n",
       "hyperparameter equal to half the number of predictors and second shape \n",
       "hyperparameter free. By specifying <code>what</code> to be the prior mode (the\n",
       "default), mean, median, or expected log of <i>R^2</i>, the second shape\n",
       "parameter for this Beta distribution is determined internally. If\n",
       "<code>what = 'log'</code>, location should be a negative scalar; otherwise it\n",
       "should be a scalar on the <i>(0,1)</i> interval.\n",
       "</p>\n",
       "<p>For example, if <i>R^2 = 0.5</i>, then the mode, mean, and median of\n",
       "the <code>Beta</code> distribution are all the same and thus the\n",
       "second shape parameter is also equal to half the number of predictors.\n",
       "The second shape parameter of the <code>Beta</code> distribution\n",
       "is actually the same as the shape parameter in the LKJ prior for a\n",
       "correlation matrix described in the previous subsection. Thus, the smaller \n",
       "is <i>R^2</i>, the larger is the shape parameter, the smaller are the\n",
       "prior correlations among the outcome and predictor variables, and the more\n",
       "concentrated near zero is the prior density for the regression \n",
       "coefficients. Hence, the prior on the coefficients is regularizing and \n",
       "should yield a posterior distribution with good out-of-sample predictions \n",
       "<em>if</em> the prior location of <i>R^2</i> is specified in a reasonable \n",
       "fashion.\n",
       "</p>\n",
       "\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A named list to be used internally by the <span class=\"pkg\">rstanarm</span> model\n",
       "fitting functions.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,\n",
       "A., and Rubin, D. B. (2013). <em>Bayesian Data Analysis.</em> Chapman &amp; Hall/CRC\n",
       "Press, London, third edition. <a href=\"http://stat.columbia.edu/~gelman/book/\">http://stat.columbia.edu/~gelman/book/</a>\n",
       "</p>\n",
       "<p>Gelman, A., Jakulin, A., Pittau, M. G., and Su, Y. (2008). A weakly\n",
       "informative default prior distribution for logistic and other regression\n",
       "models. <em>Annals of Applied Statistics</em>. 2(4), 1360&ndash;1383.\n",
       "</p>\n",
       "<p>Piironen, J., and Vehtari, A. (2015). Projection predictive variable\n",
       "selection using Stan+R. <a href=\"http://arxiv.org/abs/1508.02502/\">http://arxiv.org/abs/1508.02502/</a>\n",
       "</p>\n",
       "<p>Stan Development Team. (2016). <em>Stan Modeling Language Users Guide and\n",
       "Reference Manual.</em> <a href=\"http://mc-stan.org/documentation/\">http://mc-stan.org/documentation/</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p>The various vignettes for the <span class=\"pkg\">rstanarm</span> package also discuss \n",
       "and demonstrate the use of some of the supported prior distributions.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "fmla &lt;- mpg ~ wt + qsec + drat + am\n",
       "\n",
       "# Draw from prior predictive distribution (by setting prior_PD = TRUE)\n",
       "prior_pred_fit &lt;- stan_glm(fmla, data = mtcars, prior_PD = TRUE,\n",
       "                           chains = 1, seed = 12345, iter = 500, # for speed only\n",
       "                           prior = student_t(df = 4, 0, 2.5), \n",
       "                           prior_intercept = cauchy(0,10), \n",
       "                           prior_ops = prior_options(prior_scale_for_dispersion = 2))\n",
       "\n",
       "\n",
       "# Can assign priors to names\n",
       "N05 &lt;- normal(0, 5)\n",
       "fit &lt;- stan_glm(fmla, data = mtcars, prior = N05, prior_intercept = N05)\n",
       "\n",
       "\n",
       "# Visually compare normal, student_t, and cauchy\n",
       "compare_priors &lt;- function(scale = 1, df_t = 2, xlim = c(-10, 10)) {\n",
       "  dt_loc_scale &lt;- function(x, df, location, scale) { \n",
       "    1/scale * dt((x - location)/scale, df)  \n",
       "  }\n",
       "  stat_dist &lt;- function(dist, ...) {\n",
       "    ggplot2::stat_function(ggplot2::aes_(color = dist), ...)\n",
       "  }\n",
       "  ggplot2::ggplot(data.frame(x = xlim), ggplot2::aes(x)) + \n",
       "    stat_dist(\"normal\", size = .75, fun = dnorm, \n",
       "              args = list(mean = 0, sd = scale)) +\n",
       "    stat_dist(\"student_t\", size = .75, fun = dt_loc_scale, \n",
       "              args = list(df = df_t, location = 0, scale = scale)) +\n",
       "    stat_dist(\"cauchy\", size = .75, linetype = 2, fun = dcauchy, \n",
       "              args = list(location = 0, scale = scale))\n",
       "}\n",
       "# Cauchy has fattest tails, then student_t, then normal\n",
       "compare_priors()\n",
       "\n",
       "# The student_t with df = 1 is the same as the cauchy\n",
       "compare_priors(df_t = 1) \n",
       "\n",
       "# Even a scale of 5 is somewhat large. It gives plausibility to rather \n",
       "# extreme values\n",
       "compare_priors(scale = 5, xlim = c(-20,20)) \n",
       "\n",
       "# If you use a prior like normal(0, 1000) to be \"non-informative\" you are \n",
       "# actually saying that a coefficient value of e.g. -500 is quite plausible\n",
       "compare_priors(scale = 1000, xlim = c(-1000,1000))\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>rstanarm</em> version 2.13.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{priors}{Prior distributions and options}{priors}\n",
       "\\aliasA{cauchy}{priors}{cauchy}\n",
       "\\aliasA{decov}{priors}{decov}\n",
       "\\aliasA{dirichlet}{priors}{dirichlet}\n",
       "\\aliasA{hs}{priors}{hs}\n",
       "\\aliasA{hs\\_plus}{priors}{hs.Rul.plus}\n",
       "\\aliasA{normal}{priors}{normal}\n",
       "\\aliasA{prior\\_options}{priors}{prior.Rul.options}\n",
       "\\aliasA{R2}{priors}{R2}\n",
       "\\aliasA{student\\_t}{priors}{student.Rul.t}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "The functions described on this page are used to specify the prior-related\n",
       "arguments of the various modeling functions in the \\pkg{rstanarm} package (to\n",
       "view the priors used for an existing model see \\code{\\LinkA{prior\\_summary}{prior.Rul.summary}}). \n",
       "The default priors used in the various \\pkg{rstanarm} modeling functions are\n",
       "intended to be \\emph{weakly informative} in that they provide moderate\n",
       "regularlization and help stabilize computation. For many applications the\n",
       "defaults will perform well, but prudent use of more informative priors is\n",
       "encouraged. Uniform prior distributions are possible (e.g. by setting\n",
       "\\code{\\LinkA{stan\\_glm}{stan.Rul.glm}}'s \\code{prior} argument to \\code{NULL}) but, unless\n",
       "the data is very strong, they are not recommended and are \\emph{not}\n",
       "non-informative, giving the same probability mass to implausible values as\n",
       "plausible ones.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "normal(location = 0, scale = NULL)\n",
       "\n",
       "student_t(df = 1, location = 0, scale = NULL)\n",
       "\n",
       "cauchy(location = 0, scale = NULL)\n",
       "\n",
       "hs(df = 3)\n",
       "\n",
       "hs_plus(df1 = 3, df2 = 3)\n",
       "\n",
       "decov(regularization = 1, concentration = 1, shape = 1, scale = 1)\n",
       "\n",
       "dirichlet(concentration = 1)\n",
       "\n",
       "R2(location = NULL, what = c(\"mode\", \"mean\", \"median\", \"log\"))\n",
       "\n",
       "prior_options(prior_scale_for_dispersion = 5, min_prior_scale = 1e-12,\n",
       "  scaled = TRUE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{location}] Prior location. For \\code{normal} and \\code{student\\_t} \n",
       "(provided that \\code{df > 1}) this is the prior mean. For \\code{cauchy} \n",
       "(which is equivalent to \\code{student\\_t} with \\code{df=1}), the mean does \n",
       "not exist and \\code{location} is the prior median. The default value is \n",
       "\\eqn{0}{}, except for \\code{R2} which has no default value for\n",
       "\\code{location}. For \\code{R2}, \\code{location} pertains to the prior\n",
       "location of the \\eqn{R^2}{} under a Beta distribution, but the interpretation\n",
       "of the \\code{location} parameter depends on the specified value of the\n",
       "\\code{what} argument (see the \"R2 family\" section in Details).\n",
       "\n",
       "\\item[\\code{scale}] Prior scale. The default depends on the family (see Details).\n",
       "\n",
       "\\item[\\code{df, df1, df2}] Prior degrees of freedom. The default is \\eqn{1}{} for \n",
       "\\code{student\\_t}, in which case it is equivalent to \\code{cauchy}. For the\n",
       "hierarchical shrinkage priors (\\code{hs} and \\code{hs\\_plus}) the degrees of\n",
       "freedom parameter(s) default to \\eqn{3}{}.\n",
       "\n",
       "\\item[\\code{regularization}] Exponent for an LKJ prior on the correlation matrix in\n",
       "the \\code{decov} prior. The default is \\eqn{1}{}, implying a joint uniform\n",
       "prior.\n",
       "\n",
       "\\item[\\code{concentration}] Concentration parameter for a symmetric Dirichlet \n",
       "distribution. The default is \\eqn{1}{}, implying a joint uniform prior.\n",
       "\n",
       "\\item[\\code{shape}] Shape parameter for a gamma prior on the scale parameter in the\n",
       "\\code{decov} prior. If \\code{shape} and \\code{scale} are both \\eqn{1}{} (the\n",
       "default) then the gamma prior simplifies to the unit-exponential\n",
       "distribution.\n",
       "\n",
       "\\item[\\code{what}] A character string among \\code{'mode'} (the default),\n",
       "\\code{'mean'}, \\code{'median'}, or \\code{'log'} indicating how the\n",
       "\\code{location} parameter is interpreted in the \\code{LKJ} case. If\n",
       "\\code{'log'}, then \\code{location} is interpreted as the expected\n",
       "logarithm of the \\eqn{R^2}{} under a Beta distribution. Otherwise,\n",
       "\\code{location} is interpreted as the \\code{what} of the \\eqn{R^2}{}\n",
       "under a Beta distribution. If the number of predictors is less than\n",
       "or equal to two, the mode of this Beta distribution does not exist\n",
       "and an error will prompt the user to specify another choice for\n",
       "\\code{what}.\n",
       "\n",
       "\\item[\\code{prior\\_scale\\_for\\_dispersion}] Prior scale for the standard error of the \n",
       "regression in Gaussian models, which is given a half-Cauchy prior truncated\n",
       "at zero.\n",
       "\n",
       "\\item[\\code{min\\_prior\\_scale}] Minimum prior scale for the intercept and \n",
       "coefficients.\n",
       "\n",
       "\\item[\\code{scaled}] A logical scalar, defaulting to \\code{TRUE}. If \\code{TRUE} \n",
       "then the scales of the priors on the regression coefficients may be \n",
       "additionally modified internally by \\pkg{rstanarm} as follows. First, if\n",
       "\\emph{response} is Gaussian, the prior scales also multiplied by \n",
       "\\code{2*sd(y)}. Additionally, if the \\code{QR} argument to the model\n",
       "fitting function (e.g. \\code{stan\\_glm}) is \\code{FALSE} then: for a \n",
       "predictor with only one value nothing is changed; for a predictor \\code{x} \n",
       "with exactly two unique values, we take the user-specified (or default) \n",
       "scale(s) for the selected priors and divide by the range of \\code{x}; for a\n",
       "predictor \\code{x} with more than two unique values, we divide the prior \n",
       "scale(s) by \\code{2*sd(x)}.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The details depend on the family of the prior being used:\n",
       "%\n",
       "\\begin{SubSection}{Student t family}\n",
       "Family members:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{normal(location, scale)}\n",
       "\\item \\code{student\\_t(df, location, scale)}\n",
       "\\item \\code{cauchy(location, scale)}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "For the prior distribution for the intercept, \\code{location}, \n",
       "\\code{scale}, and \\code{df} should be scalars. For the prior for the other\n",
       "coefficients they can either be vectors of length equal to the number of\n",
       "coefficients (not including the intercept), or they can be scalars, in \n",
       "which case they will be recycled to the appropriate length. As the \n",
       "degrees of freedom approaches infinity, the Student t distribution \n",
       "approaches the normal distribution and if the degrees of freedom are one,\n",
       "then the Student t distribution is the Cauchy distribution.\n",
       "\n",
       "If \\code{scale} is not specified it will default to 10 for the intercept\n",
       "and 2.5 for the other coefficients, unless the probit link function is\n",
       "used, in which case these defaults are scaled by a factor of \n",
       "\\code{dnorm(0)/dlogis(0)}, which is roughly 1.6.\n",
       "\n",
       "If the \\code{scaled} argument to \\code{prior\\_options} is \\code{TRUE} (the\n",
       "default), then the scales will be further adjusted as described above in\n",
       "the documentation of the \\code{scaled} argument in the \\strong{Arguments} \n",
       "section.\n",
       "\\end{SubSection}\n",
       "\n",
       "%\n",
       "\\begin{SubSection}{Hierarchical shrinkage family}\n",
       "Family members:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{hs(df)}\n",
       "\\item \\code{hs\\_plus(df1, df2)}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "The hierarchical shrinkage priors are normal with a mean of zero and a \n",
       "standard deviation that is also a random variable. The traditional \n",
       "hierarchical shrinkage prior utilizes a standard deviation that is \n",
       "distributed half Cauchy with a median of zero and a scale parameter that is\n",
       "also half Cauchy. This is called the \"horseshoe prior\". The hierarchical \n",
       "shrinkage (\\code{hs}) prior in the \\pkg{rstanarm} package instead utilizes \n",
       "a half Student t distribution for the standard deviation (with 3 degrees of\n",
       "freedom by default), scaled by a half Cauchy parameter, as described by\n",
       "Piironen and Vehtari (2015). It is possible to change the \\code{df}\n",
       "argument, the prior degrees of freedom, to obtain less or more shrinkage.\n",
       "\n",
       "The hierarhical shrinkpage plus (\\code{hs\\_plus}) prior is a normal with a \n",
       "mean of zero and a standard deviation that is distributed as the product of\n",
       "two independent half Student t parameters (both with 3 degrees of freedom\n",
       "(\\code{df1}, \\code{df2}) by default) that are each scaled by the same\n",
       "square root of a half Cauchy parameter.\n",
       "\n",
       "These hierarchical shrinkage priors have very tall modes and very fat \n",
       "tails. Consequently, they tend to produce posterior distributions that are\n",
       "very concentrated near zero, unless the predictor has a strong influence on\n",
       "the outcome, in which case the prior has little influence. Hierarchical\n",
       "shrinkage priors often require you to increase the \n",
       "\\code{\\LinkA{adapt\\_delta}{adapt.Rul.delta}} tuning parameter in order to diminish the number\n",
       "of divergent transitions. For more details on tuning parameters and\n",
       "divergent transitions see the Troubleshooting section of the \n",
       "\\emph{How to Use the rstanarm Package} vignette.\n",
       "\\end{SubSection}\n",
       "\n",
       "%\n",
       "\\begin{SubSection}{Dirichlet family}\n",
       "Family members:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{dirichlet(concentration)}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "The Dirichlet distribution is a multivariate generalization of the beta\n",
       "distribution. It is perhaps the easiest prior distribution to specify\n",
       "because the concentration parameters can be interpreted as prior counts\n",
       "(although they need not be integers) of a multinomial random variable.\n",
       "\n",
       "The Dirichlet distribution is used in \\code{\\LinkA{stan\\_polr}{stan.Rul.polr}} for an \n",
       "implicit prior on the cutpoints in an ordinal regression model. More\n",
       "specifically, the Dirichlet prior pertains to the prior probability of\n",
       "observing each category of the ordinal outcome when the predictors are at\n",
       "their sample means. Given these prior probabilities, it is straightforward\n",
       "to add them to form cumulative probabilities and then use an inverse CDF\n",
       "transformation of the cumulative probabilities to define the cutpoints.\n",
       "\n",
       "If a scalar is passed to the \\code{concentration} argument of the \n",
       "\\code{dirichlet} function, then it is replicated to the appropriate length \n",
       "and the Dirichlet distribution is symmetric. If \\code{concentration} is a\n",
       "vector and all elements are \\eqn{1}{}, then the Dirichlet distribution is\n",
       "jointly uniform. If all concentration parameters are equal but greater than\n",
       "\\eqn{1}{} then the prior mode is that the categories are equiprobable, and\n",
       "the larger the value of the identical concentration parameters, the more\n",
       "sharply peaked the distribution is at the mode. The elements in \n",
       "\\code{concentration} can also be given different values to represent that \n",
       "not all outcome categories are a priori equiprobable.\n",
       "\\end{SubSection}\n",
       "\n",
       "%\n",
       "\\begin{SubSection}{Covariance matrices}\n",
       "Family members:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{decov(regularization, concentration, shape, scale)}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "(Also see vignette for \\code{stan\\_glmer})\n",
       "\n",
       "Covariance matrices are decomposed into correlation matrices and \n",
       "variances. The variances are in turn decomposed into the product of a\n",
       "simplex vector and the trace of the matrix. Finally, the trace is the\n",
       "product of the order of the matrix and the square of a scale parameter.\n",
       "This prior on a covariance matrix is represented by the \\code{decov} \n",
       "function.\n",
       "\n",
       "The prior for a correlation matrix is called LKJ whose density is \n",
       "proportional to the determinant of the correlation matrix raised to the \n",
       "power of a positive regularization parameter minus one. If\n",
       "\\code{regularization = 1} (the default), then this prior is jointly \n",
       "uniform over all correlation matrices of that size. If \n",
       "\\code{regularization > 1}, then the identity matrix is the mode and in the\n",
       "unlikely case that \\code{regularization < 1}, the identity matrix is the\n",
       "trough.\n",
       "\n",
       "The trace of a covariance matrix is equal to the sum of the variances. We\n",
       "set the trace equal to the product of the order of the covariance matrix\n",
       "and the \\emph{square} of a positive scale parameter. The particular\n",
       "variances are set equal to the product of a simplex vector --- which is\n",
       "non-negative and sums to \\eqn{1}{} --- and the scalar trace. In other words,\n",
       "each element of the simplex vector represents the proportion of the trace\n",
       "attributable to the corresponding variable.\n",
       "\n",
       "A symmetric Dirichlet prior is used for the simplex vector, which has a \n",
       "single (positive) \\code{concentration} parameter, which defaults to\n",
       "\\eqn{1}{} and implies that the prior is jointly uniform over the space of\n",
       "simplex vectors of that size. If \\code{concentration > 1}, then the prior\n",
       "mode corresponds to all variables having the same (proportion of total)\n",
       "variance, which can be used to ensure the the posterior variances are not\n",
       "zero. As the \\code{concentration} parameter approaches infinity, this\n",
       "mode becomes more pronounced. In the unlikely case that \n",
       "\\code{concentration < 1}, the variances are more polarized.\n",
       "\n",
       "If all the variables were multiplied by a number, the trace of their \n",
       "covariance matrix would increase by that number squared. Thus, it is \n",
       "reasonable to use a scale-invariant prior distribution for the positive\n",
       "scale parameter, and in this case we utilize a Gamma distribution, whose\n",
       "\\code{shape} and \\code{scale} are both \\eqn{1}{} by default, implying a\n",
       "unit-exponential distribution. Set the \\code{shape} hyperparameter to some\n",
       "value greater than \\eqn{1}{} to ensure that the posterior trace is not zero.\n",
       "\n",
       "If \\code{regularization}, \\code{concentration}, \\code{shape} and / or \n",
       "\\code{scale} are positive scalars, then they are recycled to the \n",
       "appropriate length. Otherwise, each can be a positive vector of the \n",
       "appropriate length, but the appropriate length depends on the number of \n",
       "covariance matrices in the model and their sizes. A one-by-one covariance \n",
       "matrix is just a variance and thus does not have \\code{regularization} or \n",
       "\\code{concentration} parameters, but does have \\code{shape} and \n",
       "\\code{scale} parameters for the prior standard deviation of that \n",
       "variable.\n",
       "\\end{SubSection}\n",
       "\n",
       "%\n",
       "\\begin{SubSection}{R2 family}\n",
       "Family members:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{R2(location, what)}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "The \\code{\\LinkA{stan\\_lm}{stan.Rul.lm}}, \\code{\\LinkA{stan\\_aov}{stan.Rul.aov}}, and \n",
       "\\code{\\LinkA{stan\\_polr}{stan.Rul.polr}} functions allow the user to utilize a function \n",
       "called \\code{R2} to convey prior information about all the parameters. \n",
       "This prior hinges on prior beliefs about the location of \\eqn{R^2}{}, the \n",
       "proportion of variance in the outcome attributable to the predictors, \n",
       "which has a \\code{\\LinkA{Beta}{Beta}} prior with first shape \n",
       "hyperparameter equal to half the number of predictors and second shape \n",
       "hyperparameter free. By specifying \\code{what} to be the prior mode (the\n",
       "default), mean, median, or expected log of \\eqn{R^2}{}, the second shape\n",
       "parameter for this Beta distribution is determined internally. If\n",
       "\\code{what = 'log'}, location should be a negative scalar; otherwise it\n",
       "should be a scalar on the \\eqn{(0,1)}{} interval.\n",
       "\n",
       "For example, if \\eqn{R^2 = 0.5}{}, then the mode, mean, and median of\n",
       "the \\code{\\LinkA{Beta}{Beta}} distribution are all the same and thus the\n",
       "second shape parameter is also equal to half the number of predictors.\n",
       "The second shape parameter of the \\code{\\LinkA{Beta}{Beta}} distribution\n",
       "is actually the same as the shape parameter in the LKJ prior for a\n",
       "correlation matrix described in the previous subsection. Thus, the smaller \n",
       "is \\eqn{R^2}{}, the larger is the shape parameter, the smaller are the\n",
       "prior correlations among the outcome and predictor variables, and the more\n",
       "concentrated near zero is the prior density for the regression \n",
       "coefficients. Hence, the prior on the coefficients is regularizing and \n",
       "should yield a posterior distribution with good out-of-sample predictions \n",
       "\\emph{if} the prior location of \\eqn{R^2}{} is specified in a reasonable \n",
       "fashion.\n",
       "\\end{SubSection}\n",
       "\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A named list to be used internally by the \\pkg{rstanarm} model\n",
       "fitting functions.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,\n",
       "A., and Rubin, D. B. (2013). \\emph{Bayesian Data Analysis.} Chapman \\& Hall/CRC\n",
       "Press, London, third edition. \\url{http://stat.columbia.edu/~gelman/book/}\n",
       "\n",
       "Gelman, A., Jakulin, A., Pittau, M. G., and Su, Y. (2008). A weakly\n",
       "informative default prior distribution for logistic and other regression\n",
       "models. \\emph{Annals of Applied Statistics}. 2(4), 1360--1383.\n",
       "\n",
       "Piironen, J., and Vehtari, A. (2015). Projection predictive variable\n",
       "selection using Stan+R. \\url{http://arxiv.org/abs/1508.02502/}\n",
       "\n",
       "Stan Development Team. (2016). \\emph{Stan Modeling Language Users Guide and\n",
       "Reference Manual.} \\url{http://mc-stan.org/documentation/}\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "The various vignettes for the \\pkg{rstanarm} package also discuss \n",
       "and demonstrate the use of some of the supported prior distributions.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "fmla <- mpg ~ wt + qsec + drat + am\n",
       "\n",
       "# Draw from prior predictive distribution (by setting prior_PD = TRUE)\n",
       "prior_pred_fit <- stan_glm(fmla, data = mtcars, prior_PD = TRUE,\n",
       "                           chains = 1, seed = 12345, iter = 500, # for speed only\n",
       "                           prior = student_t(df = 4, 0, 2.5), \n",
       "                           prior_intercept = cauchy(0,10), \n",
       "                           prior_ops = prior_options(prior_scale_for_dispersion = 2))\n",
       "\n",
       "\n",
       "# Can assign priors to names\n",
       "N05 <- normal(0, 5)\n",
       "fit <- stan_glm(fmla, data = mtcars, prior = N05, prior_intercept = N05)\n",
       "\n",
       "\n",
       "# Visually compare normal, student_t, and cauchy\n",
       "compare_priors <- function(scale = 1, df_t = 2, xlim = c(-10, 10)) {\n",
       "  dt_loc_scale <- function(x, df, location, scale) { \n",
       "    1/scale * dt((x - location)/scale, df)  \n",
       "  }\n",
       "  stat_dist <- function(dist, ...) {\n",
       "    ggplot2::stat_function(ggplot2::aes_(color = dist), ...)\n",
       "  }\n",
       "  ggplot2::ggplot(data.frame(x = xlim), ggplot2::aes(x)) + \n",
       "    stat_dist(\"normal\", size = .75, fun = dnorm, \n",
       "              args = list(mean = 0, sd = scale)) +\n",
       "    stat_dist(\"student_t\", size = .75, fun = dt_loc_scale, \n",
       "              args = list(df = df_t, location = 0, scale = scale)) +\n",
       "    stat_dist(\"cauchy\", size = .75, linetype = 2, fun = dcauchy, \n",
       "              args = list(location = 0, scale = scale))\n",
       "}\n",
       "# Cauchy has fattest tails, then student_t, then normal\n",
       "compare_priors()\n",
       "\n",
       "# The student_t with df = 1 is the same as the cauchy\n",
       "compare_priors(df_t = 1) \n",
       "\n",
       "# Even a scale of 5 is somewhat large. It gives plausibility to rather \n",
       "# extreme values\n",
       "compare_priors(scale = 5, xlim = c(-20,20)) \n",
       "\n",
       "# If you use a prior like normal(0, 1000) to be \"non-informative\" you are \n",
       "# actually saying that a coefficient value of e.g. -500 is quite plausible\n",
       "compare_priors(scale = 1000, xlim = c(-1000,1000))\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "priors                package:rstanarm                 R Documentation\n",
       "\n",
       "_\bP_\br_\bi_\bo_\br _\bd_\bi_\bs_\bt_\br_\bi_\bb_\bu_\bt_\bi_\bo_\bn_\bs _\ba_\bn_\bd _\bo_\bp_\bt_\bi_\bo_\bn_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     The functions described on this page are used to specify the\n",
       "     prior-related arguments of the various modeling functions in the\n",
       "     ‘rstanarm’ package (to view the priors used for an existing model\n",
       "     see ‘prior_summary’).  The default priors used in the various\n",
       "     ‘rstanarm’ modeling functions are intended to be _weakly\n",
       "     informative_ in that they provide moderate regularlization and\n",
       "     help stabilize computation. For many applications the defaults\n",
       "     will perform well, but prudent use of more informative priors is\n",
       "     encouraged. Uniform prior distributions are possible (e.g. by\n",
       "     setting ‘stan_glm’'s ‘prior’ argument to ‘NULL’) but, unless the\n",
       "     data is very strong, they are not recommended and are _not_\n",
       "     non-informative, giving the same probability mass to implausible\n",
       "     values as plausible ones.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     normal(location = 0, scale = NULL)\n",
       "     \n",
       "     student_t(df = 1, location = 0, scale = NULL)\n",
       "     \n",
       "     cauchy(location = 0, scale = NULL)\n",
       "     \n",
       "     hs(df = 3)\n",
       "     \n",
       "     hs_plus(df1 = 3, df2 = 3)\n",
       "     \n",
       "     decov(regularization = 1, concentration = 1, shape = 1, scale = 1)\n",
       "     \n",
       "     dirichlet(concentration = 1)\n",
       "     \n",
       "     R2(location = NULL, what = c(\"mode\", \"mean\", \"median\", \"log\"))\n",
       "     \n",
       "     prior_options(prior_scale_for_dispersion = 5, min_prior_scale = 1e-12,\n",
       "       scaled = TRUE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "location: Prior location. For ‘normal’ and ‘student_t’ (provided that\n",
       "          ‘df > 1’) this is the prior mean. For ‘cauchy’ (which is\n",
       "          equivalent to ‘student_t’ with ‘df=1’), the mean does not\n",
       "          exist and ‘location’ is the prior median. The default value\n",
       "          is 0, except for ‘R2’ which has no default value for\n",
       "          ‘location’. For ‘R2’, ‘location’ pertains to the prior\n",
       "          location of the R^2 under a Beta distribution, but the\n",
       "          interpretation of the ‘location’ parameter depends on the\n",
       "          specified value of the ‘what’ argument (see the \"R2 family\"\n",
       "          section in Details).\n",
       "\n",
       "   scale: Prior scale. The default depends on the family (see Details).\n",
       "\n",
       "df, df1, df2: Prior degrees of freedom. The default is 1 for\n",
       "          ‘student_t’, in which case it is equivalent to ‘cauchy’. For\n",
       "          the hierarchical shrinkage priors (‘hs’ and ‘hs_plus’) the\n",
       "          degrees of freedom parameter(s) default to 3.\n",
       "\n",
       "regularization: Exponent for an LKJ prior on the correlation matrix in\n",
       "          the ‘decov’ prior. The default is 1, implying a joint uniform\n",
       "          prior.\n",
       "\n",
       "concentration: Concentration parameter for a symmetric Dirichlet\n",
       "          distribution. The default is 1, implying a joint uniform\n",
       "          prior.\n",
       "\n",
       "   shape: Shape parameter for a gamma prior on the scale parameter in\n",
       "          the ‘decov’ prior. If ‘shape’ and ‘scale’ are both 1 (the\n",
       "          default) then the gamma prior simplifies to the\n",
       "          unit-exponential distribution.\n",
       "\n",
       "    what: A character string among ‘'mode'’ (the default), ‘'mean'’,\n",
       "          ‘'median'’, or ‘'log'’ indicating how the ‘location’\n",
       "          parameter is interpreted in the ‘LKJ’ case. If ‘'log'’, then\n",
       "          ‘location’ is interpreted as the expected logarithm of the\n",
       "          R^2 under a Beta distribution. Otherwise, ‘location’ is\n",
       "          interpreted as the ‘what’ of the R^2 under a Beta\n",
       "          distribution. If the number of predictors is less than or\n",
       "          equal to two, the mode of this Beta distribution does not\n",
       "          exist and an error will prompt the user to specify another\n",
       "          choice for ‘what’.\n",
       "\n",
       "prior_scale_for_dispersion: Prior scale for the standard error of the\n",
       "          regression in Gaussian models, which is given a half-Cauchy\n",
       "          prior truncated at zero.\n",
       "\n",
       "min_prior_scale: Minimum prior scale for the intercept and\n",
       "          coefficients.\n",
       "\n",
       "  scaled: A logical scalar, defaulting to ‘TRUE’. If ‘TRUE’ then the\n",
       "          scales of the priors on the regression coefficients may be\n",
       "          additionally modified internally by ‘rstanarm’ as follows.\n",
       "          First, if _response_ is Gaussian, the prior scales also\n",
       "          multiplied by ‘2*sd(y)’. Additionally, if the ‘QR’ argument\n",
       "          to the model fitting function (e.g. ‘stan_glm’) is ‘FALSE’\n",
       "          then: for a predictor with only one value nothing is changed;\n",
       "          for a predictor ‘x’ with exactly two unique values, we take\n",
       "          the user-specified (or default) scale(s) for the selected\n",
       "          priors and divide by the range of ‘x’; for a predictor ‘x’\n",
       "          with more than two unique values, we divide the prior\n",
       "          scale(s) by ‘2*sd(x)’.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The details depend on the family of the prior being used:\n",
       "\n",
       "  _\bS_\bt_\bu_\bd_\be_\bn_\bt _\bt _\bf_\ba_\bm_\bi_\bl_\by:\n",
       "\n",
       "       Family members:\n",
       "\n",
       "         • ‘normal(location, scale)’\n",
       "\n",
       "         • ‘student_t(df, location, scale)’\n",
       "\n",
       "         • ‘cauchy(location, scale)’\n",
       "\n",
       "       For the prior distribution for the intercept, ‘location’,\n",
       "       ‘scale’, and ‘df’ should be scalars. For the prior for the other\n",
       "       coefficients they can either be vectors of length equal to the\n",
       "       number of coefficients (not including the intercept), or they\n",
       "       can be scalars, in which case they will be recycled to the\n",
       "       appropriate length. As the degrees of freedom approaches\n",
       "       infinity, the Student t distribution approaches the normal\n",
       "       distribution and if the degrees of freedom are one, then the\n",
       "       Student t distribution is the Cauchy distribution.\n",
       "\n",
       "       If ‘scale’ is not specified it will default to 10 for the\n",
       "       intercept and 2.5 for the other coefficients, unless the probit\n",
       "       link function is used, in which case these defaults are scaled\n",
       "       by a factor of ‘dnorm(0)/dlogis(0)’, which is roughly 1.6.\n",
       "\n",
       "       If the ‘scaled’ argument to ‘prior_options’ is ‘TRUE’ (the\n",
       "       default), then the scales will be further adjusted as described\n",
       "       above in the documentation of the ‘scaled’ argument in the\n",
       "       *Arguments* section.\n",
       "\n",
       "\n",
       "  _\bH_\bi_\be_\br_\ba_\br_\bc_\bh_\bi_\bc_\ba_\bl _\bs_\bh_\br_\bi_\bn_\bk_\ba_\bg_\be _\bf_\ba_\bm_\bi_\bl_\by:\n",
       "\n",
       "       Family members:\n",
       "\n",
       "         • ‘hs(df)’\n",
       "\n",
       "         • ‘hs_plus(df1, df2)’\n",
       "\n",
       "       The hierarchical shrinkage priors are normal with a mean of zero\n",
       "       and a standard deviation that is also a random variable. The\n",
       "       traditional hierarchical shrinkage prior utilizes a standard\n",
       "       deviation that is distributed half Cauchy with a median of zero\n",
       "       and a scale parameter that is also half Cauchy. This is called\n",
       "       the \"horseshoe prior\". The hierarchical shrinkage (‘hs’) prior\n",
       "       in the ‘rstanarm’ package instead utilizes a half Student t\n",
       "       distribution for the standard deviation (with 3 degrees of\n",
       "       freedom by default), scaled by a half Cauchy parameter, as\n",
       "       described by Piironen and Vehtari (2015). It is possible to\n",
       "       change the ‘df’ argument, the prior degrees of freedom, to\n",
       "       obtain less or more shrinkage.\n",
       "\n",
       "       The hierarhical shrinkpage plus (‘hs_plus’) prior is a normal\n",
       "       with a mean of zero and a standard deviation that is distributed\n",
       "       as the product of two independent half Student t parameters\n",
       "       (both with 3 degrees of freedom (‘df1’, ‘df2’) by default) that\n",
       "       are each scaled by the same square root of a half Cauchy\n",
       "       parameter.\n",
       "\n",
       "       These hierarchical shrinkage priors have very tall modes and\n",
       "       very fat tails. Consequently, they tend to produce posterior\n",
       "       distributions that are very concentrated near zero, unless the\n",
       "       predictor has a strong influence on the outcome, in which case\n",
       "       the prior has little influence. Hierarchical shrinkage priors\n",
       "       often require you to increase the ‘adapt_delta’ tuning parameter\n",
       "       in order to diminish the number of divergent transitions. For\n",
       "       more details on tuning parameters and divergent transitions see\n",
       "       the Troubleshooting section of the _How to Use the rstanarm\n",
       "       Package_ vignette.\n",
       "\n",
       "\n",
       "  _\bD_\bi_\br_\bi_\bc_\bh_\bl_\be_\bt _\bf_\ba_\bm_\bi_\bl_\by:\n",
       "\n",
       "       Family members:\n",
       "\n",
       "         • ‘dirichlet(concentration)’\n",
       "\n",
       "       The Dirichlet distribution is a multivariate generalization of\n",
       "       the beta distribution. It is perhaps the easiest prior\n",
       "       distribution to specify because the concentration parameters can\n",
       "       be interpreted as prior counts (although they need not be\n",
       "       integers) of a multinomial random variable.\n",
       "\n",
       "       The Dirichlet distribution is used in ‘stan_polr’ for an\n",
       "       implicit prior on the cutpoints in an ordinal regression model.\n",
       "       More specifically, the Dirichlet prior pertains to the prior\n",
       "       probability of observing each category of the ordinal outcome\n",
       "       when the predictors are at their sample means. Given these prior\n",
       "       probabilities, it is straightforward to add them to form\n",
       "       cumulative probabilities and then use an inverse CDF\n",
       "       transformation of the cumulative probabilities to define the\n",
       "       cutpoints.\n",
       "\n",
       "       If a scalar is passed to the ‘concentration’ argument of the\n",
       "       ‘dirichlet’ function, then it is replicated to the appropriate\n",
       "       length and the Dirichlet distribution is symmetric. If\n",
       "       ‘concentration’ is a vector and all elements are 1, then the\n",
       "       Dirichlet distribution is jointly uniform. If all concentration\n",
       "       parameters are equal but greater than 1 then the prior mode is\n",
       "       that the categories are equiprobable, and the larger the value\n",
       "       of the identical concentration parameters, the more sharply\n",
       "       peaked the distribution is at the mode. The elements in\n",
       "       ‘concentration’ can also be given different values to represent\n",
       "       that not all outcome categories are a priori equiprobable.\n",
       "\n",
       "\n",
       "  _\bC_\bo_\bv_\ba_\br_\bi_\ba_\bn_\bc_\be _\bm_\ba_\bt_\br_\bi_\bc_\be_\bs:\n",
       "\n",
       "       Family members:\n",
       "\n",
       "         • ‘decov(regularization, concentration, shape, scale)’\n",
       "\n",
       "       (Also see vignette for ‘stan_glmer’)\n",
       "\n",
       "       Covariance matrices are decomposed into correlation matrices and\n",
       "       variances. The variances are in turn decomposed into the product\n",
       "       of a simplex vector and the trace of the matrix. Finally, the\n",
       "       trace is the product of the order of the matrix and the square\n",
       "       of a scale parameter.  This prior on a covariance matrix is\n",
       "       represented by the ‘decov’ function.\n",
       "\n",
       "       The prior for a correlation matrix is called LKJ whose density\n",
       "       is proportional to the determinant of the correlation matrix\n",
       "       raised to the power of a positive regularization parameter minus\n",
       "       one. If ‘regularization = 1’ (the default), then this prior is\n",
       "       jointly uniform over all correlation matrices of that size. If\n",
       "       ‘regularization > 1’, then the identity matrix is the mode and\n",
       "       in the unlikely case that ‘regularization < 1’, the identity\n",
       "       matrix is the trough.\n",
       "\n",
       "       The trace of a covariance matrix is equal to the sum of the\n",
       "       variances. We set the trace equal to the product of the order of\n",
       "       the covariance matrix and the _square_ of a positive scale\n",
       "       parameter. The particular variances are set equal to the product\n",
       "       of a simplex vector - which is non-negative and sums to 1 - and\n",
       "       the scalar trace. In other words, each element of the simplex\n",
       "       vector represents the proportion of the trace attributable to\n",
       "       the corresponding variable.\n",
       "\n",
       "       A symmetric Dirichlet prior is used for the simplex vector,\n",
       "       which has a single (positive) ‘concentration’ parameter, which\n",
       "       defaults to 1 and implies that the prior is jointly uniform over\n",
       "       the space of simplex vectors of that size. If ‘concentration >\n",
       "       1’, then the prior mode corresponds to all variables having the\n",
       "       same (proportion of total) variance, which can be used to ensure\n",
       "       the the posterior variances are not zero. As the ‘concentration’\n",
       "       parameter approaches infinity, this mode becomes more\n",
       "       pronounced. In the unlikely case that ‘concentration < 1’, the\n",
       "       variances are more polarized.\n",
       "\n",
       "       If all the variables were multiplied by a number, the trace of\n",
       "       their covariance matrix would increase by that number squared.\n",
       "       Thus, it is reasonable to use a scale-invariant prior\n",
       "       distribution for the positive scale parameter, and in this case\n",
       "       we utilize a Gamma distribution, whose ‘shape’ and ‘scale’ are\n",
       "       both 1 by default, implying a unit-exponential distribution. Set\n",
       "       the ‘shape’ hyperparameter to some value greater than 1 to\n",
       "       ensure that the posterior trace is not zero.\n",
       "\n",
       "       If ‘regularization’, ‘concentration’, ‘shape’ and / or ‘scale’\n",
       "       are positive scalars, then they are recycled to the appropriate\n",
       "       length. Otherwise, each can be a positive vector of the\n",
       "       appropriate length, but the appropriate length depends on the\n",
       "       number of covariance matrices in the model and their sizes. A\n",
       "       one-by-one covariance matrix is just a variance and thus does\n",
       "       not have ‘regularization’ or ‘concentration’ parameters, but\n",
       "       does have ‘shape’ and ‘scale’ parameters for the prior standard\n",
       "       deviation of that variable.\n",
       "\n",
       "\n",
       "  _\bR_\b2 _\bf_\ba_\bm_\bi_\bl_\by:\n",
       "\n",
       "       Family members:\n",
       "\n",
       "         • ‘R2(location, what)’\n",
       "\n",
       "       The ‘stan_lm’, ‘stan_aov’, and ‘stan_polr’ functions allow the\n",
       "       user to utilize a function called ‘R2’ to convey prior\n",
       "       information about all the parameters.  This prior hinges on\n",
       "       prior beliefs about the location of R^2, the proportion of\n",
       "       variance in the outcome attributable to the predictors, which\n",
       "       has a ‘Beta’ prior with first shape hyperparameter equal to half\n",
       "       the number of predictors and second shape hyperparameter free.\n",
       "       By specifying ‘what’ to be the prior mode (the default), mean,\n",
       "       median, or expected log of R^2, the second shape parameter for\n",
       "       this Beta distribution is determined internally. If ‘what =\n",
       "       'log'’, location should be a negative scalar; otherwise it\n",
       "       should be a scalar on the (0,1) interval.\n",
       "\n",
       "       For example, if R^2 = 0.5, then the mode, mean, and median of\n",
       "       the ‘Beta’ distribution are all the same and thus the second\n",
       "       shape parameter is also equal to half the number of predictors.\n",
       "       The second shape parameter of the ‘Beta’ distribution is\n",
       "       actually the same as the shape parameter in the LKJ prior for a\n",
       "       correlation matrix described in the previous subsection. Thus,\n",
       "       the smaller is R^2, the larger is the shape parameter, the\n",
       "       smaller are the prior correlations among the outcome and\n",
       "       predictor variables, and the more concentrated near zero is the\n",
       "       prior density for the regression coefficients. Hence, the prior\n",
       "       on the coefficients is regularizing and should yield a posterior\n",
       "       distribution with good out-of-sample predictions _if_ the prior\n",
       "       location of R^2 is specified in a reasonable fashion.\n",
       "\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A named list to be used internally by the ‘rstanarm’ model fitting\n",
       "     functions.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,\n",
       "     A., and Rubin, D. B. (2013). _Bayesian Data Analysis._ Chapman &\n",
       "     Hall/CRC Press, London, third edition. <URL:\n",
       "     http://stat.columbia.edu/~gelman/book/>\n",
       "\n",
       "     Gelman, A., Jakulin, A., Pittau, M. G., and Su, Y. (2008). A\n",
       "     weakly informative default prior distribution for logistic and\n",
       "     other regression models. _Annals of Applied Statistics_. 2(4),\n",
       "     1360-1383.\n",
       "\n",
       "     Piironen, J., and Vehtari, A. (2015). Projection predictive\n",
       "     variable selection using Stan+R. <URL:\n",
       "     http://arxiv.org/abs/1508.02502/>\n",
       "\n",
       "     Stan Development Team. (2016). _Stan Modeling Language Users Guide\n",
       "     and Reference Manual._ <URL: http://mc-stan.org/documentation/>\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     The various vignettes for the ‘rstanarm’ package also discuss and\n",
       "     demonstrate the use of some of the supported prior distributions.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     fmla <- mpg ~ wt + qsec + drat + am\n",
       "     \n",
       "     # Draw from prior predictive distribution (by setting prior_PD = TRUE)\n",
       "     prior_pred_fit <- stan_glm(fmla, data = mtcars, prior_PD = TRUE,\n",
       "                                chains = 1, seed = 12345, iter = 500, # for speed only\n",
       "                                prior = student_t(df = 4, 0, 2.5), \n",
       "                                prior_intercept = cauchy(0,10), \n",
       "                                prior_ops = prior_options(prior_scale_for_dispersion = 2))\n",
       "     \n",
       "     \n",
       "     # Can assign priors to names\n",
       "     N05 <- normal(0, 5)\n",
       "     fit <- stan_glm(fmla, data = mtcars, prior = N05, prior_intercept = N05)\n",
       "     \n",
       "     \n",
       "     # Visually compare normal, student_t, and cauchy\n",
       "     compare_priors <- function(scale = 1, df_t = 2, xlim = c(-10, 10)) {\n",
       "       dt_loc_scale <- function(x, df, location, scale) { \n",
       "         1/scale * dt((x - location)/scale, df)  \n",
       "       }\n",
       "       stat_dist <- function(dist, ...) {\n",
       "         ggplot2::stat_function(ggplot2::aes_(color = dist), ...)\n",
       "       }\n",
       "       ggplot2::ggplot(data.frame(x = xlim), ggplot2::aes(x)) + \n",
       "         stat_dist(\"normal\", size = .75, fun = dnorm, \n",
       "                   args = list(mean = 0, sd = scale)) +\n",
       "         stat_dist(\"student_t\", size = .75, fun = dt_loc_scale, \n",
       "                   args = list(df = df_t, location = 0, scale = scale)) +\n",
       "         stat_dist(\"cauchy\", size = .75, linetype = 2, fun = dcauchy, \n",
       "                   args = list(location = 0, scale = scale))\n",
       "     }\n",
       "     # Cauchy has fattest tails, then student_t, then normal\n",
       "     compare_priors()\n",
       "     \n",
       "     # The student_t with df = 1 is the same as the cauchy\n",
       "     compare_priors(df_t = 1) \n",
       "     \n",
       "     # Even a scale of 5 is somewhat large. It gives plausibility to rather \n",
       "     # extreme values\n",
       "     compare_priors(scale = 5, xlim = c(-20,20)) \n",
       "     \n",
       "     # If you use a prior like normal(0, 1000) to be \"non-informative\" you are \n",
       "     # actually saying that a coefficient value of e.g. -500 is quite plausible\n",
       "     compare_priors(scale = 1000, xlim = c(-1000,1000))\n",
       "     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(priors, package = 'rstanarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose we have $K$ predictors and believe --- prior to seeing \n",
    "the data --- that $\\alpha, \\beta_1, \\dots, \\beta_K$ (intercepts & all regression coeffecients) are as **likely to be positive\n",
    "as they are to be negative**, but are **highly unlikely to be far from zero**. \n",
    "\n",
    "These beliefs can be represented by **normal distributions with mean zero and a small\n",
    "scale (standard deviation)**. \n",
    "\n",
    "To give $\\alpha$ and each of the $\\beta$s for this prior (with a scale of 1, say), in the call to `stan_glm` we would include the arguments `prior_intercept = normal(0,1)` and `prior = normal(0,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(data): object 'dataset' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(data): object 'dataset' not found\n"
     ]
    }
   ],
   "source": [
    "# Toy function to illustrate the idea; don't run it, won't work\n",
    "posterior <- stan_glm(outcome ~ ., data = dataset,\n",
    "                 family = binomial(link = \"logit\"), \n",
    "                 prior = normal(0,1), prior_intercept = normal(0,1)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, on the other hand, we have less a priori confidence that the parameters will\n",
    "be close to zero then we could use a larger scale for the normal distribution \n",
    "and/or a distribution with heavier tails than the normal like the Student t \n",
    "distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(data): object 'dataset' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(data): object 'dataset' not found\n"
     ]
    }
   ],
   "source": [
    "# New toy posterior, with t_distributions instead\n",
    "posterior <- stan_glm(outcome ~ ., data = dataset,\n",
    "                 family = binomial(link = \"logit\"), \n",
    "                 prior = student_t(), prior_intercept = student_t()\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[__Step 1__ in the \"How to Use the __rstanarm__ Package\" vignette discusses one such example.](https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html)\n",
    "\n",
    "Therefore, **for the Bayes GLM, we define the prior and prior intercept via the distributions we expect these variables to take**, and `stan_glm` **allows us to switch between distributions easily**. In general, normal distributions may suffice, but more complex distributions may be far more appropriate for more applications, and warrant investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior\n",
    "\n",
    "With independent prior distributions, the joint posterior distribution for $\\alpha$ and $\\boldsymbol{\\beta}$ is proportional to the product of the **priors** and the $N$ **likelihood contributions**:\n",
    "\n",
    "\n",
    "$$f\\left(\\alpha,\\boldsymbol{\\beta} | \\mathbf{y},\\mathbf{X}\\right) \\propto\n",
    "  f\\left(\\alpha\\right) \\times \\prod_{k=1}^K f\\left(\\beta_k\\right) \\times\n",
    "  \\prod_{i=1}^N {\n",
    "  g^{-1}\\left(\\eta_i\\right)^{y_i} \n",
    "  \\left(1 - g^{-1}\\left(\\eta_i\\right)\\right)^{n_i-y_i}}$$\n",
    "\n",
    "This is posterior distribution that `stan_glm` will draw from when using MCMC.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Example\n",
    "\n",
    "When the logit link function is used the model is often referred to as a  logistic regression model (the inverse logit function is the CDF of the standard logistic distribution). As an example, here we will show how to carry out a \n",
    "analysis for Pima Indians data set similar to analysis from Chapter 5.4 of [Gelman and Hill (2007)](http://www.stat.columbia.edu/~gelman/arm/)  using `stan_glm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the model, we must first prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Pregnancies        Glucose      BloodPressure    SkinThickness  \n",
       " Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n",
       " 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n",
       " Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n",
       " Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n",
       " 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n",
       " Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n",
       "    Insulin           BMI        DiabetesPedigreeFunction      Age       \n",
       " Min.   :  0.0   Min.   : 0.00   Min.   :0.0780           Min.   :21.00  \n",
       " 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00  \n",
       " Median : 30.5   Median :32.00   Median :0.3725           Median :29.00  \n",
       " Mean   : 79.8   Mean   :31.99   Mean   :0.4719           Mean   :33.24  \n",
       " 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  \n",
       " Max.   :846.0   Max.   :67.10   Max.   :2.4200           Max.   :81.00  \n",
       "    Outcome     \n",
       " Min.   :0.000  \n",
       " 1st Qu.:0.000  \n",
       " Median :0.000  \n",
       " Mean   :0.349  \n",
       " 3rd Qu.:1.000  \n",
       " Max.   :1.000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t768 obs. of  9 variables:\n",
      " $ Pregnancies             : int  6 1 8 1 0 5 3 10 2 8 ...\n",
      " $ Glucose                 : int  148 85 183 89 137 116 78 115 197 125 ...\n",
      " $ BloodPressure           : int  72 66 64 66 40 74 50 0 70 96 ...\n",
      " $ SkinThickness           : int  35 29 0 23 35 0 32 0 45 0 ...\n",
      " $ Insulin                 : int  0 0 0 94 168 0 88 0 543 0 ...\n",
      " $ BMI                     : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ...\n",
      " $ DiabetesPedigreeFunction: num  0.627 0.351 0.672 0.167 2.288 ...\n",
      " $ Age                     : int  50 31 32 21 33 30 26 29 53 54 ...\n",
      " $ Outcome                 : int  1 0 1 0 1 0 1 0 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "# file preview shows a header row\n",
    "diabetes <- read.csv(\"data/diabetes.csv\", header = TRUE)\n",
    "\n",
    "# first look at the data set using summary() and str() to understand what type of data are you working\n",
    "# with\n",
    "summary(diabetes)\n",
    "str(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Factors** allow us to treat a given numeric and string vector as a more discrete object via 'levels', which becomes helpful when associating variables with changes in levels later. Not the change in the `data.frame` summary below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diabetes$Outcome <- factor(diabetes$Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Pregnancies        Glucose      BloodPressure    SkinThickness  \n",
       " Min.   : 0.000   Min.   :  0.0   Min.   :  0.00   Min.   : 0.00  \n",
       " 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.: 0.00  \n",
       " Median : 3.000   Median :117.0   Median : 72.00   Median :23.00  \n",
       " Mean   : 3.845   Mean   :120.9   Mean   : 69.11   Mean   :20.54  \n",
       " 3rd Qu.: 6.000   3rd Qu.:140.2   3rd Qu.: 80.00   3rd Qu.:32.00  \n",
       " Max.   :17.000   Max.   :199.0   Max.   :122.00   Max.   :99.00  \n",
       "    Insulin           BMI        DiabetesPedigreeFunction      Age       \n",
       " Min.   :  0.0   Min.   : 0.00   Min.   :0.0780           Min.   :21.00  \n",
       " 1st Qu.:  0.0   1st Qu.:27.30   1st Qu.:0.2437           1st Qu.:24.00  \n",
       " Median : 30.5   Median :32.00   Median :0.3725           Median :29.00  \n",
       " Mean   : 79.8   Mean   :31.99   Mean   :0.4719           Mean   :33.24  \n",
       " 3rd Qu.:127.2   3rd Qu.:36.60   3rd Qu.:0.6262           3rd Qu.:41.00  \n",
       " Max.   :846.0   Max.   :67.10   Max.   :2.4200           Max.   :81.00  \n",
       " Outcome\n",
       " 0:500  \n",
       " 1:268  \n",
       "        \n",
       "        \n",
       "        \n",
       "        "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t768 obs. of  9 variables:\n",
      " $ Pregnancies             : int  6 1 8 1 0 5 3 10 2 8 ...\n",
      " $ Glucose                 : int  148 85 183 89 137 116 78 115 197 125 ...\n",
      " $ BloodPressure           : int  72 66 64 66 40 74 50 0 70 96 ...\n",
      " $ SkinThickness           : int  35 29 0 23 35 0 32 0 45 0 ...\n",
      " $ Insulin                 : int  0 0 0 94 168 0 88 0 543 0 ...\n",
      " $ BMI                     : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ...\n",
      " $ DiabetesPedigreeFunction: num  0.627 0.351 0.672 0.167 2.288 ...\n",
      " $ Age                     : int  50 31 32 21 33 30 26 29 53 54 ...\n",
      " $ Outcome                 : Factor w/ 2 levels \"0\",\"1\": 2 1 2 1 2 1 2 1 2 2 ...\n"
     ]
    }
   ],
   "source": [
    "summary(diabetes)\n",
    "str(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows with zeroes will throw our model later, so lets **get rid of any rows with any 0s**. This cuts our dataset down significantly, but will save us some issues later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing those observation rows with 0 in any of the variables\n",
    "for (i in 2:6) {\n",
    "# For vector 2 to 6\n",
    "      diabetes <- diabetes[-which(diabetes[, i] == 0), ]\n",
    "    # Remove every row where the column value is 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t392 obs. of  9 variables:\n",
      " $ Pregnancies             : int  1 0 3 2 1 5 0 1 1 3 ...\n",
      " $ Glucose                 : int  89 137 78 197 189 166 118 103 115 126 ...\n",
      " $ BloodPressure           : int  66 40 50 70 60 72 84 30 70 88 ...\n",
      " $ SkinThickness           : int  23 35 32 45 23 19 47 38 30 41 ...\n",
      " $ Insulin                 : int  94 168 88 543 846 175 230 83 96 235 ...\n",
      " $ BMI                     : num  28.1 43.1 31 30.5 30.1 25.8 45.8 43.3 34.6 39.3 ...\n",
      " $ DiabetesPedigreeFunction: num  0.167 2.288 0.248 0.158 0.398 ...\n",
      " $ Age                     : int  21 33 26 53 59 51 31 33 32 27 ...\n",
      " $ Outcome                 : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 2 2 2 1 2 1 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Pregnancies        Glucose      BloodPressure    SkinThickness  \n",
       " Min.   : 0.000   Min.   : 56.0   Min.   : 24.00   Min.   : 7.00  \n",
       " 1st Qu.: 1.000   1st Qu.: 99.0   1st Qu.: 62.00   1st Qu.:21.00  \n",
       " Median : 2.000   Median :119.0   Median : 70.00   Median :29.00  \n",
       " Mean   : 3.301   Mean   :122.6   Mean   : 70.66   Mean   :29.15  \n",
       " 3rd Qu.: 5.000   3rd Qu.:143.0   3rd Qu.: 78.00   3rd Qu.:37.00  \n",
       " Max.   :17.000   Max.   :198.0   Max.   :110.00   Max.   :63.00  \n",
       "    Insulin            BMI        DiabetesPedigreeFunction      Age       \n",
       " Min.   : 14.00   Min.   :18.20   Min.   :0.0850           Min.   :21.00  \n",
       " 1st Qu.: 76.75   1st Qu.:28.40   1st Qu.:0.2697           1st Qu.:23.00  \n",
       " Median :125.50   Median :33.20   Median :0.4495           Median :27.00  \n",
       " Mean   :156.06   Mean   :33.09   Mean   :0.5230           Mean   :30.86  \n",
       " 3rd Qu.:190.00   3rd Qu.:37.10   3rd Qu.:0.6870           3rd Qu.:36.00  \n",
       " Max.   :846.00   Max.   :67.10   Max.   :2.4200           Max.   :81.00  \n",
       " Outcome\n",
       " 0:262  \n",
       " 1:130  \n",
       "        \n",
       "        \n",
       "        \n",
       "        "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(diabetes)\n",
    "summary(diabetes)\n",
    "# From 768 to 392 obs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling helps us **normalize** the data. There is amuch more helpful exploration of this phenomenon [over here](http://gastonsanchez.com/how-to/2014/01/15/Center-data-in-R/), but the short version is `scale()` quickly standardizes the data with mean zero & unit (1) variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale the covariates for easier comparison of coefficient posteriors\n",
    "for (i in 1:8) {\n",
    "      diabetes[i] <- scale(diabetes[i])\n",
    "}\n",
    "# Also seems to append the old name of the variable into it, but they still have the same references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Pregnancies.Pregnancies   Glucose.Glucose    BloodPressure.BloodPressure\n",
       " Min.   :-1.027899       Min.   :-2.1589717   Min.   :-3.734229          \n",
       " 1st Qu.:-0.716511       1st Qu.:-0.7656174   1st Qu.:-0.693278          \n",
       " Median :-0.405123       Median :-0.1175457   Median :-0.053078          \n",
       " Mean   : 0.000000       Mean   : 0.0000000   Mean   : 0.000000          \n",
       " 3rd Qu.: 0.529042       3rd Qu.: 0.6601404   3rd Qu.: 0.587122          \n",
       " Max.   : 4.265702       Max.   : 2.4423377   Max.   : 3.147923          \n",
       " SkinThickness.SkinThickness   Insulin.Insulin         BMI.BMI      \n",
       " Min.   :-2.105793           Min.   :-1.195339   Min.   :-2.118234  \n",
       " 1st Qu.:-0.774542           1st Qu.:-0.667326   1st Qu.:-0.666826  \n",
       " Median :-0.013827           Median :-0.257116   Median : 0.016190  \n",
       " Mean   : 0.000000           Mean   : 0.000000   Mean   : 0.000000  \n",
       " 3rd Qu.: 0.746888           3rd Qu.: 0.285623   3rd Qu.: 0.571140  \n",
       " Max.   : 3.219211           Max.   : 5.805571   Max.   : 4.839986  \n",
       " DiabetesPedigreeFunction.DiabetesPedigreeFunction       Age.Age       Outcome\n",
       " Min.   :-1.267905                                 Min.   :-0.967063   0:262  \n",
       " 1st Qu.:-0.733154                                 1st Qu.:-0.771000   1:130  \n",
       " Median :-0.212875                                 Median :-0.378873          \n",
       " Mean   : 0.000000                                 Mean   : 0.000000          \n",
       " 3rd Qu.: 0.474558                                 3rd Qu.: 0.503413          \n",
       " Max.   : 5.490650                                 Max.   : 4.914842          "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(diabetes)\n",
    "# Not how the min, max, and other values now reflet much smaller numbers that are generally standardized \n",
    "# The string names seem different, but diabetes$pregnancies is still totally valid. Not sure why the strings have\n",
    "# changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets **rename** The `DiabetesPedigreeFunction.DiabetesPedigreeFunction` to something a little easier, and make all of our names lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modify the data column names slightly for easier typing\n",
    "names(diabetes)[7] <- \"dpf\"\n",
    "names(diabetes) <- tolower(names(diabetes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " pregnancies.Pregnancies   glucose.Glucose    bloodpressure.BloodPressure\n",
       " Min.   :-1.027899       Min.   :-2.1589717   Min.   :-3.734229          \n",
       " 1st Qu.:-0.716511       1st Qu.:-0.7656174   1st Qu.:-0.693278          \n",
       " Median :-0.405123       Median :-0.1175457   Median :-0.053078          \n",
       " Mean   : 0.000000       Mean   : 0.0000000   Mean   : 0.000000          \n",
       " 3rd Qu.: 0.529042       3rd Qu.: 0.6601404   3rd Qu.: 0.587122          \n",
       " Max.   : 4.265702       Max.   : 2.4423377   Max.   : 3.147923          \n",
       " skinthickness.SkinThickness   insulin.Insulin         bmi.BMI      \n",
       " Min.   :-2.105793           Min.   :-1.195339   Min.   :-2.118234  \n",
       " 1st Qu.:-0.774542           1st Qu.:-0.667326   1st Qu.:-0.666826  \n",
       " Median :-0.013827           Median :-0.257116   Median : 0.016190  \n",
       " Mean   : 0.000000           Mean   : 0.000000   Mean   : 0.000000  \n",
       " 3rd Qu.: 0.746888           3rd Qu.: 0.285623   3rd Qu.: 0.571140  \n",
       " Max.   : 3.219211           Max.   : 5.805571   Max.   : 4.839986  \n",
       " dpf.DiabetesPedigreeFunction       age.Age       outcome\n",
       " Min.   :-1.267905            Min.   :-0.967063   0:262  \n",
       " 1st Qu.:-0.733154            1st Qu.:-0.771000   1:130  \n",
       " Median :-0.212875            Median :-0.378873          \n",
       " Mean   : 0.000000            Mean   : 0.000000          \n",
       " 3rd Qu.: 0.474558            3rd Qu.: 0.503413          \n",
       " Max.   : 5.490650            Max.   : 4.914842          "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is deciding our **input** variables for the model.\n",
    "\n",
    "R has an object called a `model.matrix` which is conveniently designed to hold all these model variables. It takes regression notation, so our task of regressing `outcome` against every other variable is noted: `outcome ~ . -1`. \n",
    "\n",
    "That last bit is nomenclature, we use `.` to denote **every available column**, and the `-1` to state that we don't want the **intercept vector** to count as an input variable; it will be generated as part of the `glm`. Here's what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pregnancies</th><th scope=col>glucose</th><th scope=col>bloodpressure</th><th scope=col>skinthickness</th><th scope=col>insulin</th><th scope=col>bmi</th><th scope=col>dpf</th><th scope=col>age</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4</th><td>-0.716510831731856</td><td>-1.08965328588737 </td><td>-0.373177907818495</td><td>-0.584362921139607</td><td>-0.522174689475281</td><td>-0.709514269939694</td><td>-1.03055930843226 </td><td>-0.967063231434636</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-1.02789913110978</td><td>0.465718905529468</td><td>-2.45382847482402</td><td>0.556709383152926</td><td>0.100502421118279</td><td>1.42490909404547 </td><td>5.10858224726345 </td><td>0.209317797959863</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>-0.0937342329760078</td><td>-1.4460927464204   </td><td>-1.65357825674497  </td><td>0.271441307079793  </td><td>-0.57266202276665  </td><td>-0.296859086235896 </td><td>-0.796108357931857 </td><td>-0.476904469186928 </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>-0.405122532353932 </td><td>2.40993414480051   </td><td>-0.0530778205868761</td><td>1.50760297006337   </td><td>3.25596075182889   </td><td>-0.368006531702068 </td><td>-1.05660941404341  </td><td>2.1699528469507    </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>-0.716510831731856</td><td>2.15070544623104  </td><td>-0.853328038665924</td><td>-0.584362921139607</td><td>5.80557108304306  </td><td>-0.424924488075005</td><td>-0.361939931079261</td><td>2.75814336164795  </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0.529042365779841 </td><td>1.40542293784381  </td><td>0.106972223028934 </td><td>-0.964720355903785</td><td>0.159404309958211 </td><td>-1.03679251908409 </td><td>0.18511228675501  </td><td>1.97388934205161  </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>-1.02789913110978 </td><td>-0.149949253573031</td><td>1.06727248472379  </td><td>1.69778168744546  </td><td>0.6222048651291   </td><td>1.8091052995628   </td><td>0.080911864310387 </td><td>0.01325429306078  </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>-0.716510831731856</td><td>-0.636003063390792</td><td>-3.25407869290307 </td><td>0.84197745922606  </td><td>-0.614734800509459</td><td>1.45336807223194  </td><td>-0.984248009567981</td><td>0.209317797959863 </td></tr>\n",
       "\t<tr><th scope=row>20</th><td>-0.716510831731856 </td><td>-0.247160015536583 </td><td>-0.0530778205868761</td><td>0.0812625896977039 </td><td>-0.505345578378157 </td><td>0.215402521120544  </td><td>0.0172338283720062 </td><td>0.111286045510322  </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>-0.0937342329760078</td><td>0.109279444996442  </td><td>1.38737257195541   </td><td>1.12724553529919   </td><td>0.664277642871908  </td><td>0.884188508502561  </td><td>0.523763659700034  </td><td>-0.378872716737387 </td></tr>\n",
       "\t<tr><th scope=row>25</th><td>2.39737216204739   </td><td>0.660140429456572  </td><td>1.86752270280284   </td><td>0.366530665770837  </td><td>-0.0846178009500762</td><td>0.499992302985233  </td><td>-0.778741620857753 </td><td>1.97388934205161   </td></tr>\n",
       "\t<tr><th scope=row>26</th><td>2.08598386266946   </td><td>0.0768758576752583 </td><td>-0.0530778205868761</td><td>-0.299094845066474 </td><td>-0.345469022955487 </td><td>-0.282629597142661 </td><td>-0.920569973629601 </td><td>0.993571817556197  </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>-0.716510831731856</td><td>-0.830424587317897</td><td>-0.373177907818495</td><td>-1.34507779066796 </td><td>-0.135105134241446</td><td>-1.40675923550818 </td><td>-0.104333331146721</td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>3.02014876080323  </td><td>0.724947604098941 </td><td>0.907222441107981 </td><td>-0.964720355903785</td><td>-0.387541800698295</td><td>-1.54905412644053 </td><td>-0.804791726468909</td><td>2.56207985674886  </td></tr>\n",
       "\t<tr><th scope=row>32</th><td>-0.0937342329760078</td><td>1.14619423927433   </td><td>0.427072310260553  </td><td>0.651798741843971  </td><td>0.748423198357524  </td><td>-0.211482151676489 </td><td>0.949248718015578  </td><td>-0.280840964287845 </td></tr>\n",
       "\t<tr><th scope=row>33</th><td>-0.0937342329760078</td><td>-1.12205687320855  </td><td>-1.01337808228173  </td><td>-1.72543522543214  </td><td>-0.858756911417746 </td><td>-1.17908741001643  </td><td>-0.741113690530528 </td><td>-0.869031478985095 </td></tr>\n",
       "\t<tr><th scope=row>36</th><td>0.217654066401916 </td><td>-0.636003063390792</td><td>-0.853328038665924</td><td>0.366530665770837 </td><td>0.302451754283758 </td><td>-1.29292332276231 </td><td>1.28211117860257  </td><td>0.209317797959863 </td></tr>\n",
       "\t<tr><th scope=row>40</th><td>0.217654066401916 </td><td>-0.376774364821319</td><td>0.106972223028934 </td><td>1.69778168744546  </td><td>0.428670087512183 </td><td>0.571139748451405 </td><td>2.50936059850591  </td><td>2.46404810429932  </td></tr>\n",
       "\t<tr><th scope=row>41</th><td>-0.0937342329760078</td><td>1.85907316034038   </td><td>-0.533227951434305 </td><td>-0.394184203757518 </td><td>-0.72412402264076  </td><td>0.130025586561137  </td><td>-0.729535865814459 </td><td>-0.476904469186928 </td></tr>\n",
       "\t<tr><th scope=row>44</th><td>1.77459556329154  </td><td>1.56744087444973  </td><td>3.14792305172932  </td><td>-0.489273562448563</td><td>0.706350420614716 </td><td>1.75218734318986  </td><td>0.572969414743329 </td><td>2.26798459940024  </td></tr>\n",
       "\t<tr><th scope=row>51</th><td>-0.716510831731856 </td><td>-0.636003063390792 </td><td>0.747172397492172  </td><td>-1.72543522543214  </td><td>-0.62314935605802  </td><td>-1.94747982105109  </td><td>-0.0927555064306515</td><td>-0.869031478985095 </td></tr>\n",
       "\t<tr><th scope=row>52</th><td>-0.716510831731856 </td><td>-0.700810238033161 </td><td>-1.65357825674497  </td><td>-1.34507779066796  </td><td>-1.01021891129185  </td><td>-1.26446434457584  </td><td>0.00855045983495428</td><td>-0.476904469186928 </td></tr>\n",
       "\t<tr><th scope=row>53</th><td>0.529042365779841  </td><td>-1.12205687320855  </td><td>-0.373177907818495 </td><td>-0.774541638521696 </td><td>-1.11960813342316  </td><td>-1.23600536638937  </td><td>-0.52402947710423  </td><td>-0.0847774593887617</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>1.46320726391361  </td><td>1.72945881105565  </td><td>1.54742261557122  </td><td>0.461620024461882 </td><td>1.21122375352841  </td><td>0.0873371192814343</td><td>-0.162222454727067</td><td>2.6601116091984   </td></tr>\n",
       "\t<tr><th scope=row>55</th><td>1.15181896453569  </td><td>0.886965540704861 </td><td>-0.373177907818495</td><td>1.22233489399024  </td><td>1.564635086568    </td><td>0.229632010213779 </td><td>0.564286046206277 </td><td>1.09160357000574  </td></tr>\n",
       "\t<tr><th scope=row>57</th><td>1.15181896453569  </td><td>2.08589827158867  </td><td>-0.213127864202686</td><td>0.937066817917104 </td><td>1.24488197572266  </td><td>0.656516683010811 </td><td>-0.778741620857753</td><td>0.993571817556197 </td></tr>\n",
       "\t<tr><th scope=row>58</th><td>-1.02789913110978 </td><td>-0.733213825354345</td><td>1.38737257195541  </td><td>2.93394335042904  </td><td>-0.387541800698295</td><td>1.95140019049514  </td><td>1.2705333538865   </td><td>0.01325429306078  </td></tr>\n",
       "\t<tr><th scope=row>60</th><td>-1.02789913110978 </td><td>-0.571195888748424</td><td>-0.533227951434305</td><td>1.12724553529919  </td><td>-0.118276023144323</td><td>1.19723726855372  </td><td>-1.01319257135815 </td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>64</th><td>-0.405122532353932</td><td>0.595333254814204 </td><td>-1.01337808228173 </td><td>0.461620024461882 </td><td>-0.236079800824185</td><td>-1.09371047545702 </td><td>0.509291378804948 </td><td>-0.672967974086012</td></tr>\n",
       "\t<tr><th scope=row>69</th><td>-0.716510831731856</td><td>-0.895231761960265</td><td>-0.373177907818495</td><td>-1.53525650805005 </td><td>-0.993389800194732</td><td>-1.91902084286462 </td><td>-0.547185126536368</td><td>-0.57493622163647 </td></tr>\n",
       "\t<tr><th scope=row></th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>708</th><td>-0.405122532353932</td><td>0.141683032317627 </td><td>-1.97367834397659 </td><td>-0.774541638521696</td><td>1.50573319772807  </td><td>0.186943542934075 </td><td>-1.0045092028211  </td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>710</th><td>-0.405122532353932</td><td>-0.960038936602634</td><td>-0.533227951434305</td><td>0.271441307079793 </td><td>0.0331859767297865</td><td>0.699205150290514 </td><td>0.436929974329515 </td><td>-0.770999726535553</td></tr>\n",
       "\t<tr><th scope=row>711</th><td>-0.0937342329760078</td><td>1.14619423927433   </td><td>-0.533227951434305 </td><td>-1.53525650805005  </td><td>1.94329008625327   </td><td>-0.268400108049427 </td><td>-0.660068917518043 </td><td>-0.672967974086012 </td></tr>\n",
       "\t<tr><th scope=row>712</th><td>0.529042365779841 </td><td>0.109279444996442 </td><td>0.587122353876362 </td><td>-0.204005486375429</td><td>-1.12802268897172 </td><td>-0.496071933541177</td><td>-0.243267227739551</td><td>0.895540065106655 </td></tr>\n",
       "\t<tr><th scope=row>714</th><td>-1.02789913110978 </td><td>0.368508143565915 </td><td>-1.01337808228173 </td><td>-0.869630997212741</td><td>1.13549275359136  </td><td>-0.951415584524679</td><td>-0.495084915314057</td><td>-0.967063231434636</td></tr>\n",
       "\t<tr><th scope=row>716</th><td>1.15181896453569 </td><td>2.08589827158867 </td><td>-1.65357825674497</td><td>0.366530665770837</td><td>1.98536286399608 </td><td>0.115796097467903</td><td>0.876887313540146</td><td>0.307349550409405</td></tr>\n",
       "\t<tr><th scope=row>717</th><td>-0.0937342329760078</td><td>1.6322480490921    </td><td>0.587122353876362  </td><td>0.937066817917104  </td><td>0.243549865443827  </td><td>0.101566608374668  </td><td>1.29368900331864   </td><td>0.01325429306078   </td></tr>\n",
       "\t<tr><th scope=row>719</th><td>-0.716510831731856</td><td>-0.473985126784872</td><td>-0.853328038665924</td><td>1.60269232875442  </td><td>0.184647976603896 </td><td>0.343467922959654 </td><td>-0.312734176035967</td><td>-0.672967974086012</td></tr>\n",
       "\t<tr><th scope=row>722</th><td>-0.716510831731856</td><td>-0.279563602857767</td><td>-0.373177907818495</td><td>0.651798741843971 </td><td>0.369768198672251 </td><td>0.713434639383749 </td><td>-0.677435654592147</td><td>-0.967063231434636</td></tr>\n",
       "\t<tr><th scope=row>723</th><td>-0.716510831731856 </td><td>0.854561953383677  </td><td>-0.213127864202686 </td><td>-0.0138267689933405</td><td>-0.244494356372747 </td><td>-0.538760400820881 </td><td>-0.503768283851109 </td><td>1.09160357000574   </td></tr>\n",
       "\t<tr><th scope=row>724</th><td>0.529042365779841 </td><td>-0.182352840894215</td><td>1.2273225283396   </td><td>0.0812625896977039</td><td>-0.429614578441103</td><td>0.855729530316093 </td><td>-0.787424989394805</td><td>1.09160357000574  </td></tr>\n",
       "\t<tr><th scope=row>727</th><td>-0.716510831731856 </td><td>-0.214756428215399 </td><td>0.587122353876362  </td><td>-0.0138267689933405</td><td>0.201477087701019  </td><td>0.42884485751906   </td><td>-0.078283225535565 </td><td>-0.57493622163647  </td></tr>\n",
       "\t<tr><th scope=row>731</th><td>-0.0937342329760078</td><td>0.238893794281179  </td><td>0.587122353876362  </td><td>-0.584362921139607 </td><td>-0.648393022703705 </td><td>-0.666825802659991 </td><td>-0.579024144505559 </td><td>0.307349550409405  </td></tr>\n",
       "\t<tr><th scope=row>733</th><td>-0.405122532353932</td><td>1.66465163641328  </td><td>1.38737257195541  </td><td>0.746888100535015 </td><td>-0.303396245212678</td><td>1.62412194135075  </td><td>0.355885201317031 </td><td>-0.672967974086012</td></tr>\n",
       "\t<tr><th scope=row>734</th><td>-0.405122532353932</td><td>-0.53879230142724 </td><td>-1.17342812589754 </td><td>-0.204005486375429</td><td>0.0752587544725946</td><td>-0.581448868100584</td><td>-0.280895158066776</td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>737</th><td>-1.02789913110978  </td><td>0.109279444996442  </td><td>1.2273225283396    </td><td>-0.204005486375429 </td><td>-0.303396245212678 </td><td>-0.809120693592335 </td><td>-0.0232885581342361</td><td>-0.967063231434636 </td></tr>\n",
       "\t<tr><th scope=row>739</th><td>-0.405122532353932</td><td>-0.765617412675529</td><td>-0.853328038665924</td><td>-1.15489907328587 </td><td>0.0331859767297865</td><td>0.499992302985233 </td><td>-0.202744841233309</td><td>-0.967063231434636</td></tr>\n",
       "\t<tr><th scope=row>741</th><td>2.39737216204739   </td><td>-0.0851420789306623</td><td>0.747172397492172  </td><td>0.746888100535015  </td><td>-0.0509595787558297</td><td>1.31107318129959   </td><td>0.758214610200436  </td><td>1.67979408470299   </td></tr>\n",
       "\t<tr><th scope=row>742</th><td>-0.0937342329760078</td><td>-0.668406650711977 </td><td>-2.1337283875924   </td><td>-0.869630997212741 </td><td>-0.522174689475281 </td><td>-0.325318064422364 </td><td>-0.356151018721226 </td><td>-0.476904469186928 </td></tr>\n",
       "\t<tr><th scope=row>743</th><td>-0.716510831731856</td><td>-0.441581539463688</td><td>-1.01337808228173 </td><td>-1.05980971459483 </td><td>-0.337054467406925</td><td>-0.652596313566756</td><td>-0.880047587123359</td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>745</th><td>3.02014876080323  </td><td>0.984176302668414 </td><td>1.38737257195541  </td><td>0.746888100535015 </td><td>-0.135105134241446</td><td>1.06917186671461  </td><td>1.88415806383817  </td><td>0.797508312657113 </td></tr>\n",
       "\t<tr><th scope=row>746</th><td>2.70876046142531  </td><td>-0.733213825354345</td><td>1.06727248472379  </td><td>0.366530665770837 </td><td>-0.429614578441103</td><td>-0.43915397716824 </td><td>-0.101438874967703</td><td>1.4837305798039   </td></tr>\n",
       "\t<tr><th scope=row>748</th><td>-0.716510831731856</td><td>-1.34888198445684 </td><td>0.267022266644743 </td><td>1.12724553529919  </td><td>-0.833513244772061</td><td>1.88025274502897  </td><td>1.65839048187482  </td><td>0.111286045510322 </td></tr>\n",
       "\t<tr><th scope=row>749</th><td>-0.0937342329760078</td><td>2.08589827158867   </td><td>-0.0530778205868761</td><td>-0.679452279830652 </td><td>0.369768198672251  </td><td>0.471533324798763  </td><td>-0.332995369289088 </td><td>0.503413055308488  </td></tr>\n",
       "\t<tr><th scope=row>752</th><td>-0.716510831731856 </td><td>-0.0527384916094782</td><td>0.587122353876362  </td><td>0.937066817917104  </td><td>-0.690465800446513 </td><td>0.841500041222858  </td><td>-0.758480427604632 </td><td>-0.280840964287845 </td></tr>\n",
       "\t<tr><th scope=row>754</th><td>-1.02789913110978 </td><td>1.89147674766157  </td><td>1.38737257195541  </td><td>1.41251361137233  </td><td>2.97828041872635  </td><td>1.45336807223194  </td><td>-0.871364218586307</td><td>-0.476904469186928</td></tr>\n",
       "\t<tr><th scope=row>756</th><td>-0.716510831731856</td><td>0.174086619638811 </td><td>1.38737257195541  </td><td>0.937066817917104 </td><td>-0.387541800698295</td><td>0.485762813891998 </td><td>1.54550669089314  </td><td>0.60144480775803  </td></tr>\n",
       "\t<tr><th scope=row>761</th><td>-0.405122532353932</td><td>-1.12205687320855 </td><td>-1.01337808228173 </td><td>-0.299094845066474</td><td>-1.17851002226309 </td><td>-0.666825802659991</td><td>0.703219942799107 </td><td>-0.869031478985095</td></tr>\n",
       "\t<tr><th scope=row>764</th><td>2.08598386266946   </td><td>-0.700810238033161 </td><td>0.427072310260553  </td><td>1.7928710461365    </td><td>0.201477087701019  </td><td>-0.0264987934644417</td><td>-1.01898148371619  </td><td>3.15027037144611   </td></tr>\n",
       "\t<tr><th scope=row>766</th><td>0.529042365779841  </td><td>-0.0527384916094782</td><td>0.106972223028934  </td><td>-0.584362921139607 </td><td>-0.370712689601171 </td><td>-0.979874562711148 </td><td>-0.804791726468909 </td><td>-0.0847774593887617</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       "  & pregnancies & glucose & bloodpressure & skinthickness & insulin & bmi & dpf & age\\\\\n",
       "\\hline\n",
       "\t4 & -0.716510831731856 & -1.08965328588737  & -0.373177907818495 & -0.584362921139607 & -0.522174689475281 & -0.709514269939694 & -1.03055930843226  & -0.967063231434636\\\\\n",
       "\t5 & -1.02789913110978 & 0.465718905529468 & -2.45382847482402 & 0.556709383152926 & 0.100502421118279 & 1.42490909404547  & 5.10858224726345  & 0.209317797959863\\\\\n",
       "\t7 & -0.0937342329760078 & -1.4460927464204    & -1.65357825674497   & 0.271441307079793   & -0.57266202276665   & -0.296859086235896  & -0.796108357931857  & -0.476904469186928 \\\\\n",
       "\t9 & -0.405122532353932  & 2.40993414480051    & -0.0530778205868761 & 1.50760297006337    & 3.25596075182889    & -0.368006531702068  & -1.05660941404341   & 2.1699528469507    \\\\\n",
       "\t14 & -0.716510831731856 & 2.15070544623104   & -0.853328038665924 & -0.584362921139607 & 5.80557108304306   & -0.424924488075005 & -0.361939931079261 & 2.75814336164795  \\\\\n",
       "\t15 & 0.529042365779841  & 1.40542293784381   & 0.106972223028934  & -0.964720355903785 & 0.159404309958211  & -1.03679251908409  & 0.18511228675501   & 1.97388934205161  \\\\\n",
       "\t17 & -1.02789913110978  & -0.149949253573031 & 1.06727248472379   & 1.69778168744546   & 0.6222048651291    & 1.8091052995628    & 0.080911864310387  & 0.01325429306078  \\\\\n",
       "\t19 & -0.716510831731856 & -0.636003063390792 & -3.25407869290307  & 0.84197745922606   & -0.614734800509459 & 1.45336807223194   & -0.984248009567981 & 0.209317797959863 \\\\\n",
       "\t20 & -0.716510831731856  & -0.247160015536583  & -0.0530778205868761 & 0.0812625896977039  & -0.505345578378157  & 0.215402521120544   & 0.0172338283720062  & 0.111286045510322  \\\\\n",
       "\t21 & -0.0937342329760078 & 0.109279444996442   & 1.38737257195541    & 1.12724553529919    & 0.664277642871908   & 0.884188508502561   & 0.523763659700034   & -0.378872716737387 \\\\\n",
       "\t25 & 2.39737216204739    & 0.660140429456572   & 1.86752270280284    & 0.366530665770837   & -0.0846178009500762 & 0.499992302985233   & -0.778741620857753  & 1.97388934205161   \\\\\n",
       "\t26 & 2.08598386266946    & 0.0768758576752583  & -0.0530778205868761 & -0.299094845066474  & -0.345469022955487  & -0.282629597142661  & -0.920569973629601  & 0.993571817556197  \\\\\n",
       "\t28 & -0.716510831731856 & -0.830424587317897 & -0.373177907818495 & -1.34507779066796  & -0.135105134241446 & -1.40675923550818  & -0.104333331146721 & -0.869031478985095\\\\\n",
       "\t29 & 3.02014876080323   & 0.724947604098941  & 0.907222441107981  & -0.964720355903785 & -0.387541800698295 & -1.54905412644053  & -0.804791726468909 & 2.56207985674886  \\\\\n",
       "\t32 & -0.0937342329760078 & 1.14619423927433    & 0.427072310260553   & 0.651798741843971   & 0.748423198357524   & -0.211482151676489  & 0.949248718015578   & -0.280840964287845 \\\\\n",
       "\t33 & -0.0937342329760078 & -1.12205687320855   & -1.01337808228173   & -1.72543522543214   & -0.858756911417746  & -1.17908741001643   & -0.741113690530528  & -0.869031478985095 \\\\\n",
       "\t36 & 0.217654066401916  & -0.636003063390792 & -0.853328038665924 & 0.366530665770837  & 0.302451754283758  & -1.29292332276231  & 1.28211117860257   & 0.209317797959863 \\\\\n",
       "\t40 & 0.217654066401916  & -0.376774364821319 & 0.106972223028934  & 1.69778168744546   & 0.428670087512183  & 0.571139748451405  & 2.50936059850591   & 2.46404810429932  \\\\\n",
       "\t41 & -0.0937342329760078 & 1.85907316034038    & -0.533227951434305  & -0.394184203757518  & -0.72412402264076   & 0.130025586561137   & -0.729535865814459  & -0.476904469186928 \\\\\n",
       "\t44 & 1.77459556329154   & 1.56744087444973   & 3.14792305172932   & -0.489273562448563 & 0.706350420614716  & 1.75218734318986   & 0.572969414743329  & 2.26798459940024  \\\\\n",
       "\t51 & -0.716510831731856  & -0.636003063390792  & 0.747172397492172   & -1.72543522543214   & -0.62314935605802   & -1.94747982105109   & -0.0927555064306515 & -0.869031478985095 \\\\\n",
       "\t52 & -0.716510831731856  & -0.700810238033161  & -1.65357825674497   & -1.34507779066796   & -1.01021891129185   & -1.26446434457584   & 0.00855045983495428 & -0.476904469186928 \\\\\n",
       "\t53 & 0.529042365779841   & -1.12205687320855   & -0.373177907818495  & -0.774541638521696  & -1.11960813342316   & -1.23600536638937   & -0.52402947710423   & -0.0847774593887617\\\\\n",
       "\t54 & 1.46320726391361   & 1.72945881105565   & 1.54742261557122   & 0.461620024461882  & 1.21122375352841   & 0.0873371192814343 & -0.162222454727067 & 2.6601116091984   \\\\\n",
       "\t55 & 1.15181896453569   & 0.886965540704861  & -0.373177907818495 & 1.22233489399024   & 1.564635086568     & 0.229632010213779  & 0.564286046206277  & 1.09160357000574  \\\\\n",
       "\t57 & 1.15181896453569   & 2.08589827158867   & -0.213127864202686 & 0.937066817917104  & 1.24488197572266   & 0.656516683010811  & -0.778741620857753 & 0.993571817556197 \\\\\n",
       "\t58 & -1.02789913110978  & -0.733213825354345 & 1.38737257195541   & 2.93394335042904   & -0.387541800698295 & 1.95140019049514   & 1.2705333538865    & 0.01325429306078  \\\\\n",
       "\t60 & -1.02789913110978  & -0.571195888748424 & -0.533227951434305 & 1.12724553529919   & -0.118276023144323 & 1.19723726855372   & -1.01319257135815  & -0.869031478985095\\\\\n",
       "\t64 & -0.405122532353932 & 0.595333254814204  & -1.01337808228173  & 0.461620024461882  & -0.236079800824185 & -1.09371047545702  & 0.509291378804948  & -0.672967974086012\\\\\n",
       "\t69 & -0.716510831731856 & -0.895231761960265 & -0.373177907818495 & -1.53525650805005  & -0.993389800194732 & -1.91902084286462  & -0.547185126536368 & -0.57493622163647 \\\\\n",
       "\t & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t708 & -0.405122532353932 & 0.141683032317627  & -1.97367834397659  & -0.774541638521696 & 1.50573319772807   & 0.186943542934075  & -1.0045092028211   & -0.869031478985095\\\\\n",
       "\t710 & -0.405122532353932 & -0.960038936602634 & -0.533227951434305 & 0.271441307079793  & 0.0331859767297865 & 0.699205150290514  & 0.436929974329515  & -0.770999726535553\\\\\n",
       "\t711 & -0.0937342329760078 & 1.14619423927433    & -0.533227951434305  & -1.53525650805005   & 1.94329008625327    & -0.268400108049427  & -0.660068917518043  & -0.672967974086012 \\\\\n",
       "\t712 & 0.529042365779841  & 0.109279444996442  & 0.587122353876362  & -0.204005486375429 & -1.12802268897172  & -0.496071933541177 & -0.243267227739551 & 0.895540065106655 \\\\\n",
       "\t714 & -1.02789913110978  & 0.368508143565915  & -1.01337808228173  & -0.869630997212741 & 1.13549275359136   & -0.951415584524679 & -0.495084915314057 & -0.967063231434636\\\\\n",
       "\t716 & 1.15181896453569  & 2.08589827158867  & -1.65357825674497 & 0.366530665770837 & 1.98536286399608  & 0.115796097467903 & 0.876887313540146 & 0.307349550409405\\\\\n",
       "\t717 & -0.0937342329760078 & 1.6322480490921     & 0.587122353876362   & 0.937066817917104   & 0.243549865443827   & 0.101566608374668   & 1.29368900331864    & 0.01325429306078   \\\\\n",
       "\t719 & -0.716510831731856 & -0.473985126784872 & -0.853328038665924 & 1.60269232875442   & 0.184647976603896  & 0.343467922959654  & -0.312734176035967 & -0.672967974086012\\\\\n",
       "\t722 & -0.716510831731856 & -0.279563602857767 & -0.373177907818495 & 0.651798741843971  & 0.369768198672251  & 0.713434639383749  & -0.677435654592147 & -0.967063231434636\\\\\n",
       "\t723 & -0.716510831731856  & 0.854561953383677   & -0.213127864202686  & -0.0138267689933405 & -0.244494356372747  & -0.538760400820881  & -0.503768283851109  & 1.09160357000574   \\\\\n",
       "\t724 & 0.529042365779841  & -0.182352840894215 & 1.2273225283396    & 0.0812625896977039 & -0.429614578441103 & 0.855729530316093  & -0.787424989394805 & 1.09160357000574  \\\\\n",
       "\t727 & -0.716510831731856  & -0.214756428215399  & 0.587122353876362   & -0.0138267689933405 & 0.201477087701019   & 0.42884485751906    & -0.078283225535565  & -0.57493622163647  \\\\\n",
       "\t731 & -0.0937342329760078 & 0.238893794281179   & 0.587122353876362   & -0.584362921139607  & -0.648393022703705  & -0.666825802659991  & -0.579024144505559  & 0.307349550409405  \\\\\n",
       "\t733 & -0.405122532353932 & 1.66465163641328   & 1.38737257195541   & 0.746888100535015  & -0.303396245212678 & 1.62412194135075   & 0.355885201317031  & -0.672967974086012\\\\\n",
       "\t734 & -0.405122532353932 & -0.53879230142724  & -1.17342812589754  & -0.204005486375429 & 0.0752587544725946 & -0.581448868100584 & -0.280895158066776 & -0.869031478985095\\\\\n",
       "\t737 & -1.02789913110978   & 0.109279444996442   & 1.2273225283396     & -0.204005486375429  & -0.303396245212678  & -0.809120693592335  & -0.0232885581342361 & -0.967063231434636 \\\\\n",
       "\t739 & -0.405122532353932 & -0.765617412675529 & -0.853328038665924 & -1.15489907328587  & 0.0331859767297865 & 0.499992302985233  & -0.202744841233309 & -0.967063231434636\\\\\n",
       "\t741 & 2.39737216204739    & -0.0851420789306623 & 0.747172397492172   & 0.746888100535015   & -0.0509595787558297 & 1.31107318129959    & 0.758214610200436   & 1.67979408470299   \\\\\n",
       "\t742 & -0.0937342329760078 & -0.668406650711977  & -2.1337283875924    & -0.869630997212741  & -0.522174689475281  & -0.325318064422364  & -0.356151018721226  & -0.476904469186928 \\\\\n",
       "\t743 & -0.716510831731856 & -0.441581539463688 & -1.01337808228173  & -1.05980971459483  & -0.337054467406925 & -0.652596313566756 & -0.880047587123359 & -0.869031478985095\\\\\n",
       "\t745 & 3.02014876080323   & 0.984176302668414  & 1.38737257195541   & 0.746888100535015  & -0.135105134241446 & 1.06917186671461   & 1.88415806383817   & 0.797508312657113 \\\\\n",
       "\t746 & 2.70876046142531   & -0.733213825354345 & 1.06727248472379   & 0.366530665770837  & -0.429614578441103 & -0.43915397716824  & -0.101438874967703 & 1.4837305798039   \\\\\n",
       "\t748 & -0.716510831731856 & -1.34888198445684  & 0.267022266644743  & 1.12724553529919   & -0.833513244772061 & 1.88025274502897   & 1.65839048187482   & 0.111286045510322 \\\\\n",
       "\t749 & -0.0937342329760078 & 2.08589827158867    & -0.0530778205868761 & -0.679452279830652  & 0.369768198672251   & 0.471533324798763   & -0.332995369289088  & 0.503413055308488  \\\\\n",
       "\t752 & -0.716510831731856  & -0.0527384916094782 & 0.587122353876362   & 0.937066817917104   & -0.690465800446513  & 0.841500041222858   & -0.758480427604632  & -0.280840964287845 \\\\\n",
       "\t754 & -1.02789913110978  & 1.89147674766157   & 1.38737257195541   & 1.41251361137233   & 2.97828041872635   & 1.45336807223194   & -0.871364218586307 & -0.476904469186928\\\\\n",
       "\t756 & -0.716510831731856 & 0.174086619638811  & 1.38737257195541   & 0.937066817917104  & -0.387541800698295 & 0.485762813891998  & 1.54550669089314   & 0.60144480775803  \\\\\n",
       "\t761 & -0.405122532353932 & -1.12205687320855  & -1.01337808228173  & -0.299094845066474 & -1.17851002226309  & -0.666825802659991 & 0.703219942799107  & -0.869031478985095\\\\\n",
       "\t764 & 2.08598386266946    & -0.700810238033161  & 0.427072310260553   & 1.7928710461365     & 0.201477087701019   & -0.0264987934644417 & -1.01898148371619   & 3.15027037144611   \\\\\n",
       "\t766 & 0.529042365779841   & -0.0527384916094782 & 0.106972223028934   & -0.584362921139607  & -0.370712689601171  & -0.979874562711148  & -0.804791726468909  & -0.0847774593887617\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -0.716510831731856\n",
       "2. -1.02789913110978\n",
       "3. -0.0937342329760078\n",
       "4. -0.405122532353932\n",
       "5. -0.716510831731856\n",
       "6. 0.529042365779841\n",
       "7. -1.02789913110978\n",
       "8. -0.716510831731856\n",
       "9. -0.716510831731856\n",
       "10. -0.0937342329760078\n",
       "11. 2.39737216204739\n",
       "12. 2.08598386266946\n",
       "13. -0.716510831731856\n",
       "14. 3.02014876080323\n",
       "15. -0.0937342329760078\n",
       "16. -0.0937342329760078\n",
       "17. 0.217654066401916\n",
       "18. 0.217654066401916\n",
       "19. -0.0937342329760078\n",
       "20. 1.77459556329154\n",
       "21. -0.716510831731856\n",
       "22. -0.716510831731856\n",
       "23. 0.529042365779841\n",
       "24. 1.46320726391361\n",
       "25. 1.15181896453569\n",
       "26. 1.15181896453569\n",
       "27. -1.02789913110978\n",
       "28. -1.02789913110978\n",
       "29. -0.405122532353932\n",
       "30. -0.716510831731856\n",
       "31. 0.217654066401916\n",
       "32. -0.405122532353932\n",
       "33. 0.529042365779841\n",
       "34. 0.217654066401916\n",
       "35. 1.15181896453569\n",
       "36. -0.405122532353932\n",
       "37. -0.405122532353932\n",
       "38. 3.64292535955908\n",
       "39. 0.217654066401916\n",
       "40. 1.15181896453569\n",
       "41. -0.405122532353932\n",
       "42. 0.840430665157765\n",
       "43. -0.716510831731856\n",
       "44. 0.840430665157765\n",
       "45. -0.716510831731856\n",
       "46. -0.716510831731856\n",
       "47. -0.716510831731856\n",
       "48. 0.217654066401916\n",
       "49. -0.0937342329760078\n",
       "50. -1.02789913110978\n",
       "51. -0.0937342329760078\n",
       "52. 1.46320726391361\n",
       "53. -0.716510831731856\n",
       "54. 1.15181896453569\n",
       "55. 0.217654066401916\n",
       "56. -1.02789913110978\n",
       "57. -0.405122532353932\n",
       "58. -0.716510831731856\n",
       "59. -0.0937342329760078\n",
       "60. -0.716510831731856\n",
       "61. -0.716510831731856\n",
       "62. 0.217654066401916\n",
       "63. -0.0937342329760078\n",
       "64. -0.405122532353932\n",
       "65. -0.405122532353932\n",
       "66. -1.02789913110978\n",
       "67. -1.02789913110978\n",
       "68. 0.529042365779841\n",
       "69. -0.405122532353932\n",
       "70. 0.217654066401916\n",
       "71. -0.405122532353932\n",
       "72. -0.716510831731856\n",
       "73. 1.77459556329154\n",
       "74. -0.716510831731856\n",
       "75. -0.405122532353932\n",
       "76. -0.716510831731856\n",
       "77. -0.405122532353932\n",
       "78. 4.26570195831493\n",
       "79. 1.15181896453569\n",
       "80. -1.02789913110978\n",
       "81. 0.840430665157765\n",
       "82. -0.0937342329760078\n",
       "83. 0.840430665157765\n",
       "84. -0.716510831731856\n",
       "85. -0.405122532353932\n",
       "86. 1.46320726391361\n",
       "87. -1.02789913110978\n",
       "88. -1.02789913110978\n",
       "89. 1.46320726391361\n",
       "90. -0.716510831731856\n",
       "91. 1.46320726391361\n",
       "92. 0.529042365779841\n",
       "93. 1.77459556329154\n",
       "94. 0.529042365779841\n",
       "95. -0.0937342329760078\n",
       "96. 0.217654066401916\n",
       "97. 0.217654066401916\n",
       "98. -0.405122532353932\n",
       "99. 0.840430665157765\n",
       "100. 1.46320726391361\n",
       "101. -0.716510831731856\n",
       "102. -1.02789913110978\n",
       "103. 1.77459556329154\n",
       "104. 2.70876046142531\n",
       "105. 0.529042365779841\n",
       "106. 0.840430665157765\n",
       "107. -1.02789913110978\n",
       "108. 1.15181896453569\n",
       "109. -0.716510831731856\n",
       "110. -0.716510831731856\n",
       "111. 0.217654066401916\n",
       "112. -1.02789913110978\n",
       "113. 0.840430665157765\n",
       "114. -0.716510831731856\n",
       "115. -0.0937342329760078\n",
       "116. 1.15181896453569\n",
       "117. 0.217654066401916\n",
       "118. 0.840430665157765\n",
       "119. -0.405122532353932\n",
       "120. -1.02789913110978\n",
       "121. 1.77459556329154\n",
       "122. -0.405122532353932\n",
       "123. 2.70876046142531\n",
       "124. -0.716510831731856\n",
       "125. 2.39737216204739\n",
       "126. -0.0937342329760078\n",
       "127. 0.529042365779841\n",
       "128. -0.405122532353932\n",
       "129. -0.716510831731856\n",
       "130. -0.405122532353932\n",
       "131. -1.02789913110978\n",
       "132. -0.405122532353932\n",
       "133. 2.08598386266946\n",
       "134. 1.15181896453569\n",
       "135. 1.15181896453569\n",
       "136. 0.529042365779841\n",
       "137. -0.716510831731856\n",
       "138. 0.217654066401916\n",
       "139. 0.529042365779841\n",
       "140. -1.02789913110978\n",
       "141. -1.02789913110978\n",
       "142. -0.405122532353932\n",
       "143. -0.716510831731856\n",
       "144. 0.840430665157765\n",
       "145. -0.405122532353932\n",
       "146. -1.02789913110978\n",
       "147. 3.33153706018116\n",
       "148. -0.405122532353932\n",
       "149. 0.529042365779841\n",
       "150. -0.405122532353932\n",
       "151. 2.08598386266946\n",
       "152. -1.02789913110978\n",
       "153. -1.02789913110978\n",
       "154. -0.405122532353932\n",
       "155. -1.02789913110978\n",
       "156. -0.405122532353932\n",
       "157. -0.0937342329760078\n",
       "158. -0.405122532353932\n",
       "159. -0.0937342329760078\n",
       "160. -0.0937342329760078\n",
       "161. 0.217654066401916\n",
       "162. 3.02014876080323\n",
       "163. -0.716510831731856\n",
       "164. -0.716510831731856\n",
       "165. -0.405122532353932\n",
       "166. 0.840430665157765\n",
       "167. -0.405122532353932\n",
       "168. -0.716510831731856\n",
       "169. -1.02789913110978\n",
       "170. 1.77459556329154\n",
       "171. -0.716510831731856\n",
       "172. -0.716510831731856\n",
       "173. 1.46320726391361\n",
       "174. -0.716510831731856\n",
       "175. -0.0937342329760078\n",
       "176. -0.716510831731856\n",
       "177. -0.716510831731856\n",
       "178. 2.70876046142531\n",
       "179. -0.716510831731856\n",
       "180. 0.529042365779841\n",
       "181. 0.217654066401916\n",
       "182. 0.529042365779841\n",
       "183. -0.0937342329760078\n",
       "184. -0.716510831731856\n",
       "185. -0.0937342329760078\n",
       "186. -1.02789913110978\n",
       "187. -0.405122532353932\n",
       "188. -0.405122532353932\n",
       "189. 2.70876046142531\n",
       "190. -1.02789913110978\n",
       "191. -0.716510831731856\n",
       "192. -1.02789913110978\n",
       "193. -0.716510831731856\n",
       "194. -0.716510831731856\n",
       "195. -0.716510831731856\n",
       "196. -0.716510831731856\n",
       "197. -0.716510831731856\n",
       "198. 0.529042365779841\n",
       "199. -0.0937342329760078\n",
       "200. -0.716510831731856\n",
       "201. -0.716510831731856\n",
       "202. 0.217654066401916\n",
       "203. -0.405122532353932\n",
       "204. -0.0937342329760078\n",
       "205. 0.529042365779841\n",
       "206. -0.405122532353932\n",
       "207. -0.716510831731856\n",
       "208. -0.716510831731856\n",
       "209. -0.716510831731856\n",
       "210. -0.716510831731856\n",
       "211. -1.02789913110978\n",
       "212. -0.0937342329760078\n",
       "213. -0.0937342329760078\n",
       "214. -0.716510831731856\n",
       "215. -0.405122532353932\n",
       "216. -1.02789913110978\n",
       "217. 1.46320726391361\n",
       "218. 0.217654066401916\n",
       "219. -0.716510831731856\n",
       "220. -1.02789913110978\n",
       "221. -0.716510831731856\n",
       "222. -0.0937342329760078\n",
       "223. -0.716510831731856\n",
       "224. -0.405122532353932\n",
       "225. 0.217654066401916\n",
       "226. -1.02789913110978\n",
       "227. -0.716510831731856\n",
       "228. -1.02789913110978\n",
       "229. -1.02789913110978\n",
       "230. -1.02789913110978\n",
       "231. -0.716510831731856\n",
       "232. -1.02789913110978\n",
       "233. -0.405122532353932\n",
       "234. 0.529042365779841\n",
       "235. 2.08598386266946\n",
       "236. 1.77459556329154\n",
       "237. 1.77459556329154\n",
       "238. 1.46320726391361\n",
       "239. -1.02789913110978\n",
       "240. -1.02789913110978\n",
       "241. -1.02789913110978\n",
       "242. 0.840430665157765\n",
       "243. -0.405122532353932\n",
       "244. 1.15181896453569\n",
       "245. 1.46320726391361\n",
       "246. -0.0937342329760078\n",
       "247. 0.217654066401916\n",
       "248. -1.02789913110978\n",
       "249. -1.02789913110978\n",
       "250. -0.716510831731856\n",
       "251. -1.02789913110978\n",
       "252. -0.405122532353932\n",
       "253. 0.217654066401916\n",
       "254. -0.405122532353932\n",
       "255. 1.15181896453569\n",
       "256. 0.840430665157765\n",
       "257. -0.405122532353932\n",
       "258. 1.15181896453569\n",
       "259. -1.02789913110978\n",
       "260. -0.716510831731856\n",
       "261. -0.405122532353932\n",
       "262. -1.02789913110978\n",
       "263. -0.0937342329760078\n",
       "264. -0.0937342329760078\n",
       "265. 1.77459556329154\n",
       "266. 0.840430665157765\n",
       "267. -0.405122532353932\n",
       "268. -0.0937342329760078\n",
       "269. -0.716510831731856\n",
       "270. -0.0937342329760078\n",
       "271. -1.02789913110978\n",
       "272. -0.405122532353932\n",
       "273. -0.716510831731856\n",
       "274. -0.716510831731856\n",
       "275. -1.02789913110978\n",
       "276. -0.0937342329760078\n",
       "277. 1.46320726391361\n",
       "278. -0.0937342329760078\n",
       "279. 0.217654066401916\n",
       "280. -0.716510831731856\n",
       "281. 1.46320726391361\n",
       "282. 0.529042365779841\n",
       "283. 0.217654066401916\n",
       "284. -0.716510831731856\n",
       "285. -0.0937342329760078\n",
       "286. -0.716510831731856\n",
       "287. -0.716510831731856\n",
       "288. 1.15181896453569\n",
       "289. -1.02789913110978\n",
       "290. -0.716510831731856\n",
       "291. 0.840430665157765\n",
       "292. -0.405122532353932\n",
       "293. -0.716510831731856\n",
       "294. 0.840430665157765\n",
       "295. 0.217654066401916\n",
       "296. -1.02789913110978\n",
       "297. -0.0937342329760078\n",
       "298. -0.405122532353932\n",
       "299. -0.716510831731856\n",
       "300. -0.716510831731856\n",
       "301. 0.840430665157765\n",
       "302. 1.46320726391361\n",
       "303. -0.0937342329760078\n",
       "304. -0.405122532353932\n",
       "305. -0.405122532353932\n",
       "306. 0.840430665157765\n",
       "307. -1.02789913110978\n",
       "308. -0.716510831731856\n",
       "309. -0.716510831731856\n",
       "310. 1.15181896453569\n",
       "311. -0.716510831731856\n",
       "312. -0.716510831731856\n",
       "313. -1.02789913110978\n",
       "314. -0.716510831731856\n",
       "315. -0.0937342329760078\n",
       "316. -0.0937342329760078\n",
       "317. 1.15181896453569\n",
       "318. 2.39737216204739\n",
       "319. -0.405122532353932\n",
       "320. -0.405122532353932\n",
       "321. -1.02789913110978\n",
       "322. 0.217654066401916\n",
       "323. -1.02789913110978\n",
       "324. -0.716510831731856\n",
       "325. -0.405122532353932\n",
       "326. 1.15181896453569\n",
       "327. -0.716510831731856\n",
       "328. -1.02789913110978\n",
       "329. -0.0937342329760078\n",
       "330. -0.405122532353932\n",
       "331. -0.716510831731856\n",
       "332. -1.02789913110978\n",
       "333. 2.39737216204739\n",
       "334. -0.716510831731856\n",
       "335. -0.716510831731856\n",
       "336. 0.529042365779841\n",
       "337. -0.716510831731856\n",
       "338. -0.405122532353932\n",
       "339. -0.405122532353932\n",
       "340. -0.716510831731856\n",
       "341. -0.0937342329760078\n",
       "342. 1.46320726391361\n",
       "343. 1.77459556329154\n",
       "344. -0.716510831731856\n",
       "345. 0.840430665157765\n",
       "346. 1.77459556329154\n",
       "347. 0.840430665157765\n",
       "348. 2.08598386266946\n",
       "349. -0.0937342329760078\n",
       "350. -0.405122532353932\n",
       "351. -0.405122532353932\n",
       "352. -1.02789913110978\n",
       "353. -0.405122532353932\n",
       "354. -0.716510831731856\n",
       "355. -0.716510831731856\n",
       "356. -0.405122532353932\n",
       "357. 1.15181896453569\n",
       "358. 1.15181896453569\n",
       "359. -0.0937342329760078\n",
       "360. 0.217654066401916\n",
       "361. -0.405122532353932\n",
       "362. 0.217654066401916\n",
       "363. -0.405122532353932\n",
       "364. -0.405122532353932\n",
       "365. -0.0937342329760078\n",
       "366. 0.529042365779841\n",
       "367. -1.02789913110978\n",
       "368. 1.15181896453569\n",
       "369. -0.0937342329760078\n",
       "370. -0.716510831731856\n",
       "371. -0.716510831731856\n",
       "372. -0.716510831731856\n",
       "373. 0.529042365779841\n",
       "374. -0.716510831731856\n",
       "375. -0.0937342329760078\n",
       "376. -0.405122532353932\n",
       "377. -0.405122532353932\n",
       "378. -1.02789913110978\n",
       "379. -0.405122532353932\n",
       "380. 2.39737216204739\n",
       "381. -0.0937342329760078\n",
       "382. -0.716510831731856\n",
       "383. 3.02014876080323\n",
       "384. 2.70876046142531\n",
       "385. -0.716510831731856\n",
       "386. -0.0937342329760078\n",
       "387. -0.716510831731856\n",
       "388. -1.02789913110978\n",
       "389. -0.716510831731856\n",
       "390. -0.405122532353932\n",
       "391. 2.08598386266946\n",
       "392. 0.529042365779841\n",
       "393. -1.08965328588737\n",
       "394. 0.465718905529468\n",
       "395. -1.4460927464204\n",
       "396. 2.40993414480051\n",
       "397. 2.15070544623104\n",
       "398. 1.40542293784381\n",
       "399. -0.149949253573031\n",
       "400. -0.636003063390792\n",
       "401. -0.247160015536583\n",
       "402. 0.109279444996442\n",
       "403. 0.660140429456572\n",
       "404. 0.0768758576752583\n",
       "405. -0.830424587317897\n",
       "406. 0.724947604098941\n",
       "407. 1.14619423927433\n",
       "408. -1.12205687320855\n",
       "409. -0.636003063390792\n",
       "410. -0.376774364821319\n",
       "411. 1.85907316034038\n",
       "412. 1.56744087444973\n",
       "413. -0.636003063390792\n",
       "414. -0.700810238033161\n",
       "415. -1.12205687320855\n",
       "416. 1.72945881105565\n",
       "417. 0.886965540704861\n",
       "418. 2.08589827158867\n",
       "419. -0.733213825354345\n",
       "420. -0.571195888748424\n",
       "421. 0.595333254814204\n",
       "422. -0.895231761960265\n",
       "423. 0.757351191420125\n",
       "424. -0.733213825354345\n",
       "425. 0.530526080171836\n",
       "426. 0.206490206959995\n",
       "427. -1.28407480981447\n",
       "428. -0.409177952142504\n",
       "429. -0.733213825354345\n",
       "430. 0.433315318208284\n",
       "431. 0.01206868303289\n",
       "432. -1.34888198445684\n",
       "433. 0.627736842135388\n",
       "434. 0.692544016777757\n",
       "435. -1.67291785766868\n",
       "436. -0.960038936602634\n",
       "437. -0.0203349042882941\n",
       "438. -1.34888198445684\n",
       "439. 0.109279444996442\n",
       "440. 0.692544016777757\n",
       "441. -1.28407480981447\n",
       "442. -0.895231761960265\n",
       "443. 1.56744087444973\n",
       "444. 1.04898347731078\n",
       "445. -1.08965328588737\n",
       "446. 1.2110014139167\n",
       "447. -0.765617412675529\n",
       "448. 1.27580858855907\n",
       "449. -0.506388714106056\n",
       "450. -1.12205687320855\n",
       "451. -0.0851420789306623\n",
       "452. -0.149949253573031\n",
       "453. -0.182352840894215\n",
       "454. 1.6322480490921\n",
       "455. 1.53503728712854\n",
       "456. -0.862828174639081\n",
       "457. 0.0768758576752583\n",
       "458. -0.733213825354345\n",
       "459. -0.960038936602634\n",
       "460. -0.571195888748424\n",
       "461. -0.473985126784872\n",
       "462. 1.0165798899896\n",
       "463. -0.53879230142724\n",
       "464. 0.433315318208284\n",
       "465. 1.08138706463197\n",
       "466. 0.984176302668414\n",
       "467. -0.765617412675529\n",
       "468. -0.441581539463688\n",
       "469. -1.12205687320855\n",
       "470. 1.30821217588025\n",
       "471. -0.668406650711977\n",
       "472. -0.279563602857767\n",
       "473. -0.603599476069608\n",
       "474. -0.376774364821319\n",
       "475. 0.368508143565915\n",
       "476. -1.41368915909921\n",
       "477. -1.54330350838395\n",
       "478. 1.8266695730192\n",
       "479. 0.206490206959995\n",
       "480. -0.117545666251846\n",
       "481. 1.89147674766157\n",
       "482. 0.174086619638811\n",
       "483. -0.441581539463688\n",
       "484. 0.530526080171836\n",
       "485. 0.01206868303289\n",
       "486. 1.14619423927433\n",
       "487. -0.506388714106056\n",
       "488. -0.441581539463688\n",
       "489. 0.822158366062493\n",
       "490. -0.765617412675529\n",
       "491. -0.636003063390792\n",
       "492. 2.37753055747933\n",
       "493. -0.862828174639081\n",
       "494. 0.56292966749302\n",
       "495. -0.344370777500135\n",
       "496. 0.919369128026045\n",
       "497. -0.441581539463688\n",
       "498. 0.0768758576752583\n",
       "499. 1.76186239837683\n",
       "500. 0.627736842135388\n",
       "501. -0.733213825354345\n",
       "502. -1.15446046052974\n",
       "503. 2.40993414480051\n",
       "504. -0.182352840894215\n",
       "505. 0.368508143565915\n",
       "506. -1.41368915909921\n",
       "507. -1.57570709570513\n",
       "508. 1.89147674766157\n",
       "509. -1.024846111245\n",
       "510. -0.117545666251846\n",
       "511. 0.757351191420125\n",
       "512. 1.37301935052262\n",
       "513. 0.0444722703540741\n",
       "514. -1.05724969856619\n",
       "515. -0.992442523923818\n",
       "516. 2.28031979551578\n",
       "517. 1.04898347731078\n",
       "518. 2.21551262087341\n",
       "519. -0.862828174639081\n",
       "520. -0.473985126784872\n",
       "521. -1.67291785766868\n",
       "522. -0.733213825354345\n",
       "523. -0.603599476069608\n",
       "524. -0.473985126784872\n",
       "525. 0.206490206959995\n",
       "526. 0.336104556244731\n",
       "527. 0.433315318208284\n",
       "528. 1.04898347731078\n",
       "529. -0.117545666251846\n",
       "530. -0.862828174639081\n",
       "531. -0.473985126784872\n",
       "532. -1.4460927464204\n",
       "533. -0.506388714106056\n",
       "534. 0.174086619638811\n",
       "535. 0.174086619638811\n",
       "536. 0.919369128026045\n",
       "537. 0.757351191420125\n",
       "538. 0.109279444996442\n",
       "539. -0.733213825354345\n",
       "540. 0.692544016777757\n",
       "541. -1.47849633374158\n",
       "542. -0.0851420789306623\n",
       "543. 1.24340500123789\n",
       "544. 0.465718905529468\n",
       "545. 0.174086619638811\n",
       "546. 0.0444722703540741\n",
       "547. -0.53879230142724\n",
       "548. 1.04898347731078\n",
       "549. -0.311967190178951\n",
       "550. -0.344370777500135\n",
       "551. -0.765617412675529\n",
       "552. -0.247160015536583\n",
       "553. 0.206490206959995\n",
       "554. 0.95177271534723\n",
       "555. 1.11379065195315\n",
       "556. -0.0203349042882941\n",
       "557. -0.668406650711977\n",
       "558. -0.571195888748424\n",
       "559. -1.15446046052974\n",
       "560. -0.895231761960265\n",
       "561. 1.37301935052262\n",
       "562. 0.95177271534723\n",
       "563. 0.238893794281179\n",
       "564. -0.895231761960265\n",
       "565. 0.109279444996442\n",
       "566. 0.530526080171836\n",
       "567. -0.765617412675529\n",
       "568. -1.05724969856619\n",
       "569. 0.0768758576752583\n",
       "570. -1.12205687320855\n",
       "571. 2.37753055747933\n",
       "572. 2.15070544623104\n",
       "573. 0.789754778741309\n",
       "574. -0.765617412675529\n",
       "575. -1.34888198445684\n",
       "576. 0.336104556244731\n",
       "577. 1.6322480490921\n",
       "578. -1.25167122249329\n",
       "579. -0.571195888748424\n",
       "580. -0.0203349042882941\n",
       "581. 0.56292966749302\n",
       "582. -0.798020999996713\n",
       "583. -1.15446046052974\n",
       "584. -0.960038936602634\n",
       "585. -0.506388714106056\n",
       "586. -0.441581539463688\n",
       "587. -1.05724969856619\n",
       "588. 0.0768758576752583\n",
       "589. -0.117545666251846\n",
       "590. 0.692544016777757\n",
       "591. -0.733213825354345\n",
       "592. -0.733213825354345\n",
       "593. 0.271297381602363\n",
       "594. -0.214756428215399\n",
       "595. 0.141683032317627\n",
       "596. -0.862828174639081\n",
       "597. 0.433315318208284\n",
       "598. 0.01206868303289\n",
       "599. 1.59984446177091\n",
       "600. -0.344370777500135\n",
       "601. 0.660140429456572\n",
       "602. 0.660140429456572\n",
       "603. 0.498122492850652\n",
       "604. 1.6322480490921\n",
       "605. 0.206490206959995\n",
       "606. -0.117545666251846\n",
       "607. -0.92763534928145\n",
       "608. -0.668406650711977\n",
       "609. 0.919369128026045\n",
       "610. 1.98868750962512\n",
       "611. 1.89147674766157\n",
       "612. 0.4009117308871\n",
       "613. -0.895231761960265\n",
       "614. -1.08965328588737\n",
       "615. -1.38128557177803\n",
       "616. -1.28407480981447\n",
       "617. -0.182352840894215\n",
       "618. 1.85907316034038\n",
       "619. -0.733213825354345\n",
       "620. -0.895231761960265\n",
       "621. -0.603599476069608\n",
       "622. -0.0851420789306623\n",
       "623. -1.31647839713566\n",
       "624. -1.024846111245\n",
       "625. -0.733213825354345\n",
       "626. -1.18686404785092\n",
       "627. 0.822158366062493\n",
       "628. 0.368508143565915\n",
       "629. -0.0851420789306623\n",
       "630. -1.57570709570513\n",
       "631. 0.0444722703540741\n",
       "632. -1.57570709570513\n",
       "633. -0.830424587317897\n",
       "634. 1.0165798899896\n",
       "635. -0.571195888748424\n",
       "636. -0.279563602857767\n",
       "637. 0.109279444996442\n",
       "638. 1.14619423927433\n",
       "639. -1.21926763517211\n",
       "640. -1.25167122249329\n",
       "641. 0.4009117308871\n",
       "642. 0.530526080171836\n",
       "643. 1.6322480490921\n",
       "644. -1.28407480981447\n",
       "645. 0.0768758576752583\n",
       "646. -1.34888198445684\n",
       "647. 2.34512697015815\n",
       "648. 1.0165798899896\n",
       "649. -0.182352840894215\n",
       "650. -0.92763534928145\n",
       "651. 1.85907316034038\n",
       "652. 0.238893794281179\n",
       "653. -1.25167122249329\n",
       "654. 0.530526080171836\n",
       "655. -0.765617412675529\n",
       "656. 1.30821217588025\n",
       "657. 0.724947604098941\n",
       "658. 0.206490206959995\n",
       "659. -1.77012861963224\n",
       "660. 0.0444722703540741\n",
       "661. -0.830424587317897\n",
       "662. -0.214756428215399\n",
       "663. -0.182352840894215\n",
       "664. -0.0203349042882941\n",
       "665. -1.18686404785092\n",
       "666. -1.47849633374158\n",
       "667. 0.141683032317627\n",
       "668. 0.206490206959995\n",
       "669. -0.733213825354345\n",
       "670. 0.174086619638811\n",
       "671. -1.25167122249329\n",
       "672. -1.12205687320855\n",
       "673. 2.05349468426749\n",
       "674. 2.08589827158867\n",
       "675. 0.271297381602363\n",
       "676. 1.34061576320144\n",
       "677. -1.25167122249329\n",
       "678. -1.12205687320855\n",
       "679. -1.25167122249329\n",
       "680. 0.0444722703540741\n",
       "681. 2.4423377321217\n",
       "682. -1.15446046052974\n",
       "683. -0.765617412675529\n",
       "684. -0.895231761960265\n",
       "685. -0.765617412675529\n",
       "686. -0.992442523923818\n",
       "687. 1.0165798899896\n",
       "688. -0.0527384916094782\n",
       "689. -0.376774364821319\n",
       "690. -0.798020999996713\n",
       "691. 0.660140429456572\n",
       "692. -0.117545666251846\n",
       "693. -0.473985126784872\n",
       "694. 0.0444722703540741\n",
       "695. 1.72945881105565\n",
       "696. -0.344370777500135\n",
       "697. -1.31647839713566\n",
       "698. 0.01206868303289\n",
       "699. 2.11830185890986\n",
       "700. -1.08965328588737\n",
       "701. -0.441581539463688\n",
       "702. 0.886965540704861\n",
       "703. 1.89147674766157\n",
       "704. -0.992442523923818\n",
       "705. 0.95177271534723\n",
       "706. -0.376774364821319\n",
       "707. -0.53879230142724\n",
       "708. 1.66465163641328\n",
       "709. 1.47023011248618\n",
       "710. 0.498122492850652\n",
       "711. -1.77012861963224\n",
       "712. -0.344370777500135\n",
       "713. -0.92763534928145\n",
       "714. -1.05724969856619\n",
       "715. -0.668406650711977\n",
       "716. 0.174086619638811\n",
       "717. -0.92763534928145\n",
       "718. -0.830424587317897\n",
       "719. -0.733213825354345\n",
       "720. -0.668406650711977\n",
       "721. -0.636003063390792\n",
       "722. 1.11379065195315\n",
       "723. 1.43782652516499\n",
       "724. 1.8266695730192\n",
       "725. 0.433315318208284\n",
       "726. -1.024846111245\n",
       "727. -0.182352840894215\n",
       "728. 0.01206868303289\n",
       "729. -0.53879230142724\n",
       "730. 1.04898347731078\n",
       "731. -0.700810238033161\n",
       "732. -0.0851420789306623\n",
       "733. -1.38128557177803\n",
       "734. 1.43782652516499\n",
       "735. 0.724947604098941\n",
       "736. -0.344370777500135\n",
       "737. -0.798020999996713\n",
       "738. 1.0165798899896\n",
       "739. 1.37301935052262\n",
       "740. -1.77012861963224\n",
       "741. 0.01206868303289\n",
       "742. -0.700810238033161\n",
       "743. -2.15897166748645\n",
       "744. -0.895231761960265\n",
       "745. 0.206490206959995\n",
       "746. 0.56292966749302\n",
       "747. 0.692544016777757\n",
       "748. -0.0527384916094782\n",
       "749. 0.206490206959995\n",
       "750. 0.627736842135388\n",
       "751. 1.50263369980736\n",
       "752. 0.141683032317627\n",
       "753. -0.0203349042882941\n",
       "754. -0.409177952142504\n",
       "755. 0.141683032317627\n",
       "756. -0.960038936602634\n",
       "757. 1.14619423927433\n",
       "758. 0.109279444996442\n",
       "759. 0.368508143565915\n",
       "760. 2.08589827158867\n",
       "761. 1.6322480490921\n",
       "762. -0.473985126784872\n",
       "763. -0.279563602857767\n",
       "764. 0.854561953383677\n",
       "765. -0.182352840894215\n",
       "766. -0.214756428215399\n",
       "767. 0.238893794281179\n",
       "768. 1.66465163641328\n",
       "769. -0.53879230142724\n",
       "770. 0.109279444996442\n",
       "771. -0.765617412675529\n",
       "772. -0.0851420789306623\n",
       "773. -0.668406650711977\n",
       "774. -0.441581539463688\n",
       "775. 0.984176302668414\n",
       "776. -0.733213825354345\n",
       "777. -1.34888198445684\n",
       "778. 2.08589827158867\n",
       "779. -0.0527384916094782\n",
       "780. 1.89147674766157\n",
       "781. 0.174086619638811\n",
       "782. -1.12205687320855\n",
       "783. -0.700810238033161\n",
       "784. -0.0527384916094782\n",
       "785. -0.373177907818495\n",
       "786. -2.45382847482402\n",
       "787. -1.65357825674497\n",
       "788. -0.0530778205868761\n",
       "789. -0.853328038665924\n",
       "790. 0.106972223028934\n",
       "791. 1.06727248472379\n",
       "792. -3.25407869290307\n",
       "793. -0.0530778205868761\n",
       "794. 1.38737257195541\n",
       "795. 1.86752270280284\n",
       "796. -0.0530778205868761\n",
       "797. -0.373177907818495\n",
       "798. 0.907222441107981\n",
       "799. 0.427072310260553\n",
       "800. -1.01337808228173\n",
       "801. -0.853328038665924\n",
       "802. 0.106972223028934\n",
       "803. -0.533227951434305\n",
       "804. 3.14792305172932\n",
       "805. 0.747172397492172\n",
       "806. -1.65357825674497\n",
       "807. -0.373177907818495\n",
       "808. 1.54742261557122\n",
       "809. -0.373177907818495\n",
       "810. -0.213127864202686\n",
       "811. 1.38737257195541\n",
       "812. -0.533227951434305\n",
       "813. -1.01337808228173\n",
       "814. -0.373177907818495\n",
       "815. 1.1472975065317\n",
       "816. -0.373177907818495\n",
       "817. -0.533227951434305\n",
       "818. 1.2273225283396\n",
       "819. 0.587122353876362\n",
       "820. 0.267022266644743\n",
       "821. -0.213127864202686\n",
       "822. -0.0530778205868761\n",
       "823. 0.747172397492172\n",
       "824. 0.587122353876362\n",
       "825. 0.907222441107981\n",
       "826. 0.106972223028934\n",
       "827. -1.81362830036078\n",
       "828. -1.65357825674497\n",
       "829. 1.54742261557122\n",
       "830. 0.106972223028934\n",
       "831. -1.17342812589754\n",
       "832. -1.01337808228173\n",
       "833. -1.01337808228173\n",
       "834. 1.1472975065317\n",
       "835. 0.106972223028934\n",
       "836. -0.693277995050114\n",
       "837. 0.427072310260553\n",
       "838. -1.33347816951335\n",
       "839. 0.427072310260553\n",
       "840. 0.427072310260553\n",
       "841. 0.267022266644743\n",
       "842. -3.25407869290307\n",
       "843. -0.0530778205868761\n",
       "844. -1.01337808228173\n",
       "845. 1.38737257195541\n",
       "846. -0.0530778205868761\n",
       "847. -0.533227951434305\n",
       "848. -0.213127864202686\n",
       "849. -0.853328038665924\n",
       "850. -0.0530778205868761\n",
       "851. -0.853328038665924\n",
       "852. 0.106972223028934\n",
       "853. -1.49352821312916\n",
       "854. -0.693277995050114\n",
       "855. -0.533227951434305\n",
       "856. 0.267022266644743\n",
       "857. 1.2273225283396\n",
       "858. 0.907222441107981\n",
       "859. -1.49352821312916\n",
       "860. -1.17342812589754\n",
       "861. 0.267022266644743\n",
       "862. 0.106972223028934\n",
       "863. 0.267022266644743\n",
       "864. 0.747172397492172\n",
       "865. 0.267022266644743\n",
       "866. 1.54742261557122\n",
       "867. -0.0530778205868761\n",
       "868. -0.853328038665924\n",
       "869. -0.533227951434305\n",
       "870. 0.106972223028934\n",
       "871. 3.14792305172932\n",
       "872. -0.533227951434305\n",
       "873. -0.213127864202686\n",
       "874. 2.18762279003446\n",
       "875. 0.427072310260553\n",
       "876. 0.747172397492172\n",
       "877. -0.0530778205868761\n",
       "878. 1.06727248472379\n",
       "879. -0.693277995050114\n",
       "880. -0.533227951434305\n",
       "881. -0.853328038665924\n",
       "882. -0.0530778205868761\n",
       "883. 0.106972223028934\n",
       "884. 0.427072310260553\n",
       "885. -0.533227951434305\n",
       "886. -0.4532029296264\n",
       "887. 0.907222441107981\n",
       "888. -0.0530778205868761\n",
       "889. -0.693277995050114\n",
       "890. -0.213127864202686\n",
       "891. -0.853328038665924\n",
       "892. -0.853328038665924\n",
       "893. -0.373177907818495\n",
       "894. 0.587122353876362\n",
       "895. -0.0530778205868761\n",
       "896. 0.747172397492172\n",
       "897. 0.747172397492172\n",
       "898. 0.747172397492172\n",
       "899. -0.213127864202686\n",
       "900. 1.06727248472379\n",
       "901. -0.0530778205868761\n",
       "902. -1.65357825674497\n",
       "903. 0.427072310260553\n",
       "904. 1.54742261557122\n",
       "905. -0.0530778205868761\n",
       "906. 0.747172397492172\n",
       "907. -0.693277995050114\n",
       "908. -1.65357825674497\n",
       "909. 0.427072310260553\n",
       "910. -0.213127864202686\n",
       "911. 0.267022266644743\n",
       "912. -0.693277995050114\n",
       "913. 0.587122353876362\n",
       "914. -0.0530778205868761\n",
       "915. -0.533227951434305\n",
       "916. -0.693277995050114\n",
       "917. 0.427072310260553\n",
       "918. 1.38737257195541\n",
       "919. 0.267022266644743\n",
       "920. 1.06727248472379\n",
       "921. 1.2273225283396\n",
       "922. -1.17342812589754\n",
       "923. 0.106972223028934\n",
       "924. 1.38737257195541\n",
       "925. -0.693277995050114\n",
       "926. 0.587122353876362\n",
       "927. -1.81362830036078\n",
       "928. -0.693277995050114\n",
       "929. -0.0530778205868761\n",
       "930. 1.06727248472379\n",
       "931. 0.587122353876362\n",
       "932. -1.01337808228173\n",
       "933. 0.907222441107981\n",
       "934. 0.427072310260553\n",
       "935. -0.213127864202686\n",
       "936. -0.213127864202686\n",
       "937. -0.213127864202686\n",
       "938. -0.213127864202686\n",
       "939. -0.0530778205868761\n",
       "940. 0.267022266644743\n",
       "941. -1.65357825674497\n",
       "942. -0.213127864202686\n",
       "943. 0.747172397492172\n",
       "944. -0.373177907818495\n",
       "945. -0.853328038665924\n",
       "946. 1.54742261557122\n",
       "947. 0.106972223028934\n",
       "948. -0.533227951434305\n",
       "949. 1.2273225283396\n",
       "950. -0.0530778205868761\n",
       "951. -1.01337808228173\n",
       "952. -0.853328038665924\n",
       "953. 0.427072310260553\n",
       "954. 0.587122353876362\n",
       "955. -0.0530778205868761\n",
       "956. 0.267022266644743\n",
       "957. 1.38737257195541\n",
       "958. -1.97367834397659\n",
       "959. -0.693277995050114\n",
       "960. -0.693277995050114\n",
       "961. -1.65357825674497\n",
       "962. 0.267022266644743\n",
       "963. 0.427072310260553\n",
       "964. -0.533227951434305\n",
       "965. 0.267022266644743\n",
       "966. -1.33347816951335\n",
       "967. 1.2273225283396\n",
       "968. 2.50772287726608\n",
       "969. 0.907222441107981\n",
       "970. -0.533227951434305\n",
       "971. -1.01337808228173\n",
       "972. -1.49352821312916\n",
       "973. 0.907222441107981\n",
       "974. 0.907222441107981\n",
       "975. -0.853328038665924\n",
       "976. 2.34767283365027\n",
       "977. 0.106972223028934\n",
       "978. -0.853328038665924\n",
       "979. -0.693277995050114\n",
       "980. -0.0530778205868761\n",
       "981. -1.33347816951335\n",
       "982. 0.907222441107981\n",
       "983. -0.213127864202686\n",
       "984. -0.373177907818495\n",
       "985. -0.533227951434305\n",
       "986. 0.106972223028934\n",
       "987. -1.01337808228173\n",
       "988. -1.17342812589754\n",
       "989. 1.06727248472379\n",
       "990. -1.81362830036078\n",
       "991. -0.213127864202686\n",
       "992. 0.106972223028934\n",
       "993. 1.06727248472379\n",
       "994. 0.267022266644743\n",
       "995. -0.853328038665924\n",
       "996. 1.06727248472379\n",
       "997. -0.533227951434305\n",
       "998. 1.38737257195541\n",
       "999. -0.213127864202686\n",
       "1000. -0.533227951434305\n",
       "1001. 0.587122353876362\n",
       "1002. 0.587122353876362\n",
       "1003. -0.533227951434305\n",
       "1004. 1.86752270280284\n",
       "1005. 0.907222441107981\n",
       "1006. 0.267022266644743\n",
       "1007. 0.267022266644743\n",
       "1008. -0.373177907818495\n",
       "1009. -0.533227951434305\n",
       "1010. 0.587122353876362\n",
       "1011. 0.106972223028934\n",
       "1012. 0.747172397492172\n",
       "1013. -0.533227951434305\n",
       "1014. 0.267022266644743\n",
       "1015. -0.533227951434305\n",
       "1016. -0.213127864202686\n",
       "1017. -1.33347816951335\n",
       "1018. -0.213127864202686\n",
       "1019. 1.06727248472379\n",
       "1020. 0.267022266644743\n",
       "1021. 0.106972223028934\n",
       "1022. -0.0530778205868761\n",
       "1023. -1.17342812589754\n",
       "1024. -1.49352821312916\n",
       "1025. -0.533227951434305\n",
       "1026. 0.587122353876362\n",
       "1027. 0.747172397492172\n",
       "1028. 0.427072310260553\n",
       "1029. 0.267022266644743\n",
       "1030. -0.0530778205868761\n",
       "1031. -1.01337808228173\n",
       "1032. 0.907222441107981\n",
       "1033. -0.213127864202686\n",
       "1034. -0.693277995050114\n",
       "1035. 0.587122353876362\n",
       "1036. -0.4532029296264\n",
       "1037. -0.0530778205868761\n",
       "1038. 0.106972223028934\n",
       "1039. -0.0530778205868761\n",
       "1040. 0.267022266644743\n",
       "1041. 1.54742261557122\n",
       "1042. -0.533227951434305\n",
       "1043. 1.54742261557122\n",
       "1044. -0.853328038665924\n",
       "1045. -1.65357825674497\n",
       "1046. -0.693277995050114\n",
       "1047. -1.33347816951335\n",
       "1048. -0.0530778205868761\n",
       "1049. 1.38737257195541\n",
       "1050. 1.54742261557122\n",
       "1051. -0.0530778205868761\n",
       "1052. 0.747172397492172\n",
       "1053. -0.533227951434305\n",
       "1054. 0.267022266644743\n",
       "1055. -0.373177907818495\n",
       "1056. -0.853328038665924\n",
       "1057. -0.373177907818495\n",
       "1058. -1.17342812589754\n",
       "1059. 0.747172397492172\n",
       "1060. 1.70747265918703\n",
       "1061. 0.267022266644743\n",
       "1062. 0.106972223028934\n",
       "1063. 1.54742261557122\n",
       "1064. 0.587122353876362\n",
       "1065. 1.54742261557122\n",
       "1066. 0.427072310260553\n",
       "1067. -0.213127864202686\n",
       "1068. 0.907222441107981\n",
       "1069. -0.213127864202686\n",
       "1070. -0.693277995050114\n",
       "1071. -0.533227951434305\n",
       "1072. -0.0530778205868761\n",
       "1073. -0.373177907818495\n",
       "1074. -0.213127864202686\n",
       "1075. -0.853328038665924\n",
       "1076. -1.33347816951335\n",
       "1077. 0.106972223028934\n",
       "1078. -0.693277995050114\n",
       "1079. 0.106972223028934\n",
       "1080. -0.373177907818495\n",
       "1081. -1.01337808228173\n",
       "1082. -0.853328038665924\n",
       "1083. 1.2273225283396\n",
       "1084. -2.1337283875924\n",
       "1085. -2.1337283875924\n",
       "1086. 0.427072310260553\n",
       "1087. 1.2273225283396\n",
       "1088. 0.587122353876362\n",
       "1089. -1.49352821312916\n",
       "1090. 0.106972223028934\n",
       "1091. 0.907222441107981\n",
       "1092. -3.7342288237505\n",
       "1093. -2.61387851843983\n",
       "1094. 0.587122353876362\n",
       "1095. 0.587122353876362\n",
       "1096. -0.693277995050114\n",
       "1097. 0.907222441107981\n",
       "1098. -0.693277995050114\n",
       "1099. -1.33347816951335\n",
       "1100. -1.01337808228173\n",
       "1101. 1.38737257195541\n",
       "1102. 0.267022266644743\n",
       "1103. -0.693277995050114\n",
       "1104. 1.2273225283396\n",
       "1105. -0.0530778205868761\n",
       "1106. 1.38737257195541\n",
       "1107. 0.587122353876362\n",
       "1108. 0.907222441107981\n",
       "1109. 0.427072310260553\n",
       "1110. 0.427072310260553\n",
       "1111. 0.267022266644743\n",
       "1112. 1.2273225283396\n",
       "1113. 0.106972223028934\n",
       "1114. 0.267022266644743\n",
       "1115. 0.267022266644743\n",
       "1116. -1.65357825674497\n",
       "1117. 1.06727248472379\n",
       "1118. -1.33347816951335\n",
       "1119. -0.853328038665924\n",
       "1120. 0.267022266644743\n",
       "1121. -0.0530778205868761\n",
       "1122. -1.49352821312916\n",
       "1123. -1.01337808228173\n",
       "1124. 0.747172397492172\n",
       "1125. 0.907222441107981\n",
       "1126. 2.8278229644977\n",
       "1127. 0.747172397492172\n",
       "1128. 0.747172397492172\n",
       "1129. -1.01337808228173\n",
       "1130. 0.587122353876362\n",
       "1131. -0.213127864202686\n",
       "1132. 2.8278229644977\n",
       "1133. 2.34767283365027\n",
       "1134. -1.01337808228173\n",
       "1135. -1.17342812589754\n",
       "1136. -0.533227951434305\n",
       "1137. 0.267022266644743\n",
       "1138. 0.267022266644743\n",
       "1139. 0.907222441107981\n",
       "1140. -0.0530778205868761\n",
       "1141. -0.213127864202686\n",
       "1142. 1.54742261557122\n",
       "1143. 0.267022266644743\n",
       "1144. 1.38737257195541\n",
       "1145. 0.427072310260553\n",
       "1146. 0.427072310260553\n",
       "1147. -1.97367834397659\n",
       "1148. -0.533227951434305\n",
       "1149. -0.533227951434305\n",
       "1150. 0.587122353876362\n",
       "1151. -1.01337808228173\n",
       "1152. -1.65357825674497\n",
       "1153. 0.587122353876362\n",
       "1154. -0.853328038665924\n",
       "1155. -0.373177907818495\n",
       "1156. -0.213127864202686\n",
       "1157. 1.2273225283396\n",
       "1158. 0.587122353876362\n",
       "1159. 0.587122353876362\n",
       "1160. 1.38737257195541\n",
       "1161. -1.17342812589754\n",
       "1162. 1.2273225283396\n",
       "1163. -0.853328038665924\n",
       "1164. 0.747172397492172\n",
       "1165. -2.1337283875924\n",
       "1166. -1.01337808228173\n",
       "1167. 1.38737257195541\n",
       "1168. 1.06727248472379\n",
       "1169. 0.267022266644743\n",
       "1170. -0.0530778205868761\n",
       "1171. 0.587122353876362\n",
       "1172. 1.38737257195541\n",
       "1173. 1.38737257195541\n",
       "1174. -1.01337808228173\n",
       "1175. 0.427072310260553\n",
       "1176. 0.106972223028934\n",
       "1177. -0.584362921139607\n",
       "1178. 0.556709383152926\n",
       "1179. 0.271441307079793\n",
       "1180. 1.50760297006337\n",
       "1181. -0.584362921139607\n",
       "1182. -0.964720355903785\n",
       "1183. 1.69778168744546\n",
       "1184. 0.84197745922606\n",
       "1185. 0.0812625896977039\n",
       "1186. 1.12724553529919\n",
       "1187. 0.366530665770837\n",
       "1188. -0.299094845066474\n",
       "1189. -1.34507779066796\n",
       "1190. -0.964720355903785\n",
       "1191. 0.651798741843971\n",
       "1192. -1.72543522543214\n",
       "1193. 0.366530665770837\n",
       "1194. 1.69778168744546\n",
       "1195. -0.394184203757518\n",
       "1196. -0.489273562448563\n",
       "1197. -1.72543522543214\n",
       "1198. -1.34507779066796\n",
       "1199. -0.774541638521696\n",
       "1200. 0.461620024461882\n",
       "1201. 1.22233489399024\n",
       "1202. 0.937066817917104\n",
       "1203. 2.93394335042904\n",
       "1204. 1.12724553529919\n",
       "1205. 0.461620024461882\n",
       "1206. -1.53525650805005\n",
       "1207. -0.204005486375429\n",
       "1208. -0.869630997212741\n",
       "1209. 0.556709383152926\n",
       "1210. -0.869630997212741\n",
       "1211. -0.299094845066474\n",
       "1212. -0.0138267689933405\n",
       "1213. -0.394184203757518\n",
       "1214. 0.271441307079793\n",
       "1215. -1.34507779066796\n",
       "1216. 1.03215617660815\n",
       "1217. -1.05980971459483\n",
       "1218. -0.204005486375429\n",
       "1219. -1.05980971459483\n",
       "1220. 0.0812625896977039\n",
       "1221. 2.07813912220964\n",
       "1222. -1.05980971459483\n",
       "1223. -0.0138267689933405\n",
       "1224. -0.108916127684385\n",
       "1225. 0.176351948388748\n",
       "1226. -0.394184203757518\n",
       "1227. 0.366530665770837\n",
       "1228. -0.299094845066474\n",
       "1229. 0.461620024461882\n",
       "1230. 0.271441307079793\n",
       "1231. -1.34507779066796\n",
       "1232. 2.55358591566486\n",
       "1233. 0.0812625896977039\n",
       "1234. 1.22233489399024\n",
       "1235. 0.0812625896977039\n",
       "1236. 0.651798741843971\n",
       "1237. -0.489273562448563\n",
       "1238. -1.44016714935901\n",
       "1239. 0.746888100535015\n",
       "1240. -1.53525650805005\n",
       "1241. -0.869630997212741\n",
       "1242. -0.299094845066474\n",
       "1243. -0.394184203757518\n",
       "1244. -0.0138267689933405\n",
       "1245. -0.299094845066474\n",
       "1246. 0.176351948388748\n",
       "1247. 0.556709383152926\n",
       "1248. 1.98304976351859\n",
       "1249. -0.108916127684385\n",
       "1250. 1.22233489399024\n",
       "1251. -1.34507779066796\n",
       "1252. -0.774541638521696\n",
       "1253. -0.964720355903785\n",
       "1254. 1.12724553529919\n",
       "1255. 1.03215617660815\n",
       "1256. 0.461620024461882\n",
       "1257. -1.05980971459483\n",
       "1258. -1.6303458667411\n",
       "1259. -0.584362921139607\n",
       "1260. 1.22233489399024\n",
       "1261. -0.489273562448563\n",
       "1262. 1.22233489399024\n",
       "1263. 1.60269232875442\n",
       "1264. -1.05980971459483\n",
       "1265. 0.651798741843971\n",
       "1266. 1.12724553529919\n",
       "1267. 0.937066817917104\n",
       "1268. 0.556709383152926\n",
       "1269. 1.41251361137233\n",
       "1270. 1.12724553529919\n",
       "1271. -1.53525650805005\n",
       "1272. 1.41251361137233\n",
       "1273. -0.204005486375429\n",
       "1274. -1.24998843197692\n",
       "1275. 0.271441307079793\n",
       "1276. -0.0138267689933405\n",
       "1277. -0.204005486375429\n",
       "1278. -0.299094845066474\n",
       "1279. 0.271441307079793\n",
       "1280. 1.03215617660815\n",
       "1281. 1.12724553529919\n",
       "1282. 0.0812625896977039\n",
       "1283. -0.0138267689933405\n",
       "1284. 0.366530665770837\n",
       "1285. -1.34507779066796\n",
       "1286. -0.204005486375429\n",
       "1287. 0.937066817917104\n",
       "1288. 0.176351948388748\n",
       "1289. 0.746888100535015\n",
       "1290. -0.394184203757518\n",
       "1291. -0.108916127684385\n",
       "1292. -0.774541638521696\n",
       "1293. 0.271441307079793\n",
       "1294. -0.679452279830652\n",
       "1295. 0.556709383152926\n",
       "1296. 0.366530665770837\n",
       "1297. 0.366530665770837\n",
       "1298. -1.44016714935901\n",
       "1299. -2.10579266019632\n",
       "1300. -1.24998843197692\n",
       "1301. -0.108916127684385\n",
       "1302. -1.34507779066796\n",
       "1303. -1.05980971459483\n",
       "1304. 0.271441307079793\n",
       "1305. 1.98304976351859\n",
       "1306. 2.17322848090068\n",
       "1307. -0.584362921139607\n",
       "1308. -1.82052458412319\n",
       "1309. -0.108916127684385\n",
       "1310. -1.34507779066796\n",
       "1311. -0.299094845066474\n",
       "1312. 1.41251361137233\n",
       "1313. 0.937066817917104\n",
       "1314. -1.15489907328587\n",
       "1315. 1.31742425268128\n",
       "1316. -0.0138267689933405\n",
       "1317. 0.0812625896977039\n",
       "1318. 0.746888100535015\n",
       "1319. 1.50760297006337\n",
       "1320. 0.176351948388748\n",
       "1321. 0.84197745922606\n",
       "1322. -0.0138267689933405\n",
       "1323. -0.394184203757518\n",
       "1324. 0.366530665770837\n",
       "1325. 1.12724553529919\n",
       "1326. 0.746888100535015\n",
       "1327. -0.584362921139607\n",
       "1328. -1.44016714935901\n",
       "1329. -0.964720355903785\n",
       "1330. -0.108916127684385\n",
       "1331. 0.746888100535015\n",
       "1332. -1.15489907328587\n",
       "1333. -1.82052458412319\n",
       "1334. -0.679452279830652\n",
       "1335. -1.72543522543214\n",
       "1336. 0.937066817917104\n",
       "1337. -1.6303458667411\n",
       "1338. 0.366530665770837\n",
       "1339. -0.774541638521696\n",
       "1340. 0.271441307079793\n",
       "1341. 0.651798741843971\n",
       "1342. 0.271441307079793\n",
       "1343. -1.24998843197692\n",
       "1344. -1.05980971459483\n",
       "1345. 1.31742425268128\n",
       "1346. 0.461620024461882\n",
       "1347. -1.53525650805005\n",
       "1348. -0.774541638521696\n",
       "1349. 0.651798741843971\n",
       "1350. -0.964720355903785\n",
       "1351. -0.964720355903785\n",
       "1352. -1.6303458667411\n",
       "1353. 1.03215617660815\n",
       "1354. 1.03215617660815\n",
       "1355. 0.651798741843971\n",
       "1356. 0.366530665770837\n",
       "1357. -0.394184203757518\n",
       "1358. -0.108916127684385\n",
       "1359. -1.24998843197692\n",
       "1360. -0.108916127684385\n",
       "1361. 1.7928710461365\n",
       "1362. -0.679452279830652\n",
       "1363. 1.03215617660815\n",
       "1364. 1.31742425268128\n",
       "1365. 1.31742425268128\n",
       "1366. -1.34507779066796\n",
       "1367. 0.746888100535015\n",
       "1368. 0.937066817917104\n",
       "1369. 0.0812625896977039\n",
       "1370. -2.01070330150527\n",
       "1371. -1.05980971459483\n",
       "1372. -0.489273562448563\n",
       "1373. -1.53525650805005\n",
       "1374. -0.299094845066474\n",
       "1375. -0.584362921139607\n",
       "1376. -0.0138267689933405\n",
       "1377. -1.44016714935901\n",
       "1378. -1.6303458667411\n",
       "1379. -0.489273562448563\n",
       "1380. 0.461620024461882\n",
       "1381. 1.12724553529919\n",
       "1382. 0.271441307079793\n",
       "1383. 1.88796040482755\n",
       "1384. 0.0812625896977039\n",
       "1385. -0.584362921139607\n",
       "1386. -0.679452279830652\n",
       "1387. 0.556709383152926\n",
       "1388. 0.366530665770837\n",
       "1389. -0.0138267689933405\n",
       "1390. 1.12724553529919\n",
       "1391. -1.05980971459483\n",
       "1392. 1.60269232875442\n",
       "1393. 0.271441307079793\n",
       "1394. 0.937066817917104\n",
       "1395. 0.0812625896977039\n",
       "1396. 1.60269232875442\n",
       "1397. -0.394184203757518\n",
       "1398. -1.24998843197692\n",
       "1399. -1.72543522543214\n",
       "1400. -0.584362921139607\n",
       "1401. -0.204005486375429\n",
       "1402. 3.21921142650217\n",
       "1403. -1.6303458667411\n",
       "1404. 1.50760297006337\n",
       "1405. 0.746888100535015\n",
       "1406. -1.05980971459483\n",
       "1407. -1.53525650805005\n",
       "1408. 0.271441307079793\n",
       "1409. -0.108916127684385\n",
       "1410. -0.108916127684385\n",
       "1411. 1.7928710461365\n",
       "1412. 0.366530665770837\n",
       "1413. -0.679452279830652\n",
       "1414. 1.03215617660815\n",
       "1415. -1.53525650805005\n",
       "1416. -1.82052458412319\n",
       "1417. 0.651798741843971\n",
       "1418. 1.12724553529919\n",
       "1419. 1.50760297006337\n",
       "1420. -1.15489907328587\n",
       "1421. 0.84197745922606\n",
       "1422. 0.0812625896977039\n",
       "1423. -0.679452279830652\n",
       "1424. 0.176351948388748\n",
       "1425. 1.22233489399024\n",
       "1426. 1.12724553529919\n",
       "1427. 0.271441307079793\n",
       "1428. -0.108916127684385\n",
       "1429. -1.05980971459483\n",
       "1430. -1.34507779066796\n",
       "1431. 0.366530665770837\n",
       "1432. 0.271441307079793\n",
       "1433. -0.964720355903785\n",
       "1434. -0.394184203757518\n",
       "1435. -0.299094845066474\n",
       "1436. -0.584362921139607\n",
       "1437. -0.584362921139607\n",
       "1438. -1.15489907328587\n",
       "1439. -0.964720355903785\n",
       "1440. -1.05980971459483\n",
       "1441. 0.461620024461882\n",
       "1442. -2.10579266019632\n",
       "1443. 0.271441307079793\n",
       "1444. 0.366530665770837\n",
       "1445. -0.964720355903785\n",
       "1446. -1.34507779066796\n",
       "1447. 0.176351948388748\n",
       "1448. -1.05980971459483\n",
       "1449. 2.17322848090068\n",
       "1450. 0.0812625896977039\n",
       "1451. 0.746888100535015\n",
       "1452. 1.88796040482755\n",
       "1453. 1.03215617660815\n",
       "1454. -0.394184203757518\n",
       "1455. -0.584362921139607\n",
       "1456. -0.0138267689933405\n",
       "1457. 0.556709383152926\n",
       "1458. -0.204005486375429\n",
       "1459. -0.774541638521696\n",
       "1460. 1.31742425268128\n",
       "1461. 0.0812625896977039\n",
       "1462. -0.489273562448563\n",
       "1463. -0.584362921139607\n",
       "1464. 0.366530665770837\n",
       "1465. 0.271441307079793\n",
       "1466. 0.461620024461882\n",
       "1467. -0.964720355903785\n",
       "1468. -1.44016714935901\n",
       "1469. 0.0812625896977039\n",
       "1470. 0.271441307079793\n",
       "1471. -0.0138267689933405\n",
       "1472. 0.0812625896977039\n",
       "1473. 0.176351948388748\n",
       "1474. -1.15489907328587\n",
       "1475. 0.0812625896977039\n",
       "1476. 1.69778168744546\n",
       "1477. -0.869630997212741\n",
       "1478. -0.489273562448563\n",
       "1479. -0.204005486375429\n",
       "1480. 1.98304976351859\n",
       "1481. -0.679452279830652\n",
       "1482. 1.50760297006337\n",
       "1483. -1.44016714935901\n",
       "1484. -0.964720355903785\n",
       "1485. -1.05980971459483\n",
       "1486. -0.0138267689933405\n",
       "1487. 1.22233489399024\n",
       "1488. -0.394184203757518\n",
       "1489. 0.937066817917104\n",
       "1490. -1.53525650805005\n",
       "1491. -0.774541638521696\n",
       "1492. -0.679452279830652\n",
       "1493. 1.22233489399024\n",
       "1494. -0.299094845066474\n",
       "1495. -1.53525650805005\n",
       "1496. 1.22233489399024\n",
       "1497. -0.204005486375429\n",
       "1498. 1.69778168744546\n",
       "1499. 1.03215617660815\n",
       "1500. -1.15489907328587\n",
       "1501. -1.05980971459483\n",
       "1502. 0.271441307079793\n",
       "1503. -1.6303458667411\n",
       "1504. -1.15489907328587\n",
       "1505. 0.0812625896977039\n",
       "1506. 0.556709383152926\n",
       "1507. -1.15489907328587\n",
       "1508. 0.651798741843971\n",
       "1509. 0.556709383152926\n",
       "1510. -0.394184203757518\n",
       "1511. -0.584362921139607\n",
       "1512. 1.03215617660815\n",
       "1513. -0.108916127684385\n",
       "1514. -0.204005486375429\n",
       "1515. 0.556709383152926\n",
       "1516. 1.7928710461365\n",
       "1517. 0.176351948388748\n",
       "1518. 1.60269232875442\n",
       "1519. 1.60269232875442\n",
       "1520. 1.50760297006337\n",
       "1521. 0.366530665770837\n",
       "1522. 0.0812625896977039\n",
       "1523. -0.299094845066474\n",
       "1524. -0.584362921139607\n",
       "1525. 0.556709383152926\n",
       "1526. -1.15489907328587\n",
       "1527. -0.108916127684385\n",
       "1528. 0.937066817917104\n",
       "1529. -0.299094845066474\n",
       "1530. -0.299094845066474\n",
       "1531. 1.60269232875442\n",
       "1532. 0.271441307079793\n",
       "1533. 1.88796040482755\n",
       "1534. -0.489273562448563\n",
       "1535. -0.964720355903785\n",
       "1536. -1.72543522543214\n",
       "1537. -0.204005486375429\n",
       "1538. -0.869630997212741\n",
       "1539. -0.774541638521696\n",
       "1540. 0.271441307079793\n",
       "1541. -1.53525650805005\n",
       "1542. -0.204005486375429\n",
       "1543. -0.869630997212741\n",
       "1544. 0.366530665770837\n",
       "1545. 0.937066817917104\n",
       "1546. 1.60269232875442\n",
       "1547. 0.651798741843971\n",
       "1548. -0.0138267689933405\n",
       "1549. 0.0812625896977039\n",
       "1550. -0.0138267689933405\n",
       "1551. -0.584362921139607\n",
       "1552. 0.746888100535015\n",
       "1553. -0.204005486375429\n",
       "1554. -0.204005486375429\n",
       "1555. -1.15489907328587\n",
       "1556. 0.746888100535015\n",
       "1557. -0.869630997212741\n",
       "1558. -1.05980971459483\n",
       "1559. 0.746888100535015\n",
       "1560. 0.366530665770837\n",
       "1561. 1.12724553529919\n",
       "1562. -0.679452279830652\n",
       "1563. 0.937066817917104\n",
       "1564. 1.41251361137233\n",
       "1565. 0.937066817917104\n",
       "1566. -0.299094845066474\n",
       "1567. 1.7928710461365\n",
       "1568. -0.584362921139607\n",
       "1569. -0.522174689475281\n",
       "1570. 0.100502421118279\n",
       "1571. -0.57266202276665\n",
       "1572. 3.25596075182889\n",
       "1573. 5.80557108304306\n",
       "1574. 0.159404309958211\n",
       "1575. 0.6222048651291\n",
       "1576. -0.614734800509459\n",
       "1577. -0.505345578378157\n",
       "1578. 0.664277642871908\n",
       "1579. -0.0846178009500762\n",
       "1580. -0.345469022955487\n",
       "1581. -0.135105134241446\n",
       "1582. -0.387541800698295\n",
       "1583. 0.748423198357524\n",
       "1584. -0.858756911417746\n",
       "1585. 0.302451754283758\n",
       "1586. 0.428670087512183\n",
       "1587. -0.72412402264076\n",
       "1588. 0.706350420614716\n",
       "1589. -0.62314935605802\n",
       "1590. -1.01021891129185\n",
       "1591. -1.11960813342316\n",
       "1592. 1.21122375352841\n",
       "1593. 1.564635086568\n",
       "1594. 1.24488197572266\n",
       "1595. -0.387541800698295\n",
       "1596. -0.118276023144323\n",
       "1597. -0.236079800824185\n",
       "1598. -0.993389800194732\n",
       "1599. -0.471687356183911\n",
       "1600. -0.555832911669527\n",
       "1601. -0.135105134241446\n",
       "1602. 0.958787087071565\n",
       "1603. -0.715709467092198\n",
       "1604. -0.26132346746987\n",
       "1605. -0.715709467092198\n",
       "1606. -0.387541800698295\n",
       "1607. 0.167818865506772\n",
       "1608. -0.909244244709115\n",
       "1609. -0.774611355932129\n",
       "1610. 0.605375754031977\n",
       "1611. -0.67363668934939\n",
       "1612. -0.774611355932129\n",
       "1613. 0.538059309643484\n",
       "1614. -0.976560689097608\n",
       "1615. -0.0341304676587065\n",
       "1616. -0.135105134241446\n",
       "1617. -1.16168091116596\n",
       "1618. -1.01021891129185\n",
       "1619. -0.177177911984254\n",
       "1620. 2.85206208549793\n",
       "1621. -1.00180435574329\n",
       "1622. 0.159404309958211\n",
       "1623. -0.88400057806343\n",
       "1624. -0.471687356183911\n",
       "1625. -0.471687356183911\n",
       "1626. -0.480101911732473\n",
       "1627. -0.177177911984254\n",
       "1628. -0.522174689475281\n",
       "1629. -0.0930323564986378\n",
       "1630. 0.100502421118279\n",
       "1631. 0.580132087386292\n",
       "1632. -0.900829689160554\n",
       "1633. -0.135105134241446\n",
       "1634. -0.892415133611992\n",
       "1635. -0.539003800572404\n",
       "1636. 1.42158764224245\n",
       "1637. -0.783025911480691\n",
       "1638. 1.07659086475143\n",
       "1639. -0.31181080076124\n",
       "1640. 0.403426420866498\n",
       "1641. -0.00888680101302161\n",
       "1642. 2.76791653001231\n",
       "1643. -0.522174689475281\n",
       "1644. -0.177177911984254\n",
       "1645. -0.867171466966307\n",
       "1646. -0.353883578504048\n",
       "1647. -0.429614578441103\n",
       "1648. 1.08500542029999\n",
       "1649. -0.000472245464459984\n",
       "1650. -0.656807578252267\n",
       "1651. -0.219250689727062\n",
       "1652. -0.909244244709115\n",
       "1653. -0.850342355869184\n",
       "1654. -0.219250689727062\n",
       "1655. -0.219250689727062\n",
       "1656. -0.539003800572404\n",
       "1657. 2.85206208549793\n",
       "1658. -0.825098689223499\n",
       "1659. -0.353883578504048\n",
       "1660. 0.0331859767297865\n",
       "1661. -0.522174689475281\n",
       "1662. 0.453913754157868\n",
       "1663. -0.909244244709115\n",
       "1664. -0.480101911732473\n",
       "1665. 1.36268575340252\n",
       "1666. -0.942902466903362\n",
       "1667. 0.285622643186635\n",
       "1668. 1.04293264255718\n",
       "1669. -0.581076578315212\n",
       "1670. -0.219250689727062\n",
       "1671. 0.159404309958211\n",
       "1672. 0.967201642620127\n",
       "1673. -0.227665245275624\n",
       "1674. -0.303396245212678\n",
       "1675. 2.70901464117238\n",
       "1676. 0.285622643186635\n",
       "1677. -0.841927800320622\n",
       "1678. -1.0438771334861\n",
       "1679. 4.94728641708978\n",
       "1680. -0.867171466966307\n",
       "1681. 1.80024264192773\n",
       "1682. -1.00180435574329\n",
       "1683. -0.9344879113548\n",
       "1684. 0.302451754283758\n",
       "1685. -0.57266202276665\n",
       "1686. 0.167818865506772\n",
       "1687. 0.319280865380882\n",
       "1688. 4.40875486198183\n",
       "1689. 2.0695084194817\n",
       "1690. -0.850342355869184\n",
       "1691. 0.857812420488826\n",
       "1692. 1.84231541967054\n",
       "1693. -0.0509595787558297\n",
       "1694. -0.219250689727062\n",
       "1695. -0.749367689286444\n",
       "1696. -0.841927800320622\n",
       "1697. -0.9344879113548\n",
       "1698. -0.833513244772061\n",
       "1699. -0.337054467406925\n",
       "1700. 1.02610353146006\n",
       "1701. -0.286567134115555\n",
       "1702. -0.00888680101302161\n",
       "1703. -0.177177911984254\n",
       "1704. 3.27278986292601\n",
       "1705. 0.538059309643484\n",
       "1706. -0.900829689160554\n",
       "1707. -0.682051244897951\n",
       "1708. -0.976560689097608\n",
       "1709. -0.690465800446513\n",
       "1710. 0.218306198798142\n",
       "1711. 0.319280865380882\n",
       "1712. -0.303396245212678\n",
       "1713. 1.71609708644211\n",
       "1714. 0.495986531900676\n",
       "1715. 0.235135309895265\n",
       "1716. -0.177177911984254\n",
       "1717. -0.959731578000485\n",
       "1718. -0.429614578441103\n",
       "1719. -0.202421578629939\n",
       "1720. -0.067788689852953\n",
       "1721. 0.201477087701019\n",
       "1722. 0.41184097641506\n",
       "1723. -0.067788689852953\n",
       "1724. -0.505345578378157\n",
       "1725. -0.597905689412335\n",
       "1726. -0.522174689475281\n",
       "1727. -0.774611355932129\n",
       "1728. -0.135105134241446\n",
       "1729. 0.630619420677662\n",
       "1730. -1.06912080013179\n",
       "1731. 0.100502421118279\n",
       "1732. -0.000472245464459984\n",
       "1733. -0.303396245212678\n",
       "1734. -0.740953133737883\n",
       "1735. -0.875586022514869\n",
       "1736. -0.825098689223499\n",
       "1737. 0.832568753843141\n",
       "1738. 0.125746087763964\n",
       "1739. -0.429614578441103\n",
       "1740. -0.698880355995075\n",
       "1741. -0.404370911795418\n",
       "1742. -0.614734800509459\n",
       "1743. -0.690465800446513\n",
       "1744. -0.951317022451923\n",
       "1745. 0.0920878655697179\n",
       "1746. -0.858756911417746\n",
       "1747. 0.782081420551771\n",
       "1748. 1.42158764224245\n",
       "1749. 1.15232186468848\n",
       "1750. -0.614734800509459\n",
       "1751. -0.757782244835006\n",
       "1752. -0.135105134241446\n",
       "1753. 2.59962541904108\n",
       "1754. -0.757782244835006\n",
       "1755. -0.522174689475281\n",
       "1756. 0.0163568656326633\n",
       "1757. 1.42158764224245\n",
       "1758. -0.606320244960897\n",
       "1759. -0.682051244897951\n",
       "1760. -0.707294911543636\n",
       "1761. -0.62314935605802\n",
       "1762. 0.218306198798142\n",
       "1763. -0.816684133674937\n",
       "1764. -0.387541800698295\n",
       "1765. -0.892415133611992\n",
       "1766. 1.08500542029999\n",
       "1767. -0.631563911606582\n",
       "1768. 0.336109976478005\n",
       "1769. 2.178897641613\n",
       "1770. -0.581076578315212\n",
       "1771. 1.00085986481437\n",
       "1772. -0.345469022955487\n",
       "1773. -0.57266202276665\n",
       "1774. 0.0752587544725946\n",
       "1775. 3.55888475157711\n",
       "1776. 0.167818865506772\n",
       "1777. 1.29536930901403\n",
       "1778. -0.799855022577814\n",
       "1779. 0.0920878655697179\n",
       "1780. 2.67535641897814\n",
       "1781. -0.345469022955487\n",
       "1782. 0.117331532215403\n",
       "1783. -0.67363668934939\n",
       "1784. -0.656807578252267\n",
       "1785. 0.453913754157868\n",
       "1786. 1.0176889759115\n",
       "1787. 0.201477087701019\n",
       "1788. -0.0930323564986378\n",
       "1789. 0.201477087701019\n",
       "1790. -0.597905689412335\n",
       "1791. -0.808269578126376\n",
       "1792. -0.892415133611992\n",
       "1793. -0.303396245212678\n",
       "1794. -1.19533913336021\n",
       "1795. -0.72412402264076\n",
       "1796. -0.539003800572404\n",
       "1797. -0.774611355932129\n",
       "1798. -0.783025911480691\n",
       "1799. -0.513760133926719\n",
       "1800. 0.453913754157868\n",
       "1801. -0.429614578441103\n",
       "1802. -0.715709467092198\n",
       "1803. 0.681106753969032\n",
       "1804. -0.808269578126376\n",
       "1805. -0.841927800320622\n",
       "1806. -0.900829689160554\n",
       "1807. -0.429614578441103\n",
       "1808. -1.01021891129185\n",
       "1809. -0.471687356183911\n",
       "1810. -0.135105134241446\n",
       "1811. 0.294037198735197\n",
       "1812. -0.387541800698295\n",
       "1813. -0.682051244897951\n",
       "1814. 1.44683130888814\n",
       "1815. -0.900829689160554\n",
       "1816. -0.26132346746987\n",
       "1817. 0.790495976100333\n",
       "1818. 2.72584375226951\n",
       "1819. 0.916714309328757\n",
       "1820. -0.757782244835006\n",
       "1821. -0.286567134115555\n",
       "1822. -0.67363668934939\n",
       "1823. -0.0930323564986378\n",
       "1824. 0.31086630983232\n",
       "1825. -0.715709467092198\n",
       "1826. -0.648393022703705\n",
       "1827. -0.555832911669527\n",
       "1828. 0.117331532215403\n",
       "1829. -0.67363668934939\n",
       "1830. 0.453913754157868\n",
       "1831. -0.589491133863774\n",
       "1832. -0.429614578441103\n",
       "1833. 0.0752587544725946\n",
       "1834. 1.43000219779102\n",
       "1835. -0.757782244835006\n",
       "1836. -0.219250689727062\n",
       "1837. -0.62314935605802\n",
       "1838. -0.429614578441103\n",
       "1839. 0.268793532089512\n",
       "1840. -0.421200022892541\n",
       "1841. -0.766196800383568\n",
       "1842. -0.841927800320622\n",
       "1843. 0.453913754157868\n",
       "1844. -0.00888680101302161\n",
       "1845. 0.495986531900676\n",
       "1846. 0.285622643186635\n",
       "1847. -0.841927800320622\n",
       "1848. -0.67363668934939\n",
       "1849. 0.580132087386292\n",
       "1850. 0.428670087512183\n",
       "1851. 0.0836733100211562\n",
       "1852. -0.749367689286444\n",
       "1853. -0.421200022892541\n",
       "1854. -0.942902466903362\n",
       "1855. -0.345469022955487\n",
       "1856. 0.495986531900676\n",
       "1857. 0.992445309265812\n",
       "1858. -0.665222133800828\n",
       "1859. -0.858756911417746\n",
       "1860. -0.57266202276665\n",
       "1861. -1.16168091116596\n",
       "1862. -0.252908911921309\n",
       "1863. -0.252908911921309\n",
       "1864. 0.0752587544725946\n",
       "1865. -0.942902466903362\n",
       "1866. -0.303396245212678\n",
       "1867. 1.46366041998526\n",
       "1868. -0.783025911480691\n",
       "1869. -0.219250689727062\n",
       "1870. 3.7355904180969\n",
       "1871. -0.000472245464459984\n",
       "1872. -0.135105134241446\n",
       "1873. -0.345469022955487\n",
       "1874. 0.6222048651291\n",
       "1875. 0.243549865443827\n",
       "1876. -1.10277902232603\n",
       "1877. -0.303396245212678\n",
       "1878. -0.252908911921309\n",
       "1879. 1.15232186468848\n",
       "1880. -0.968146133549047\n",
       "1881. 0.975616198168688\n",
       "1882. 0.218306198798142\n",
       "1883. 0.0163568656326633\n",
       "1884. 0.319280865380882\n",
       "1885. 1.38792942004821\n",
       "1886. -0.101446912047199\n",
       "1887. -1.18692457781165\n",
       "1888. 0.0331859767297865\n",
       "1889. -0.345469022955487\n",
       "1890. -0.858756911417746\n",
       "1891. -0.555832911669527\n",
       "1892. 0.226720754346704\n",
       "1893. -0.757782244835006\n",
       "1894. -0.547418356120965\n",
       "1895. -0.926073355806239\n",
       "1896. -0.429614578441103\n",
       "1897. -0.0341304676587065\n",
       "1898. 2.38926153032704\n",
       "1899. -0.101446912047199\n",
       "1900. 0.0247714211812249\n",
       "1901. -0.219250689727062\n",
       "1902. -0.471687356183911\n",
       "1903. -0.421200022892541\n",
       "1904. -0.665222133800828\n",
       "1905. -0.177177911984254\n",
       "1906. 3.2307170851832\n",
       "1907. -0.555832911669527\n",
       "1908. 0.369768198672251\n",
       "1909. -0.72412402264076\n",
       "1910. 0.630619420677662\n",
       "1911. -0.219250689727062\n",
       "1912. -0.202421578629939\n",
       "1913. 0.285622643186635\n",
       "1914. -0.471687356183911\n",
       "1915. 0.100502421118279\n",
       "1916. -0.900829689160554\n",
       "1917. 0.706350420614716\n",
       "1918. 0.916714309328757\n",
       "1919. -0.9344879113548\n",
       "1920. -0.429614578441103\n",
       "1921. 0.41184097641506\n",
       "1922. 0.201477087701019\n",
       "1923. 0.201477087701019\n",
       "1924. -0.513760133926719\n",
       "1925. -0.26132346746987\n",
       "1926. 2.72584375226951\n",
       "1927. -0.26132346746987\n",
       "1928. -0.00888680101302161\n",
       "1929. 0.369768198672251\n",
       "1930. -0.471687356183911\n",
       "1931. 1.50573319772807\n",
       "1932. 0.0331859767297865\n",
       "1933. 1.94329008625327\n",
       "1934. -1.12802268897172\n",
       "1935. 1.13549275359136\n",
       "1936. 1.98536286399608\n",
       "1937. 0.243549865443827\n",
       "1938. 0.184647976603896\n",
       "1939. 0.369768198672251\n",
       "1940. -0.244494356372747\n",
       "1941. -0.429614578441103\n",
       "1942. 0.201477087701019\n",
       "1943. -0.648393022703705\n",
       "1944. -0.303396245212678\n",
       "1945. 0.0752587544725946\n",
       "1946. -0.303396245212678\n",
       "1947. 0.0331859767297865\n",
       "1948. -0.0509595787558297\n",
       "1949. -0.522174689475281\n",
       "1950. -0.337054467406925\n",
       "1951. -0.135105134241446\n",
       "1952. -0.429614578441103\n",
       "1953. -0.833513244772061\n",
       "1954. 0.369768198672251\n",
       "1955. -0.690465800446513\n",
       "1956. 2.97828041872635\n",
       "1957. -0.387541800698295\n",
       "1958. -1.17851002226309\n",
       "1959. 0.201477087701019\n",
       "1960. -0.370712689601171\n",
       "1961. -0.709514269939694\n",
       "1962. 1.42490909404547\n",
       "1963. -0.296859086235896\n",
       "1964. -0.368006531702068\n",
       "1965. -0.424924488075005\n",
       "1966. -1.03679251908409\n",
       "1967. 1.8091052995628\n",
       "1968. 1.45336807223194\n",
       "1969. 0.215402521120544\n",
       "1970. 0.884188508502561\n",
       "1971. 0.499992302985233\n",
       "1972. -0.282629597142661\n",
       "1973. -1.40675923550818\n",
       "1974. -1.54905412644053\n",
       "1975. -0.211482151676489\n",
       "1976. -1.17908741001643\n",
       "1977. -1.29292332276231\n",
       "1978. 0.571139748451405\n",
       "1979. 0.130025586561137\n",
       "1980. 1.75218734318986\n",
       "1981. -1.94747982105109\n",
       "1982. -1.26446434457584\n",
       "1983. -1.23600536638937\n",
       "1984. 0.0873371192814343\n",
       "1985. 0.229632010213779\n",
       "1986. 0.656516683010811\n",
       "1987. 1.95140019049514\n",
       "1988. 1.19723726855372\n",
       "1989. -1.09371047545702\n",
       "1990. -1.91902084286462\n",
       "1991. -0.595678357193819\n",
       "1992. -0.0264987934644417\n",
       "1993. -0.638366824473522\n",
       "1994. 0.286549966586716\n",
       "1995. -0.538760400820881\n",
       "1996. -0.0976462389306138\n",
       "1997. 0.770352595756686\n",
       "1998. 0.571139748451405\n",
       "1999. -0.154564195303551\n",
       "2000. 1.93717070140191\n",
       "2001. -1.19331689910966\n",
       "2002. 0.115796097467903\n",
       "2003. -1.80518493011875\n",
       "2004. -0.624137335380287\n",
       "2005. 2.36405537419894\n",
       "2006. -0.92295660633821\n",
       "2007. -0.624137335380287\n",
       "2008. -0.510301422634412\n",
       "2009. 0.17271405384084\n",
       "2010. 0.613828215731107\n",
       "2011. 0.0304191629084958\n",
       "2012. 0.130025586561137\n",
       "2013. -0.268400108049427\n",
       "2014. -0.368006531702068\n",
       "2015. -1.40675923550818\n",
       "2016. 2.86208749246215\n",
       "2017. 0.0731076301881997\n",
       "2018. 3.11821829614037\n",
       "2019. 1.396450115859\n",
       "2020. 0.0304191629084958\n",
       "2021. 0.201173032027309\n",
       "2022. -0.481842444447943\n",
       "2023. 0.201173032027309\n",
       "2024. -1.7055785064661\n",
       "2025. 0.101566608374668\n",
       "2026. -0.325318064422364\n",
       "2027. -0.624137335380287\n",
       "2028. 0.542680770264935\n",
       "2029. -0.0834167498373792\n",
       "2030. -0.0407282825576763\n",
       "2031. -0.368006531702068\n",
       "2032. 0.613828215731107\n",
       "2033. 0.17271405384084\n",
       "2034. 1.06917186671461\n",
       "2035. -1.2075463882029\n",
       "2036. -1.12216945364349\n",
       "2037. -0.581448868100584\n",
       "2038. 1.11186033399431\n",
       "2039. 0.585369237544639\n",
       "2040. 1.58143347407105\n",
       "2041. -0.453383466261475\n",
       "2042. -0.666825802659991\n",
       "2043. 0.329238433866419\n",
       "2044. 1.48182705041841\n",
       "2045. -0.481842444447943\n",
       "2046. -0.0549577716509099\n",
       "2047. 4.83998647642173\n",
       "2048. 0.258090988400247\n",
       "2049. -0.424924488075005\n",
       "2050. -0.154564195303551\n",
       "2051. -0.737973248126163\n",
       "2052. -0.211482151676489\n",
       "2053. 0.00196018472202755\n",
       "2054. 0.898417997595796\n",
       "2055. -1.44944770278788\n",
       "2056. 0.243861499307012\n",
       "2057. -0.31108857532913\n",
       "2058. -1.80518493011875\n",
       "2059. 0.656516683010811\n",
       "2060. 0.628057704824342\n",
       "2061. 0.0161896738152622\n",
       "2062. 1.3537616485793\n",
       "2063. 0.158484564747606\n",
       "2064. 1.23992573583342\n",
       "2065. 0.386156390239356\n",
       "2066. -0.43915397716824\n",
       "2067. 0.215402521120544\n",
       "2068. -0.609907846287053\n",
       "2069. -1.34984127913524\n",
       "2070. 0.215402521120544\n",
       "2071. 0.514221792078467\n",
       "2072. 1.72372836500339\n",
       "2073. 1.86602325593574\n",
       "2074. -1.09371047545702\n",
       "2075. -0.481842444447943\n",
       "2076. 0.400385879332591\n",
       "2077. 0.00196018472202755\n",
       "2078. -0.851809160872038\n",
       "2079. 0.727664128476983\n",
       "2080. 2.73402209062304\n",
       "2081. 0.329238433866419\n",
       "2082. -1.23600536638937\n",
       "2083. -0.780661715405866\n",
       "2084. -1.02256302999085\n",
       "2085. 0.0304191629084958\n",
       "2086. -0.31108857532913\n",
       "2087. 0.0731076301881997\n",
       "2088. -1.12216945364349\n",
       "2089. 0.0161896738152622\n",
       "2090. 1.05494237762137\n",
       "2091. -0.752202737219397\n",
       "2092. -1.10793996455026\n",
       "2093. 0.400385879332591\n",
       "2094. -0.0976462389306138\n",
       "2095. -1.00833354089762\n",
       "2096. 0.798811573943156\n",
       "2097. 1.78064632137633\n",
       "2098. -1.74826697374581\n",
       "2099. 0.42884485751906\n",
       "2100. 0.542680770264935\n",
       "2101. 0.499992302985233\n",
       "2102. 1.45336807223194\n",
       "2103. 1.05494237762137\n",
       "2104. 0.343467922959654\n",
       "2105. -0.723743759032928\n",
       "2106. -0.339547553515599\n",
       "2107. 0.499992302985233\n",
       "2108. -0.211482151676489\n",
       "2109. 0.386156390239356\n",
       "2110. 0.9411064648755\n",
       "2111. -1.07948098636379\n",
       "2112. -1.17908741001643\n",
       "2113. -0.368006531702068\n",
       "2114. -0.0264987934644417\n",
       "2115. 0.898417997595796\n",
       "2116. -0.92295660633821\n",
       "2117. -0.510301422634412\n",
       "2118. 0.144255075654372\n",
       "2119. -1.96170931014432\n",
       "2120. 0.713434639383749\n",
       "2121. -0.794891204499101\n",
       "2122. -0.894497628151741\n",
       "2123. -1.06525149727055\n",
       "2124. 0.286549966586716\n",
       "2125. 1.7664168322831\n",
       "2126. -0.325318064422364\n",
       "2127. -0.0549577716509099\n",
       "2128. -1.30715281185554\n",
       "2129. 2.10792457052072\n",
       "2130. 0.158484564747606\n",
       "2131. -1.02256302999085\n",
       "2132. -1.02256302999085\n",
       "2133. 0.770352595756686\n",
       "2134. -0.624137335380287\n",
       "2135. -1.60597208281346\n",
       "2136. -0.837579671778804\n",
       "2137. 0.0304191629084958\n",
       "2138. 0.315008944773184\n",
       "2139. 0.485762813891998\n",
       "2140. -0.268400108049427\n",
       "2141. 0.258090988400247\n",
       "2142. 0.130025586561137\n",
       "2143. -0.794891204499101\n",
       "2144. -0.0407282825576763\n",
       "2145. 0.756123106663452\n",
       "2146. 0.386156390239356\n",
       "2147. 0.258090988400247\n",
       "2148. 0.443074346612295\n",
       "2149. 0.869959019409328\n",
       "2150. -1.12216945364349\n",
       "2151. 0.585369237544639\n",
       "2152. 1.46759756132517\n",
       "2153. -0.325318064422364\n",
       "2154. -1.09371047545702\n",
       "2155. -1.13639894273673\n",
       "2156. -1.2502348554826\n",
       "2157. -1.53482463734729\n",
       "2158. -0.154564195303551\n",
       "2159. -0.211482151676489\n",
       "2160. -0.154564195303551\n",
       "2161. -1.33561179004201\n",
       "2162. -1.56328361553376\n",
       "2163. -0.766432226312632\n",
       "2164. -1.19331689910966\n",
       "2165. 0.272320477493481\n",
       "2166. 1.28261420311313\n",
       "2167. 1.32530267039283\n",
       "2168. 0.186943542934075\n",
       "2169. 1.32530267039283\n",
       "2170. -0.979874562711148\n",
       "2171. 0.215402521120544\n",
       "2172. 0.371926901146123\n",
       "2173. -0.951415584524679\n",
       "2174. 1.73795785409663\n",
       "2175. -1.00833354089762\n",
       "2176. 1.06917186671461\n",
       "2177. 1.396450115859\n",
       "2178. 0.55691025935817\n",
       "2179. 0.144255075654372\n",
       "2180. 1.06917186671461\n",
       "2181. 0.272320477493481\n",
       "2182. -0.382236020795302\n",
       "2183. -0.43915397716824\n",
       "2184. -0.126105217117082\n",
       "2185. 0.0161896738152622\n",
       "2186. 3.74431581624268\n",
       "2187. -1.10793996455026\n",
       "2188. 0.485762813891998\n",
       "2189. 0.0731076301881997\n",
       "2190. -0.368006531702068\n",
       "2191. -1.69134901737287\n",
       "2192. 0.969565443061968\n",
       "2193. 0.670746172104045\n",
       "2194. -0.410694998981771\n",
       "2195. 0.642287193917577\n",
       "2196. -1.02256302999085\n",
       "2197. -1.74826697374581\n",
       "2198. 0.315008944773184\n",
       "2199. -1.60597208281346\n",
       "2200. -0.752202737219397\n",
       "2201. 0.528451281171701\n",
       "2202. 1.8517937668425\n",
       "2203. 0.0873371192814343\n",
       "2204. -1.32138230094877\n",
       "2205. -1.02256302999085\n",
       "2206. 0.343467922959654\n",
       "2207. -0.752202737219397\n",
       "2208. 0.727664128476983\n",
       "2209. 1.31107318129959\n",
       "2210. 1.08340135580784\n",
       "2211. 1.90871172321544\n",
       "2212. 0.528451281171701\n",
       "2213. -0.595678357193819\n",
       "2214. -0.424924488075005\n",
       "2215. -1.13639894273673\n",
       "2216. -0.538760400820881\n",
       "2217. -1.12216945364349\n",
       "2218. 0.0304191629084958\n",
       "2219. 0.485762813891998\n",
       "2220. -0.638366824473522\n",
       "2221. -0.382236020795302\n",
       "2222. -1.56328361553376\n",
       "2223. -1.06525149727055\n",
       "2224. -0.211482151676489\n",
       "2225. -0.396465509888536\n",
       "2226. -1.91902084286462\n",
       "2227. -1.15062843182996\n",
       "2228. 0.0161896738152622\n",
       "2229. -2.1182336901699\n",
       "2230. -0.965645073617914\n",
       "2231. -0.325318064422364\n",
       "2232. -0.467612955354709\n",
       "2233. 1.16877829036725\n",
       "2234. 0.0304191629084958\n",
       "2235. 0.457303835705529\n",
       "2236. 0.471533324798763\n",
       "2237. 0.898417997595796\n",
       "2238. -0.0976462389306138\n",
       "2239. 0.912647486689031\n",
       "2240. -0.154564195303551\n",
       "2241. 0.201173032027309\n",
       "2242. 1.49605653951164\n",
       "2243. 0.00196018472202755\n",
       "2244. -0.0407282825576763\n",
       "2245. -0.168793684396786\n",
       "2246. -0.453383466261475\n",
       "2247. 0.542680770264935\n",
       "2248. -1.07948098636379\n",
       "2249. 1.16877829036725\n",
       "2250. 0.642287193917577\n",
       "2251. -0.880268139058507\n",
       "2252. -0.994104051804382\n",
       "2253. 0.784582084849921\n",
       "2254. -0.154564195303551\n",
       "2255. -0.254170618956192\n",
       "2256. 0.17271405384084\n",
       "2257. -0.510301422634412\n",
       "2258. 0.229632010213779\n",
       "2259. -0.424924488075005\n",
       "2260. 0.343467922959654\n",
       "2261. -1.29292332276231\n",
       "2262. -0.624137335380287\n",
       "2263. 0.0304191629084958\n",
       "2264. 0.898417997595796\n",
       "2265. -0.652596313566756\n",
       "2266. 0.0731076301881997\n",
       "2267. -0.154564195303551\n",
       "2268. -0.752202737219397\n",
       "2269. -1.42098872460142\n",
       "2270. 0.300779455679951\n",
       "2271. 0.983794932155203\n",
       "2272. -1.93325033195785\n",
       "2273. 1.19723726855372\n",
       "2274. -1.29292332276231\n",
       "2275. -0.31108857532913\n",
       "2276. -0.0264987934644417\n",
       "2277. 0.727664128476983\n",
       "2278. 0.42884485751906\n",
       "2279. -1.84787339739845\n",
       "2280. 0.756123106663452\n",
       "2281. 1.48182705041841\n",
       "2282. 0.656516683010811\n",
       "2283. 0.201173032027309\n",
       "2284. -0.794891204499101\n",
       "2285. -0.211482151676489\n",
       "2286. 1.11186033399431\n",
       "2287. -1.93325033195785\n",
       "2288. -0.538760400820881\n",
       "2289. -0.780661715405866\n",
       "2290. 0.898417997595796\n",
       "2291. -1.37830025732171\n",
       "2292. 0.670746172104045\n",
       "2293. -0.681055291753225\n",
       "2294. -1.12216945364349\n",
       "2295. 0.101566608374668\n",
       "2296. 0.144255075654372\n",
       "2297. 0.158484564747606\n",
       "2298. 0.798811573943156\n",
       "2299. -1.60597208281346\n",
       "2300. 0.827270552129624\n",
       "2301. 0.158484564747606\n",
       "2302. 0.642287193917577\n",
       "2303. 0.68497566119728\n",
       "2304. 0.243861499307012\n",
       "2305. 0.130025586561137\n",
       "2306. -0.31108857532913\n",
       "2307. 0.0731076301881997\n",
       "2308. 0.343467922959654\n",
       "2309. 3.44549654528476\n",
       "2310. -1.26446434457584\n",
       "2311. -1.26446434457584\n",
       "2312. 1.63835143044399\n",
       "2313. 0.0161896738152622\n",
       "2314. -1.27869383366907\n",
       "2315. 1.8517937668425\n",
       "2316. 0.855729530316093\n",
       "2317. 0.770352595756686\n",
       "2318. -0.382236020795302\n",
       "2319. -0.453383466261475\n",
       "2320. 0.201173032027309\n",
       "2321. 0.400385879332591\n",
       "2322. -0.666825802659991\n",
       "2323. 0.186943542934075\n",
       "2324. 0.699205150290514\n",
       "2325. -0.268400108049427\n",
       "2326. -0.496071933541177\n",
       "2327. -0.951415584524679\n",
       "2328. 0.115796097467903\n",
       "2329. 0.101566608374668\n",
       "2330. 0.343467922959654\n",
       "2331. 0.713434639383749\n",
       "2332. -0.538760400820881\n",
       "2333. 0.855729530316093\n",
       "2334. 0.42884485751906\n",
       "2335. -0.666825802659991\n",
       "2336. 1.62412194135075\n",
       "2337. -0.581448868100584\n",
       "2338. -0.809120693592335\n",
       "2339. 0.499992302985233\n",
       "2340. 1.31107318129959\n",
       "2341. -0.325318064422364\n",
       "2342. -0.652596313566756\n",
       "2343. 1.06917186671461\n",
       "2344. -0.43915397716824\n",
       "2345. 1.88025274502897\n",
       "2346. 0.471533324798763\n",
       "2347. 0.841500041222858\n",
       "2348. 1.45336807223194\n",
       "2349. 0.485762813891998\n",
       "2350. -0.666825802659991\n",
       "2351. -0.0264987934644417\n",
       "2352. -0.979874562711148\n",
       "2353. -1.03055930843226\n",
       "2354. 5.10858224726345\n",
       "2355. -0.796108357931857\n",
       "2356. -1.05660941404341\n",
       "2357. -0.361939931079261\n",
       "2358. 0.18511228675501\n",
       "2359. 0.080911864310387\n",
       "2360. -0.984248009567981\n",
       "2361. 0.0172338283720062\n",
       "2362. 0.523763659700034\n",
       "2363. -0.778741620857753\n",
       "2364. -0.920569973629601\n",
       "2365. -0.104333331146721\n",
       "2366. -0.804791726468909\n",
       "2367. 0.949248718015578\n",
       "2368. -0.741113690530528\n",
       "2369. 1.28211117860257\n",
       "2370. 2.50936059850591\n",
       "2371. -0.729535865814459\n",
       "2372. 0.572969414743329\n",
       "2373. -0.0927555064306515\n",
       "2374. 0.00855045983495428\n",
       "2375. -0.52402947710423\n",
       "2376. -0.162222454727067\n",
       "2377. 0.564286046206277\n",
       "2378. -0.778741620857753\n",
       "2379. 1.2705333538865\n",
       "2380. -1.01319257135815\n",
       "2381. 0.509291378804948\n",
       "2382. -0.547185126536368\n",
       "2383. -0.966881272493878\n",
       "2384. 0.995560016879855\n",
       "2385. -0.324312000752036\n",
       "2386. -0.845314112975151\n",
       "2387. 0.706114398978125\n",
       "2388. 0.506396922625931\n",
       "2389. -0.576129688326541\n",
       "2390. -1.0710816949385\n",
       "2391. -0.231689403023482\n",
       "2392. -0.758480427604632\n",
       "2393. 0.688747661904021\n",
       "2394. -0.775847164678735\n",
       "2395. -0.579024144505559\n",
       "2396. -0.483507090597988\n",
       "2397. -0.573235232147524\n",
       "2398. -0.694802391666251\n",
       "2399. 0.804525909064713\n",
       "2400. -0.683224566950182\n",
       "2401. -0.541396214178334\n",
       "2402. -0.799002814110874\n",
       "2403. -0.937936710703705\n",
       "2404. 0.0577562148782485\n",
       "2405. -0.958197903956826\n",
       "2406. 0.188006742934027\n",
       "2407. -0.868469762407289\n",
       "2408. 0.682958749545986\n",
       "2409. -0.344573194005157\n",
       "2410. -0.078283225535565\n",
       "2411. -0.205639297412326\n",
       "2412. -0.758480427604632\n",
       "2413. -0.347467650184174\n",
       "2414. -0.469034809702901\n",
       "2415. -0.483507090597988\n",
       "2416. 0.358779657496048\n",
       "2417. -1.25922134657463\n",
       "2418. 0.214056848545183\n",
       "2419. 0.0259171969090581\n",
       "2420. -1.0537149578644\n",
       "2421. -0.593496425400645\n",
       "2422. -0.827947375901047\n",
       "2423. 2.53830516029608\n",
       "2424. -0.359045474900243\n",
       "2425. 1.92757490652343\n",
       "2426. 0.47455790465674\n",
       "2427. 0.329835095705875\n",
       "2428. 0.897148506793267\n",
       "2429. -0.851103025333185\n",
       "2430. 0.85083720792899\n",
       "2431. -0.923464429808618\n",
       "2432. -1.03055930843226\n",
       "2433. 0.575863870922346\n",
       "2434. -0.0811776817145823\n",
       "2435. 0.0548617586992312\n",
       "2436. 0.448507799045585\n",
       "2437. -0.442984704091745\n",
       "2438. 0.567180502385294\n",
       "2439. -0.590601969221628\n",
       "2440. 0.584547239459398\n",
       "2441. 0.266157059767494\n",
       "2442. 2.30964312215371\n",
       "2443. 0.338518464242927\n",
       "2444. -0.469034809702901\n",
       "2445. -0.431406879375676\n",
       "2446. -0.370623299616313\n",
       "2447. 0.448507799045585\n",
       "2448. 1.10554935168251\n",
       "2449. -1.07976506347555\n",
       "2450. -0.833736288259082\n",
       "2451. -0.576129688326541\n",
       "2452. 0.237212497977321\n",
       "2453. -0.677435654592147\n",
       "2454. -0.26642287717169\n",
       "2455. -0.761374883783649\n",
       "2456. 0.633752994502692\n",
       "2457. -0.0261830143132534\n",
       "2458. -0.170905823264119\n",
       "2459. 1.5889235335784\n",
       "2460. 0.47455790465674\n",
       "2461. 0.413774324897377\n",
       "2462. -1.2215934162474\n",
       "2463. 5.22725495060316\n",
       "2464. -1.25632689039561\n",
       "2465. -0.82505291972203\n",
       "2466. 0.17353446203894\n",
       "2467. -0.665857829876078\n",
       "2468. 0.182217830575992\n",
       "2469. -0.22300603448643\n",
       "2470. 2.30095975361666\n",
       "2471. -0.561657407431455\n",
       "2472. -0.278000701887759\n",
       "2473. -0.697696847845268\n",
       "2474. -0.793213901752839\n",
       "2475. 1.16633293144188\n",
       "2476. 0.381935306928187\n",
       "2477. 2.40226571988227\n",
       "2478. -0.648491092801974\n",
       "2479. 1.3718393201521\n",
       "2480. -1.14344309941393\n",
       "2481. -0.292472982782846\n",
       "2482. 0.445613342866567\n",
       "2483. -0.199850385054292\n",
       "2484. 1.0360824033861\n",
       "2485. -0.703485760203303\n",
       "2486. -0.755585971425614\n",
       "2487. 0.358779657496048\n",
       "2488. 0.277734884483564\n",
       "2489. 0.824787102317834\n",
       "2490. -0.529818389462264\n",
       "2491. -0.752691515246597\n",
       "2492. -0.257739508634638\n",
       "2493. 0.677169837187952\n",
       "2494. 2.02888087278903\n",
       "2495. 0.26036814740946\n",
       "2496. 0.489030185551827\n",
       "2497. -0.538501757999316\n",
       "2498. -0.00881627723914957\n",
       "2499. -0.321417544573019\n",
       "2500. -0.292472982782846\n",
       "2501. -1.06239832640145\n",
       "2502. -0.891625411839428\n",
       "2503. -0.570340775968507\n",
       "2504. -1.10002625672867\n",
       "2505. 2.51225505468492\n",
       "2506. 1.01871566631199\n",
       "2507. 0.237212497977321\n",
       "2508. -0.260633964813655\n",
       "2509. 0.297996077736685\n",
       "2510. -0.602179793937697\n",
       "2511. -0.691907935487234\n",
       "2512. -1.07976506347555\n",
       "2513. 0.0114449160139716\n",
       "2514. 0.601913976533502\n",
       "2515. -1.15791538030902\n",
       "2516. 0.489030185551827\n",
       "2517. -1.14633755559295\n",
       "2518. -1.16080983648804\n",
       "2519. -1.03345376461128\n",
       "2520. -0.761374883783649\n",
       "2521. -0.764269339962666\n",
       "2522. 1.07081587753431\n",
       "2523. -0.14775017383198\n",
       "2524. 0.434035518150498\n",
       "2525. -0.503768283851109\n",
       "2526. 0.379040850749169\n",
       "2527. -0.70638021638232\n",
       "2528. 0.164851093501889\n",
       "2529. 1.2705333538865\n",
       "2530. -0.419829054659607\n",
       "2531. 1.01871566631199\n",
       "2532. 0.17353446203894\n",
       "2533. -0.399567861406486\n",
       "2534. -0.069599856998513\n",
       "2535. -0.628229899548853\n",
       "2536. -0.836630744438099\n",
       "2537. 4.67151936423183\n",
       "2538. 0.0635451272362831\n",
       "2539. -0.862680850049255\n",
       "2540. 0.847942751749972\n",
       "2541. 0.0143393721929889\n",
       "2542. -0.648491092801974\n",
       "2543. -0.04065529520834\n",
       "2544. 1.44130626844852\n",
       "2545. 0.862415032645059\n",
       "2546. 1.22711651120124\n",
       "2547. 2.15623694466579\n",
       "2548. -0.874258674765324\n",
       "2549. -0.920569973629601\n",
       "2550. -0.205639297412326\n",
       "2551. 1.23290542355927\n",
       "2552. -0.228794946844465\n",
       "2553. -0.387990036690417\n",
       "2554. -0.173800279443136\n",
       "2555. 3.11719639609954\n",
       "2556. 1.21843314266419\n",
       "2557. -0.686119023129199\n",
       "2558. -0.00881627723914957\n",
       "2559. 0.517974747342\n",
       "2560. 0.0143393721929889\n",
       "2561. 1.60050135829447\n",
       "2562. -0.772952708499718\n",
       "2563. 0.0317061092670927\n",
       "2564. -0.767163796141684\n",
       "2565. -0.880047587123359\n",
       "2566. -0.0464442075663746\n",
       "2567. 0.10985642610056\n",
       "2568. -0.078283225535565\n",
       "2569. -0.0203941019552188\n",
       "2570. -0.74979705906758\n",
       "2571. -0.564551863610472\n",
       "2572. -0.691907935487234\n",
       "2573. -0.839525200617116\n",
       "2574. 0.080911864310387\n",
       "2575. 0.0114449160139716\n",
       "2576. -0.0753887693565476\n",
       "2577. -0.848208569154168\n",
       "2578. 5.49065046289373\n",
       "2579. 0.390618675465239\n",
       "2580. -0.558762951252438\n",
       "2581. -0.0377608390293226\n",
       "2582. -0.689013479308216\n",
       "2583. -0.312734176035967\n",
       "2584. -0.411145686122555\n",
       "2585. -0.0724943131775303\n",
       "2586. -0.460351441165849\n",
       "2587. 1.38341714486817\n",
       "2588. -0.182483647980188\n",
       "2589. 0.607702888891536\n",
       "2590. 0.526658115879052\n",
       "2591. -0.205639297412326\n",
       "2592. -0.735324778172493\n",
       "2593. 0.222740217082235\n",
       "2594. 0.138800987890733\n",
       "2595. 0.544024852953156\n",
       "2596. -0.165116910906084\n",
       "2597. -1.04503158932734\n",
       "2598. -0.518240564746195\n",
       "2599. -0.628229899548853\n",
       "2600. -0.839525200617116\n",
       "2601. -0.457456984986832\n",
       "2602. 0.0374950216251273\n",
       "2603. 1.84074122115291\n",
       "2604. 0.306679446273737\n",
       "2605. 1.79732437846765\n",
       "2606. 0.0693340395943177\n",
       "2607. -1.04213713314833\n",
       "2608. 0.914515243867371\n",
       "2609. -0.607968706295732\n",
       "2610. 0.622175169786623\n",
       "2611. -0.605074250116714\n",
       "2612. 0.489030185551827\n",
       "2613. 1.2879000909606\n",
       "2614. -0.914781061271566\n",
       "2615. -1.06818723875948\n",
       "2616. -0.73821923435151\n",
       "2617. 0.717692223694194\n",
       "2618. 0.170640005859923\n",
       "2619. -0.972670184851912\n",
       "2620. -0.63112435572787\n",
       "2621. -0.648491092801974\n",
       "2622. -1.2042266791733\n",
       "2623. -0.0869665940726169\n",
       "2624. 0.561391590027259\n",
       "2625. 1.14028282583072\n",
       "2626. 2.1070311896225\n",
       "2627. 0.813209277601765\n",
       "2628. 1.2879000909606\n",
       "2629. 0.39930204400229\n",
       "2630. 0.0751229519523524\n",
       "2631. -1.0537149578644\n",
       "2632. -0.457456984986832\n",
       "2633. -0.289578526603828\n",
       "2634. 1.47893419877575\n",
       "2635. -1.05082050168538\n",
       "2636. -0.526923933283247\n",
       "2637. 0.196690111471079\n",
       "2638. -0.292472982782846\n",
       "2639. -0.150644630010998\n",
       "2640. -1.04792604550636\n",
       "2641. -0.0609164884614611\n",
       "2642. -0.353256562542209\n",
       "2643. -0.0753887693565476\n",
       "2644. 0.651119731576796\n",
       "2645. -0.321417544573019\n",
       "2646. -1.26790471511168\n",
       "2647. -0.535607301820299\n",
       "2648. -0.926358885987635\n",
       "2649. -0.269317333350707\n",
       "2650. -0.940831166882722\n",
       "2651. 1.06792142135529\n",
       "2652. -0.703485760203303\n",
       "2653. 0.839259383212921\n",
       "2654. 0.47455790465674\n",
       "2655. 1.82626894025782\n",
       "2656. -1.00740365900012\n",
       "2657. 3.40374755782225\n",
       "2658. 0.607702888891536\n",
       "2659. 0.460085623761654\n",
       "2660. 0.104067513742525\n",
       "2661. -0.335889825468105\n",
       "2662. 0.489030185551827\n",
       "2663. 2.12729238287562\n",
       "2664. -0.118805612041807\n",
       "2665. -0.732430321993476\n",
       "2666. -1.11449853762376\n",
       "2667. -0.668752286055095\n",
       "2668. 0.202479023829114\n",
       "2669. 0.764003522558471\n",
       "2670. 0.0982786013844908\n",
       "2671. -0.770058252320701\n",
       "2672. -0.801897270289891\n",
       "2673. -0.509557196209143\n",
       "2674. -0.466140353523884\n",
       "2675. -0.82505291972203\n",
       "2676. -1.18107102974116\n",
       "2677. 0.364568569854083\n",
       "2678. 1.00713784159592\n",
       "2679. -1.08265951965457\n",
       "2680. 0.497713554088879\n",
       "2681. 0.599019520354484\n",
       "2682. -1.12607636233983\n",
       "2683. -0.220111578307413\n",
       "2684. -0.196955928875274\n",
       "2685. -0.761374883783649\n",
       "2686. -0.836630744438099\n",
       "2687. -0.165116910906084\n",
       "2688. -0.735324778172493\n",
       "2689. -1.10292071290769\n",
       "2690. -0.819264007363995\n",
       "2691. -1.06529278258047\n",
       "2692. 1.84942458968996\n",
       "2693. 2.22570389296221\n",
       "2694. -1.03634822079029\n",
       "2695. 0.329835095705875\n",
       "2696. -0.885836499481393\n",
       "2697. -0.269317333350707\n",
       "2698. -1.03924267696931\n",
       "2699. 0.312468358631771\n",
       "2700. -0.689013479308216\n",
       "2701. 1.03318794720708\n",
       "2702. 0.263262603588477\n",
       "2703. -0.552974038894403\n",
       "2704. -0.454562528807815\n",
       "2705. 0.196690111471079\n",
       "2706. 0.88267622589818\n",
       "2707. -0.544290670357351\n",
       "2708. 1.05055468428118\n",
       "2709. -0.243267227739551\n",
       "2710. -1.14344309941393\n",
       "2711. -0.73821923435151\n",
       "2712. 0.2169513047242\n",
       "2713. -0.11591115586279\n",
       "2714. -1.17238766120411\n",
       "2715. -1.0045092028211\n",
       "2716. 0.436929974329515\n",
       "2717. -0.660068917518043\n",
       "2718. -0.243267227739551\n",
       "2719. -0.495084915314057\n",
       "2720. 0.876887313540146\n",
       "2721. 1.29368900331864\n",
       "2722. -0.312734176035967\n",
       "2723. -0.677435654592147\n",
       "2724. -0.503768283851109\n",
       "2725. -0.787424989394805\n",
       "2726. -0.078283225535565\n",
       "2727. -0.579024144505559\n",
       "2728. 0.355885201317031\n",
       "2729. -0.280895158066776\n",
       "2730. -0.0232885581342361\n",
       "2731. -0.202744841233309\n",
       "2732. 0.758214610200436\n",
       "2733. -0.356151018721226\n",
       "2734. -0.880047587123359\n",
       "2735. 1.88415806383817\n",
       "2736. -0.101438874967703\n",
       "2737. 1.65839048187482\n",
       "2738. -0.332995369289088\n",
       "2739. -0.758480427604632\n",
       "2740. -0.871364218586307\n",
       "2741. 1.54550669089314\n",
       "2742. 0.703219942799107\n",
       "2743. -1.01898148371619\n",
       "2744. -0.804791726468909\n",
       "2745. -0.967063231434636\n",
       "2746. 0.209317797959863\n",
       "2747. -0.476904469186928\n",
       "2748. 2.1699528469507\n",
       "2749. 2.75814336164795\n",
       "2750. 1.97388934205161\n",
       "2751. 0.01325429306078\n",
       "2752. 0.209317797959863\n",
       "2753. 0.111286045510322\n",
       "2754. -0.378872716737387\n",
       "2755. 1.97388934205161\n",
       "2756. 0.993571817556197\n",
       "2757. -0.869031478985095\n",
       "2758. 2.56207985674886\n",
       "2759. -0.280840964287845\n",
       "2760. -0.869031478985095\n",
       "2761. 0.209317797959863\n",
       "2762. 2.46404810429932\n",
       "2763. -0.476904469186928\n",
       "2764. 2.26798459940024\n",
       "2765. -0.869031478985095\n",
       "2766. -0.476904469186928\n",
       "2767. -0.0847774593887617\n",
       "2768. 2.6601116091984\n",
       "2769. 1.09160357000574\n",
       "2770. 0.993571817556197\n",
       "2771. 0.01325429306078\n",
       "2772. -0.869031478985095\n",
       "2773. -0.672967974086012\n",
       "2774. -0.57493622163647\n",
       "2775. -0.378872716737387\n",
       "2776. -0.280840964287845\n",
       "2777. -0.476904469186928\n",
       "2778. -0.770999726535553\n",
       "2779. 0.503413055308488\n",
       "2780. -0.378872716737387\n",
       "2781. -0.476904469186928\n",
       "2782. 1.18963532245528\n",
       "2783. 0.307349550409405\n",
       "2784. 1.09160357000574\n",
       "2785. -0.967063231434636\n",
       "2786. 0.895540065106655\n",
       "2787. -0.869031478985095\n",
       "2788. -0.770999726535553\n",
       "2789. 0.01325429306078\n",
       "2790. -0.672967974086012\n",
       "2791. -0.967063231434636\n",
       "2792. 0.60144480775803\n",
       "2793. -0.57493622163647\n",
       "2794. -0.672967974086012\n",
       "2795. -0.672967974086012\n",
       "2796. 1.4837305798039\n",
       "2797. -0.770999726535553\n",
       "2798. 0.797508312657113\n",
       "2799. -0.967063231434636\n",
       "2800. -0.57493622163647\n",
       "2801. -0.770999726535553\n",
       "2802. -0.476904469186928\n",
       "2803. -0.0847774593887617\n",
       "2804. -0.770999726535553\n",
       "2805. 0.895540065106655\n",
       "2806. 0.209317797959863\n",
       "2807. -0.0847774593887617\n",
       "2808. -0.476904469186928\n",
       "2809. 0.01325429306078\n",
       "2810. -0.967063231434636\n",
       "2811. -0.869031478985095\n",
       "2812. -0.280840964287845\n",
       "2813. -0.869031478985095\n",
       "2814. -0.770999726535553\n",
       "2815. 0.307349550409405\n",
       "2816. -0.672967974086012\n",
       "2817. 1.09160357000574\n",
       "2818. -0.770999726535553\n",
       "2819. -0.967063231434636\n",
       "2820. -0.770999726535553\n",
       "2821. -0.869031478985095\n",
       "2822. 1.58176233225345\n",
       "2823. 1.38569882735436\n",
       "2824. -0.378872716737387\n",
       "2825. 0.993571817556197\n",
       "2826. -0.182809211838303\n",
       "2827. -0.182809211838303\n",
       "2828. -0.770999726535553\n",
       "2829. 0.209317797959863\n",
       "2830. 0.503413055308488\n",
       "2831. -0.476904469186928\n",
       "2832. -0.770999726535553\n",
       "2833. 2.85617511409749\n",
       "2834. 0.209317797959863\n",
       "2835. 0.01325429306078\n",
       "2836. -0.57493622163647\n",
       "2837. 0.895540065106655\n",
       "2838. -0.182809211838303\n",
       "2839. -0.770999726535553\n",
       "2840. -0.476904469186928\n",
       "2841. -0.182809211838303\n",
       "2842. -0.378872716737387\n",
       "2843. 2.36601635184978\n",
       "2844. 2.56207985674886\n",
       "2845. -0.967063231434636\n",
       "2846. -0.672967974086012\n",
       "2847. 0.503413055308488\n",
       "2848. 0.699476560207572\n",
       "2849. -0.57493622163647\n",
       "2850. 0.111286045510322\n",
       "2851. -0.967063231434636\n",
       "2852. 2.95420686654703\n",
       "2853. -0.476904469186928\n",
       "2854. -0.869031478985095\n",
       "2855. 0.01325429306078\n",
       "2856. -0.672967974086012\n",
       "2857. 1.4837305798039\n",
       "2858. -0.869031478985095\n",
       "2859. -0.770999726535553\n",
       "2860. 1.97388934205161\n",
       "2861. -0.869031478985095\n",
       "2862. 0.209317797959863\n",
       "2863. -0.182809211838303\n",
       "2864. -0.770999726535553\n",
       "2865. 0.307349550409405\n",
       "2866. -0.672967974086012\n",
       "2867. 1.28766707490482\n",
       "2868. -0.672967974086012\n",
       "2869. 1.97388934205161\n",
       "2870. 0.307349550409405\n",
       "2871. 1.18963532245528\n",
       "2872. -0.967063231434636\n",
       "2873. -0.967063231434636\n",
       "2874. -0.57493622163647\n",
       "2875. -0.770999726535553\n",
       "2876. -0.869031478985095\n",
       "2877. 0.797508312657113\n",
       "2878. 0.60144480775803\n",
       "2879. 1.97388934205161\n",
       "2880. 0.307349550409405\n",
       "2881. -0.182809211838303\n",
       "2882. -0.476904469186928\n",
       "2883. 0.209317797959863\n",
       "2884. -0.967063231434636\n",
       "2885. -0.57493622163647\n",
       "2886. 0.01325429306078\n",
       "2887. -0.672967974086012\n",
       "2888. -0.280840964287845\n",
       "2889. -0.182809211838303\n",
       "2890. -0.672967974086012\n",
       "2891. 1.4837305798039\n",
       "2892. -0.57493622163647\n",
       "2893. 0.405381302858947\n",
       "2894. -0.182809211838303\n",
       "2895. 1.58176233225345\n",
       "2896. -0.967063231434636\n",
       "2897. -0.57493622163647\n",
       "2898. -0.0847774593887617\n",
       "2899. -0.869031478985095\n",
       "2900. -0.378872716737387\n",
       "2901. -0.57493622163647\n",
       "2902. -0.476904469186928\n",
       "2903. -0.0847774593887617\n",
       "2904. -0.280840964287845\n",
       "2905. 0.01325429306078\n",
       "2906. 1.18963532245528\n",
       "2907. -0.672967974086012\n",
       "2908. -0.0847774593887617\n",
       "2909. -0.770999726535553\n",
       "2910. 0.60144480775803\n",
       "2911. -0.57493622163647\n",
       "2912. -0.869031478985095\n",
       "2913. -0.476904469186928\n",
       "2914. 0.209317797959863\n",
       "2915. -0.869031478985095\n",
       "2916. 0.503413055308488\n",
       "2917. 1.77782583715253\n",
       "2918. -0.869031478985095\n",
       "2919. -0.476904469186928\n",
       "2920. -0.672967974086012\n",
       "2921. -0.280840964287845\n",
       "2922. 1.67979408470299\n",
       "2923. -0.182809211838303\n",
       "2924. -0.182809211838303\n",
       "2925. -0.0847774593887617\n",
       "2926. -0.0847774593887617\n",
       "2927. -0.869031478985095\n",
       "2928. 1.38569882735436\n",
       "2929. -0.57493622163647\n",
       "2930. -0.967063231434636\n",
       "2931. -0.57493622163647\n",
       "2932. -0.280840964287845\n",
       "2933. 2.6601116091984\n",
       "2934. -0.869031478985095\n",
       "2935. -0.869031478985095\n",
       "2936. 0.405381302858947\n",
       "2937. -0.672967974086012\n",
       "2938. -0.967063231434636\n",
       "2939. -0.57493622163647\n",
       "2940. -0.57493622163647\n",
       "2941. -0.672967974086012\n",
       "2942. 2.6601116091984\n",
       "2943. -0.280840964287845\n",
       "2944. 1.09160357000574\n",
       "2945. -0.967063231434636\n",
       "2946. 0.60144480775803\n",
       "2947. -0.57493622163647\n",
       "2948. 0.797508312657113\n",
       "2949. 0.405381302858947\n",
       "2950. -0.476904469186928\n",
       "2951. -0.280840964287845\n",
       "2952. -0.57493622163647\n",
       "2953. -0.869031478985095\n",
       "2954. -0.967063231434636\n",
       "2955. -0.967063231434636\n",
       "2956. -0.869031478985095\n",
       "2957. -0.280840964287845\n",
       "2958. -0.476904469186928\n",
       "2959. -0.967063231434636\n",
       "2960. -0.967063231434636\n",
       "2961. 0.503413055308488\n",
       "2962. 0.01325429306078\n",
       "2963. 0.699476560207572\n",
       "2964. -0.476904469186928\n",
       "2965. 1.18963532245528\n",
       "2966. 0.699476560207572\n",
       "2967. -0.869031478985095\n",
       "2968. -0.869031478985095\n",
       "2969. -0.672967974086012\n",
       "2970. -0.57493622163647\n",
       "2971. -0.280840964287845\n",
       "2972. -0.476904469186928\n",
       "2973. -0.869031478985095\n",
       "2974. -0.476904469186928\n",
       "2975. -0.770999726535553\n",
       "2976. -0.57493622163647\n",
       "2977. -0.672967974086012\n",
       "2978. -0.672967974086012\n",
       "2979. 1.97388934205161\n",
       "2980. 4.91484191553786\n",
       "2981. 1.67979408470299\n",
       "2982. 0.797508312657113\n",
       "2983. -0.967063231434636\n",
       "2984. -0.869031478985095\n",
       "2985. -0.57493622163647\n",
       "2986. -0.378872716737387\n",
       "2987. -0.182809211838303\n",
       "2988. 0.01325429306078\n",
       "2989. 0.797508312657113\n",
       "2990. 0.405381302858947\n",
       "2991. -0.280840964287845\n",
       "2992. -0.770999726535553\n",
       "2993. -0.672967974086012\n",
       "2994. -0.967063231434636\n",
       "2995. 2.6601116091984\n",
       "2996. -0.672967974086012\n",
       "2997. 1.38569882735436\n",
       "2998. -0.57493622163647\n",
       "2999. 2.36601635184978\n",
       "3000. 0.797508312657113\n",
       "3001. -0.967063231434636\n",
       "3002. 0.993571817556197\n",
       "3003. 0.405381302858947\n",
       "3004. -0.967063231434636\n",
       "3005. -0.967063231434636\n",
       "3006. -0.967063231434636\n",
       "3007. -0.672967974086012\n",
       "3008. -0.280840964287845\n",
       "3009. 2.1699528469507\n",
       "3010. 2.85617511409749\n",
       "3011. -0.57493622163647\n",
       "3012. -0.476904469186928\n",
       "3013. -0.967063231434636\n",
       "3014. -0.672967974086012\n",
       "3015. -0.869031478985095\n",
       "3016. -0.869031478985095\n",
       "3017. -0.182809211838303\n",
       "3018. -0.672967974086012\n",
       "3019. -0.770999726535553\n",
       "3020. 0.111286045510322\n",
       "3021. 1.18963532245528\n",
       "3022. -0.378872716737387\n",
       "3023. -0.57493622163647\n",
       "3024. -0.182809211838303\n",
       "3025. 0.60144480775803\n",
       "3026. 2.1699528469507\n",
       "3027. -0.280840964287845\n",
       "3028. 1.87585758960207\n",
       "3029. -0.57493622163647\n",
       "3030. -0.770999726535553\n",
       "3031. -0.280840964287845\n",
       "3032. 0.60144480775803\n",
       "3033. -0.280840964287845\n",
       "3034. -0.672967974086012\n",
       "3035. 0.111286045510322\n",
       "3036. -0.869031478985095\n",
       "3037. -0.967063231434636\n",
       "3038. 1.4837305798039\n",
       "3039. 0.60144480775803\n",
       "3040. 0.209317797959863\n",
       "3041. -0.869031478985095\n",
       "3042. -0.869031478985095\n",
       "3043. -0.770999726535553\n",
       "3044. -0.57493622163647\n",
       "3045. 0.405381302858947\n",
       "3046. 2.07192109450115\n",
       "3047. 2.07192109450115\n",
       "3048. -0.672967974086012\n",
       "3049. -0.57493622163647\n",
       "3050. 0.307349550409405\n",
       "3051. -0.869031478985095\n",
       "3052. -0.967063231434636\n",
       "3053. -0.476904469186928\n",
       "3054. 2.26798459940024\n",
       "3055. -0.869031478985095\n",
       "3056. -0.57493622163647\n",
       "3057. -0.378872716737387\n",
       "3058. -0.770999726535553\n",
       "3059. -0.672967974086012\n",
       "3060. 0.503413055308488\n",
       "3061. 0.895540065106655\n",
       "3062. 1.87585758960207\n",
       "3063. -0.770999726535553\n",
       "3064. -0.280840964287845\n",
       "3065. -0.967063231434636\n",
       "3066. -0.182809211838303\n",
       "3067. -0.672967974086012\n",
       "3068. -0.869031478985095\n",
       "3069. -0.770999726535553\n",
       "3070. 0.111286045510322\n",
       "3071. -0.280840964287845\n",
       "3072. -0.378872716737387\n",
       "3073. -0.378872716737387\n",
       "3074. -0.0847774593887617\n",
       "3075. 0.209317797959863\n",
       "3076. -0.869031478985095\n",
       "3077. 1.09160357000574\n",
       "3078. -0.770999726535553\n",
       "3079. -0.378872716737387\n",
       "3080. -0.280840964287845\n",
       "3081. -0.869031478985095\n",
       "3082. -0.57493622163647\n",
       "3083. -0.869031478985095\n",
       "3084. 0.993571817556197\n",
       "3085. -0.378872716737387\n",
       "3086. 1.18963532245528\n",
       "3087. 0.895540065106655\n",
       "3088. -0.672967974086012\n",
       "3089. 1.18963532245528\n",
       "3090. 1.38569882735436\n",
       "3091. 1.77782583715253\n",
       "3092. 1.58176233225345\n",
       "3093. -0.869031478985095\n",
       "3094. -0.770999726535553\n",
       "3095. -0.869031478985095\n",
       "3096. -0.869031478985095\n",
       "3097. -0.57493622163647\n",
       "3098. -0.770999726535553\n",
       "3099. 1.4837305798039\n",
       "3100. -0.770999726535553\n",
       "3101. 1.18963532245528\n",
       "3102. 1.18963532245528\n",
       "3103. 0.01325429306078\n",
       "3104. -0.280840964287845\n",
       "3105. -0.476904469186928\n",
       "3106. -0.378872716737387\n",
       "3107. -0.869031478985095\n",
       "3108. -0.770999726535553\n",
       "3109. -0.672967974086012\n",
       "3110. 0.895540065106655\n",
       "3111. -0.967063231434636\n",
       "3112. 0.307349550409405\n",
       "3113. 0.01325429306078\n",
       "3114. -0.672967974086012\n",
       "3115. -0.967063231434636\n",
       "3116. 1.09160357000574\n",
       "3117. 1.09160357000574\n",
       "3118. -0.57493622163647\n",
       "3119. 0.307349550409405\n",
       "3120. -0.672967974086012\n",
       "3121. -0.869031478985095\n",
       "3122. -0.967063231434636\n",
       "3123. -0.967063231434636\n",
       "3124. 1.67979408470299\n",
       "3125. -0.476904469186928\n",
       "3126. -0.869031478985095\n",
       "3127. 0.797508312657113\n",
       "3128. 1.4837305798039\n",
       "3129. 0.111286045510322\n",
       "3130. 0.503413055308488\n",
       "3131. -0.280840964287845\n",
       "3132. -0.476904469186928\n",
       "3133. 0.60144480775803\n",
       "3134. -0.869031478985095\n",
       "3135. 3.15027037144611\n",
       "3136. -0.0847774593887617\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    pregnancies     glucose bloodpressure skinthickness       insulin\n",
       "4   -0.71651083 -1.08965329   -0.37317791   -0.58436292 -0.5221746895\n",
       "5   -1.02789913  0.46571891   -2.45382847    0.55670938  0.1005024211\n",
       "7   -0.09373423 -1.44609275   -1.65357826    0.27144131 -0.5726620228\n",
       "9   -0.40512253  2.40993414   -0.05307782    1.50760297  3.2559607518\n",
       "14  -0.71651083  2.15070545   -0.85332804   -0.58436292  5.8055710830\n",
       "15   0.52904237  1.40542294    0.10697222   -0.96472036  0.1594043100\n",
       "17  -1.02789913 -0.14994925    1.06727248    1.69778169  0.6222048651\n",
       "19  -0.71651083 -0.63600306   -3.25407869    0.84197746 -0.6147348005\n",
       "20  -0.71651083 -0.24716002   -0.05307782    0.08126259 -0.5053455784\n",
       "21  -0.09373423  0.10927944    1.38737257    1.12724554  0.6642776429\n",
       "25   2.39737216  0.66014043    1.86752270    0.36653067 -0.0846178010\n",
       "26   2.08598386  0.07687586   -0.05307782   -0.29909485 -0.3454690230\n",
       "28  -0.71651083 -0.83042459   -0.37317791   -1.34507779 -0.1351051342\n",
       "29   3.02014876  0.72494760    0.90722244   -0.96472036 -0.3875418007\n",
       "32  -0.09373423  1.14619424    0.42707231    0.65179874  0.7484231984\n",
       "33  -0.09373423 -1.12205687   -1.01337808   -1.72543523 -0.8587569114\n",
       "36   0.21765407 -0.63600306   -0.85332804    0.36653067  0.3024517543\n",
       "40   0.21765407 -0.37677436    0.10697222    1.69778169  0.4286700875\n",
       "41  -0.09373423  1.85907316   -0.53322795   -0.39418420 -0.7241240226\n",
       "44   1.77459556  1.56744087    3.14792305   -0.48927356  0.7063504206\n",
       "51  -0.71651083 -0.63600306    0.74717240   -1.72543523 -0.6231493561\n",
       "52  -0.71651083 -0.70081024   -1.65357826   -1.34507779 -1.0102189113\n",
       "53   0.52904237 -1.12205687   -0.37317791   -0.77454164 -1.1196081334\n",
       "54   1.46320726  1.72945881    1.54742262    0.46162002  1.2112237535\n",
       "55   1.15181896  0.88696554   -0.37317791    1.22233489  1.5646350866\n",
       "57   1.15181896  2.08589827   -0.21312786    0.93706682  1.2448819757\n",
       "58  -1.02789913 -0.73321383    1.38737257    2.93394335 -0.3875418007\n",
       "60  -1.02789913 -0.57119589   -0.53322795    1.12724554 -0.1182760231\n",
       "64  -0.40512253  0.59533325   -1.01337808    0.46162002 -0.2360798008\n",
       "69  -0.71651083 -0.89523176   -0.37317791   -1.53525651 -0.9933898002\n",
       "70   0.21765407  0.75735119    1.14729751   -0.20400549 -0.4716873562\n",
       "71  -0.40512253 -0.73321383   -0.37317791   -0.86963100 -0.5558329117\n",
       "72   0.52904237  0.53052608   -0.53322795    0.55670938 -0.1351051342\n",
       "74   0.21765407  0.20649021    1.22732253   -0.86963100  0.9587870871\n",
       "83   1.15181896 -1.28407481    0.58712235   -0.29909485 -0.7157094671\n",
       "86  -0.40512253 -0.40917795    0.26702227   -0.01382677 -0.2613234675\n",
       "88  -0.40512253 -0.73321383   -0.21312786   -0.39418420 -0.7157094671\n",
       "89   3.64292536  0.43331532   -0.05307782    0.27144131 -0.3875418007\n",
       "92   0.21765407  0.01206868    0.74717240   -1.34507779  0.1678188655\n",
       "93   1.15181896 -1.34888198    0.58712235    1.03215618 -0.9092442447\n",
       "95  -0.40512253  0.62773684    0.90722244   -1.05980971 -0.7746113559\n",
       "96   0.84043067  0.69254402    0.10697222   -0.20400549  0.6053757540\n",
       "98  -0.71651083 -1.67291786   -1.81362830   -1.05980971 -0.6736366893\n",
       "99   0.84043067 -0.96003894   -1.65357826    0.08126259 -0.7746113559\n",
       "100 -0.71651083 -0.02033490    1.54742262    2.07813912  0.5380593096\n",
       "104 -0.71651083 -1.34888198    0.10697222   -1.05980971 -0.9765606891\n",
       "106 -0.71651083  0.10927944   -1.17342813   -0.01382677 -0.0341304677\n",
       "108  0.21765407  0.69254402   -1.01337808   -0.10891613 -0.1351051342\n",
       "109 -0.09373423 -1.28407481   -1.01337808    0.17635195 -1.1616809112\n",
       "110 -1.02789913 -0.89523176    1.14729751   -0.39418420 -1.0102189113\n",
       "111 -0.09373423  1.56744087    0.10697222    0.36653067 -0.1771779120\n",
       "112  1.46320726  1.04898348   -0.69327800   -0.29909485  2.8520620855\n",
       "113 -0.71651083 -1.08965329    0.42707231    0.46162002 -1.0018043557\n",
       "115  1.15181896  1.21100141   -1.33347817    0.27144131  0.1594043100\n",
       "120  0.21765407 -0.76561741    0.42707231   -1.34507779 -0.8840005781\n",
       "121 -1.02789913  1.27580859    0.42707231    2.55358592 -0.4716873562\n",
       "123 -0.40512253 -0.50638871    0.26702227    0.08126259 -0.4716873562\n",
       "126 -0.71651083 -1.12205687   -3.25407869    1.22233489 -0.4801019117\n",
       "127 -0.09373423 -0.08514208   -0.05307782    0.08126259 -0.1771779120\n",
       "128 -0.71651083 -0.14994925   -1.01337808    0.65179874 -0.5221746895\n",
       "129 -0.71651083 -0.18235284    1.38737257   -0.48927356 -0.0930323565\n",
       "131  0.21765407  1.63224805   -0.05307782   -1.44016715  0.1005024211\n",
       "133 -0.09373423  1.53503729   -0.53322795    0.74688810  0.5801320874\n",
       "135 -0.40512253 -0.86282817   -0.21312786   -1.53525651 -0.9008296892\n",
       "136 -0.40512253  0.07687586   -0.85332804   -0.86963100 -0.1351051342\n",
       "137 -1.02789913 -0.73321383   -0.05307782   -0.29909485 -0.8924151336\n",
       "138 -1.02789913 -0.96003894   -0.85332804   -0.39418420 -0.5390038006\n",
       "140  0.52904237 -0.57119589    0.10697222   -0.01382677  1.4215876422\n",
       "143 -0.40512253 -0.47398513   -1.49352821   -0.29909485 -0.7830259115\n",
       "145  0.21765407  1.01657989   -0.69327800    0.17635195  1.0765908648\n",
       "148 -0.40512253 -0.53879230   -0.53322795    0.55670938 -0.3118108008\n",
       "151 -0.71651083  0.43331532    0.26702227    1.98304976  0.4034264209\n",
       "153  1.77459556  1.08138706    1.22732253   -0.10891613 -0.0088868010\n",
       "154 -0.71651083  0.98417630    0.90722244    1.22233489  2.7679165300\n",
       "157 -0.40512253 -0.76561741   -1.49352821   -1.34507779 -0.5221746895\n",
       "158 -0.71651083 -0.44158154   -1.17342813   -0.77454164 -0.1771779120\n",
       "159 -0.40512253 -1.12205687    0.26702227   -0.96472036 -0.8671714670\n",
       "160  4.26570196  1.30821218    0.10697222    1.12724554 -0.3538835785\n",
       "162  1.15181896 -0.66840665    0.26702227    1.03215618 -0.4296145784\n",
       "163 -1.02789913 -0.27956360    0.74717240    0.46162002  1.0850054203\n",
       "166  0.84043067 -0.60359948    0.26702227   -1.05980971 -0.0004722455\n",
       "170 -0.09373423 -0.37677436    1.54742262   -1.63034587 -0.6568075783\n",
       "172  0.84043067  0.36850814   -0.05307782   -0.58436292 -0.2192506897\n",
       "174 -0.71651083 -1.41368916   -0.85332804    1.22233489 -0.9092442447\n",
       "175 -0.40512253 -1.54330351   -0.53322795   -0.48927356 -0.8503423559\n",
       "176  1.46320726  1.82666957    0.10697222    1.22233489 -0.2192506897\n",
       "178 -1.02789913  0.20649021    3.14792305    1.60269233 -0.2192506897\n",
       "182 -1.02789913 -0.11754567   -0.53322795   -1.05980971 -0.5390038006\n",
       "187  1.46320726  1.89147675   -0.21312786    0.65179874  2.8520620855\n",
       "188 -0.71651083  0.17408662    2.18762279    1.12724554 -0.8250986892\n",
       "189  1.46320726 -0.44158154    0.42707231    0.93706682 -0.3538835785\n",
       "190  0.52904237  0.53052608    0.74717240    0.55670938  0.0331859767\n",
       "192  1.77459556  0.01206868   -0.05307782    1.41251361 -0.5221746895\n",
       "196  0.52904237  1.14619424    1.06727248    1.12724554  0.4539137542\n",
       "198 -0.09373423 -0.50638871   -0.69327800   -1.53525651 -0.9092442447\n",
       "199  0.21765407 -0.44158154   -0.53322795    1.41251361 -0.4801019117\n",
       "200  0.21765407  0.82215837   -0.85332804   -0.20400549  1.3626857534\n",
       "204 -0.40512253 -0.76561741   -0.05307782   -1.24998843 -0.9429024669\n",
       "205  0.84043067 -0.63600306    0.10697222    0.27144131  0.2856226432\n",
       "207  1.46320726  2.37753056    0.42707231   -0.01382677  1.0429326426\n",
       "209 -0.71651083 -0.86282817   -0.53322795   -0.20400549 -0.5810765783\n",
       "214 -1.02789913  0.56292967   -0.45320293   -0.29909485 -0.2192506897\n",
       "215  1.77459556 -0.34437078    0.90722244    0.27144131  0.1594043100\n",
       "216  2.70876046  0.91936913   -0.05307782    1.03215618  0.9672016426\n",
       "217  0.52904237 -0.44158154   -0.69327800    1.12724554 -0.2276652453\n",
       "218  0.84043067  0.07687586   -0.21312786    0.08126259 -0.3033962452\n",
       "221 -1.02789913  1.76186240   -0.85332804   -0.01382677  2.7090146412\n",
       "224  1.15181896  0.62773684   -0.85332804    0.36653067  0.2856226432\n",
       "225 -0.71651083 -0.73321383   -0.37317791   -1.34507779 -0.8419278003\n",
       "226 -0.71651083 -1.15446046    0.58712235   -0.20400549 -1.0438771335\n",
       "229  0.21765407  2.40993414   -0.05307782    0.93706682  4.9472864171\n",
       "230 -1.02789913 -0.18235284    0.74717240    0.17635195 -0.8671714670\n",
       "232  0.84043067  0.36850814    0.74717240    0.74688810  1.8002426419\n",
       "233 -0.71651083 -1.41368916    0.74717240   -0.39418420 -1.0018043557\n",
       "235 -0.09373423 -1.57570710   -0.21312786   -0.10891613 -0.9344879114\n",
       "237  1.15181896  1.89147675    1.06727248   -0.77454164  0.3024517543\n",
       "242  0.21765407 -1.02484611   -0.05307782    0.27144131 -0.5726620228\n",
       "244  0.84043067 -0.11754567   -1.65357826   -0.67945228  0.1678188655\n",
       "245 -0.40512253  0.75735119    0.42707231    0.55670938  0.3192808654\n",
       "248 -1.02789913  1.37301935    1.54742262    0.36653067  4.4087548620\n",
       "249  1.77459556  0.04447227   -0.05307782    0.36653067  2.0695084195\n",
       "253 -0.40512253 -1.05724970    0.74717240   -1.44016715 -0.8503423559\n",
       "255  2.70876046 -0.99244252   -0.69327800   -2.10579266  0.8578124205\n",
       "259 -0.71651083  2.28031980   -1.65357826   -1.24998843  1.8423154197\n",
       "260  2.39737216  1.04898348    0.42707231   -0.10891613 -0.0509595788\n",
       "261 -0.09373423  2.21551262   -0.21312786   -1.34507779 -0.2192506897\n",
       "266  0.52904237 -0.86282817    0.26702227   -1.05980971 -0.7493676893\n",
       "272 -0.40512253 -0.47398513   -0.69327800    0.27144131 -0.8419278003\n",
       "274 -0.71651083 -1.67291786    0.58712235    1.98304976 -0.9344879114\n",
       "276 -0.40512253 -0.73321383   -0.05307782    2.17322848 -0.8335132448\n",
       "278 -1.02789913 -0.60359948   -0.53322795   -0.58436292 -0.3370544674\n",
       "280 -0.40512253 -0.47398513   -0.69327800   -1.82052458  1.0261035315\n",
       "282  2.08598386  0.20649021    0.42707231   -0.10891613 -0.2865671341\n",
       "283  1.15181896  0.33610456    1.38737257   -1.34507779 -0.0088868010\n",
       "286  1.15181896  0.43331532    0.26702227   -0.29909485 -0.1771779120\n",
       "287  0.52904237  1.04898348    1.06727248    1.41251361  3.2727898629\n",
       "288 -0.71651083 -0.11754567    1.22732253    0.93706682  0.5380593096\n",
       "289  0.21765407 -0.86282817   -1.17342813   -1.15489907 -0.9008296892\n",
       "290  0.52904237 -0.47398513    0.10697222    1.31742425 -0.6820512449\n",
       "291 -1.02789913 -1.44609275    1.38737257   -0.01382677 -0.9765606891\n",
       "292 -1.02789913 -0.50638871   -0.69327800    0.08126259 -0.6904658004\n",
       "293 -0.40512253  0.17408662    0.58712235    0.74688810  0.2183061988\n",
       "294 -0.71651083  0.17408662   -1.81362830    1.50760297  0.3192808654\n",
       "296  0.84043067  0.91936913   -0.69327800    0.17635195 -0.3033962452\n",
       "297 -0.40512253  0.75735119   -0.05307782    0.84197746  1.7160970864\n",
       "298 -1.02789913  0.10927944    1.06727248   -0.01382677  0.4959865319\n",
       "299  3.33153706 -0.73321383    0.58712235   -0.39418420  0.2351353099\n",
       "302 -0.40512253  0.69254402   -1.01337808    0.36653067 -0.1771779120\n",
       "303  0.52904237 -1.47849633    0.90722244    1.12724554 -0.9597315780\n",
       "306 -0.40512253 -0.08514208    0.42707231    0.74688810 -0.4296145784\n",
       "307  2.08598386  1.24340500   -0.21312786   -0.58436292 -0.2024215786\n",
       "308 -1.02789913  0.46571891   -0.21312786   -1.44016715 -0.0677886899\n",
       "309 -1.02789913  0.17408662   -0.21312786   -0.96472036  0.2014770877\n",
       "310 -0.40512253  0.04447227   -0.21312786   -0.10891613  0.4118409764\n",
       "312 -1.02789913 -0.53879230   -0.05307782    0.74688810 -0.0677886899\n",
       "313 -0.40512253  1.04898348    0.26702227   -1.15489907 -0.5053455784\n",
       "314 -0.09373423 -0.31196719   -1.65357826   -1.82052458 -0.5979056894\n",
       "316 -0.40512253 -0.34437078   -0.21312786   -0.67945228 -0.5221746895\n",
       "317 -0.09373423 -0.76561741    0.74717240   -1.72543523 -0.7746113559\n",
       "319 -0.09373423 -0.24716002   -0.37317791    0.93706682 -0.1351051342\n",
       "321  0.21765407  0.20649021   -0.85332804   -1.63034587  0.6306194207\n",
       "324  3.02014876  0.95177272    1.54742262    0.36653067 -1.0691208001\n",
       "326 -0.71651083  1.11379065    0.10697222   -0.77454164  0.1005024211\n",
       "327 -0.71651083 -0.02033490   -0.53322795    0.27144131 -0.0004722455\n",
       "329 -0.40512253 -0.66840665    1.22732253    0.65179874 -0.3033962452\n",
       "330  0.84043067 -0.57119589   -0.05307782    0.27144131 -0.7409531337\n",
       "332 -0.40512253 -1.15446046   -1.01337808   -1.24998843 -0.8755860225\n",
       "335 -0.71651083 -0.89523176   -0.85332804   -1.05980971 -0.8250986892\n",
       "336 -1.02789913  1.37301935    0.42707231    1.31742425  0.8325687538\n",
       "339  1.77459556  0.95177272    0.58712235    0.46162002  0.1257460878\n",
       "341 -0.71651083  0.23889379   -0.05307782   -1.53525651 -0.4296145784\n",
       "342 -0.71651083 -0.89523176    0.26702227   -0.77454164 -0.6988803560\n",
       "346  1.46320726  0.10927944    1.38737257    0.65179874 -0.4043709118\n",
       "347 -0.71651083  0.53052608   -1.97367834   -0.96472036 -0.6147348005\n",
       "349 -0.09373423 -0.76561741   -0.69327800   -0.96472036 -0.6904658004\n",
       "354 -0.71651083 -1.05724970   -0.69327800   -1.63034587 -0.9513170225\n",
       "357 -0.71651083  0.07687586   -1.65357826    1.03215618  0.0920878656\n",
       "359  2.70876046 -1.12205687    0.26702227    1.03215618 -0.8587569114\n",
       "360 -0.71651083  2.37753056    0.42707231    0.65179874  0.7820814206\n",
       "361  0.52904237  2.15070545   -0.53322795    0.36653067  1.4215876422\n",
       "365  0.21765407  0.78975478    0.26702227   -0.39418420  1.1523218647\n",
       "366  0.52904237 -0.76561741   -1.33347817   -0.10891613 -0.6147348005\n",
       "369 -0.09373423 -1.34888198    1.22732253   -1.24998843 -0.7577822448\n",
       "370 -0.71651083  0.33610456    2.50772288   -0.10891613 -0.1351051342\n",
       "371 -0.09373423  1.63224805    0.90722244    1.79287105  2.5996254190\n",
       "373 -1.02789913 -1.25167122   -0.53322795   -0.67945228 -0.7577822448\n",
       "374 -0.40512253 -0.57119589   -1.01337808    1.03215618 -0.5221746895\n",
       "375 -0.40512253 -0.02033490   -1.49352821    1.31742425  0.0163568656\n",
       "376  2.70876046  0.56292967    0.90722244    1.31742425  1.4215876422\n",
       "377 -1.02789913 -0.79802100    0.90722244   -1.34507779 -0.6063202450\n",
       "378 -0.71651083 -1.15446046   -0.85332804    0.74688810 -0.6820512449\n",
       "380 -1.02789913 -0.96003894    2.34767283    0.93706682 -0.7072949115\n",
       "381 -0.71651083 -0.50638871    0.10697222    0.08126259 -0.6231493561\n",
       "383 -0.71651083 -0.44158154   -0.85332804   -2.01070330  0.2183061988\n",
       "384 -0.71651083 -1.05724970   -0.69327800   -1.05980971 -0.8166841337\n",
       "385 -0.71651083  0.07687586   -0.05307782   -0.48927356 -0.3875418007\n",
       "386 -0.71651083 -0.11754567   -1.33347817   -1.53525651 -0.8924151336\n",
       "389  0.52904237  0.69254402    0.90722244   -0.29909485  1.0850054203\n",
       "390 -0.09373423 -0.73321383   -0.21312786   -0.58436292 -0.6315639116\n",
       "391 -0.71651083 -0.73321383   -0.37317791   -0.01382677  0.3361099765\n",
       "393 -0.71651083  0.27129738   -0.53322795   -1.44016715  2.1788976416\n",
       "394  0.21765407 -0.21475643    0.10697222   -1.63034587 -0.5810765783\n",
       "396 -0.40512253  0.14168303   -1.01337808   -0.48927356  1.0008598648\n",
       "397 -0.09373423 -0.86282817   -1.17342813    0.46162002 -0.3454690230\n",
       "403  0.52904237  0.43331532    1.06727248    1.12724554 -0.5726620228\n",
       "406 -0.40512253  0.01206868   -1.81362830    0.27144131  0.0752587545\n",
       "410 -0.71651083  1.59984446   -0.21312786    1.88796040  3.5588847516\n",
       "412 -0.71651083 -0.34437078    0.10697222    0.08126259  0.1678188655\n",
       "413 -0.71651083  0.66014043    1.06727248   -0.58436292  1.2953693090\n",
       "414 -0.71651083  0.66014043    0.26702227   -0.67945228 -0.7998550226\n",
       "415 -1.02789913  0.49812249   -0.85332804    0.55670938  0.0920878656\n",
       "416 -0.09373423  1.63224805    1.06727248    0.36653067  2.6753564190\n",
       "420 -0.09373423  0.20649021   -0.53322795   -0.01382677 -0.3454690230\n",
       "421 -0.71651083 -0.11754567    1.38737257    1.12724554  0.1173315322\n",
       "422 -0.40512253 -0.92763535   -0.21312786   -1.05980971 -0.6736366893\n",
       "423 -1.02789913 -0.66840665   -0.53322795    1.60269233 -0.6568075783\n",
       "425  1.46320726  0.91936913    0.58712235    0.27144131  0.4539137542\n",
       "426  0.21765407  1.98868751    0.58712235    0.93706682  1.0176889759\n",
       "428 -0.71651083  1.89147675   -0.53322795    0.08126259  0.2014770877\n",
       "429 -1.02789913  0.40091173    1.86752270    1.60269233 -0.0930323565\n",
       "430 -0.71651083 -0.89523176    0.90722244   -0.39418420  0.2014770877\n",
       "432 -0.09373423 -1.08965329    0.26702227   -1.24998843 -0.5979056894\n",
       "433 -0.71651083 -1.38128557    0.26702227   -1.72543523 -0.8082695781\n",
       "442 -0.40512253 -1.28407481   -0.37317791   -0.58436292 -0.8924151336\n",
       "443  0.21765407 -0.18235284   -0.53322795   -0.20400549 -0.3033962452\n",
       "446 -1.02789913  1.85907316    0.58712235    3.21921143 -1.1953391334\n",
       "447 -0.71651083 -0.73321383    0.10697222   -1.63034587 -0.7241240226\n",
       "448 -1.02789913 -0.89523176    0.74717240    1.50760297 -0.5390038006\n",
       "449 -1.02789913 -0.60359948   -0.53322795    0.74688810 -0.7746113559\n",
       "450 -1.02789913 -0.08514208    0.26702227   -1.05980971 -0.7830259115\n",
       "451 -0.71651083 -1.31647840   -0.53322795   -1.53525651 -0.5137601339\n",
       "453 -1.02789913 -1.02484611   -0.21312786    0.27144131  0.4539137542\n",
       "455 -0.40512253 -0.73321383   -1.33347817   -0.10891613 -0.4296145784\n",
       "458  0.52904237 -1.18686405   -0.21312786   -0.10891613 -0.7157094671\n",
       "459  2.08598386  0.82215837    1.06727248    1.79287105  0.6811067540\n",
       "460  1.77459556  0.36850814    0.26702227    0.36653067 -0.8082695781\n",
       "461  1.77459556 -0.08514208    0.10697222   -0.67945228 -0.8419278003\n",
       "463  1.46320726 -1.57570710   -0.05307782    1.03215618 -0.9008296892\n",
       "466 -1.02789913  0.04447227   -1.17342813   -1.53525651 -0.4296145784\n",
       "467 -1.02789913 -1.57570710   -1.49352821   -1.82052458 -1.0102189113\n",
       "468 -1.02789913 -0.83042459   -0.53322795    0.65179874 -0.4716873562\n",
       "470  0.84043067  1.01657989    0.58712235    1.12724554 -0.1351051342\n",
       "477 -0.40512253 -0.57119589    0.74717240    1.50760297  0.2940371987\n",
       "478  1.15181896 -0.27956360    0.42707231   -1.15489907 -0.3875418007\n",
       "479  1.46320726  0.10927944    0.26702227    0.84197746 -0.6820512449\n",
       "481 -0.09373423  1.14619424   -0.05307782    0.08126259  1.4468313089\n",
       "483  0.21765407 -1.21926764   -1.01337808   -0.67945228 -0.9008296892\n",
       "484 -1.02789913 -1.25167122    0.90722244    0.17635195 -0.2613234675\n",
       "486 -1.02789913  0.40091173   -0.21312786    1.22233489  0.7904959761\n",
       "487 -0.71651083  0.53052608   -0.69327800    1.12724554  2.7258437523\n",
       "488 -1.02789913  1.63224805    0.58712235    0.27144131  0.9167143093\n",
       "491 -0.40512253 -1.28407481   -0.45320293   -0.10891613 -0.7577822448\n",
       "494  0.21765407  0.07687586   -0.05307782   -1.05980971 -0.2865671341\n",
       "498 -0.40512253 -1.34888198    0.10697222   -1.34507779 -0.6736366893\n",
       "499  1.15181896  2.34512697   -0.05307782    0.36653067 -0.0930323565\n",
       "500  0.84043067  1.01657989    0.26702227    0.27144131  0.3108663098\n",
       "501 -0.40512253 -0.18235284    1.54742262   -0.96472036 -0.7157094671\n",
       "504  1.15181896 -0.92763535   -0.53322795   -0.39418420 -0.6483930227\n",
       "507 -1.02789913  1.85907316    1.54742262   -0.29909485 -0.5558329117\n",
       "508 -0.71651083  0.23889379   -0.85332804   -0.58436292  0.1173315322\n",
       "509 -0.40512253 -1.25167122   -1.65357826   -0.58436292 -0.6736366893\n",
       "512 -1.02789913  0.53052608   -0.69327800   -1.15489907  0.4539137542\n",
       "515 -0.09373423 -0.76561741   -1.33347817   -0.96472036 -0.5894911339\n",
       "516 -0.09373423  1.30821218   -0.05307782   -1.05980971 -0.4296145784\n",
       "517  1.77459556  0.72494760    1.38737257    0.46162002  0.0752587545\n",
       "520  0.84043067  0.20649021    1.54742262   -2.10579266  1.4300021978\n",
       "521 -0.40512253 -1.77012862   -0.05307782    0.27144131 -0.7577822448\n",
       "522 -0.09373423  0.04447227    0.74717240    0.36653067 -0.2192506897\n",
       "527 -0.71651083 -0.83042459   -0.53322795   -0.96472036 -0.6231493561\n",
       "528 -0.09373423 -0.21475643    0.26702227   -1.34507779 -0.4296145784\n",
       "529 -1.02789913 -0.18235284   -0.37317791    0.17635195  0.2687935321\n",
       "531 -0.40512253 -0.02033490   -0.85332804   -1.05980971 -0.4212000229\n",
       "533 -0.71651083 -1.18686405   -0.37317791    2.17322848 -0.7661968004\n",
       "535 -0.71651083 -1.47849633   -1.17342813    0.08126259 -0.8419278003\n",
       "539 -1.02789913  0.14168303    0.74717240    0.74688810  0.4539137542\n",
       "540 -0.09373423  0.20649021    1.70747266    1.88796040 -0.0088868010\n",
       "541  1.46320726 -0.73321383    0.26702227    1.03215618  0.4959865319\n",
       "542 -0.09373423  0.17408662    0.10697222   -0.39418420  0.2856226432\n",
       "544  0.21765407 -1.25167122    1.54742262   -0.58436292 -0.8419278003\n",
       "545 -0.71651083 -1.12205687    0.58712235   -0.01382677 -0.6736366893\n",
       "546  1.46320726  2.05349468    1.54742262    0.55670938  0.5801320874\n",
       "547  0.52904237  2.08589827    0.42707231   -0.20400549  0.4286700875\n",
       "548  0.21765407  0.27129738   -0.21312786   -0.77454164  0.0836733100\n",
       "549 -0.71651083  1.34061576    0.90722244    1.31742425 -0.7493676893\n",
       "552 -0.09373423 -1.25167122   -0.21312786    0.08126259 -0.4212000229\n",
       "554 -0.71651083 -1.12205687   -0.69327800   -0.48927356 -0.9429024669\n",
       "555 -0.71651083 -1.25167122   -0.53322795   -0.58436292 -0.3454690230\n",
       "556  1.15181896  0.04447227   -0.05307782    0.36653067  0.4959865319\n",
       "562 -1.02789913  2.44233773   -0.37317791    0.27144131  0.9924453093\n",
       "563 -0.71651083 -1.15446046   -0.21312786    0.46162002 -0.6652221338\n",
       "564  0.84043067 -0.76561741   -0.85332804   -0.96472036 -0.8587569114\n",
       "566 -0.40512253 -0.89523176   -1.33347817   -1.44016715 -0.5726620228\n",
       "567 -0.71651083 -0.76561741    0.10697222    0.08126259 -1.1616809112\n",
       "568  0.84043067 -0.99244252   -0.69327800    0.27144131 -0.2529089119\n",
       "569  0.21765407  1.01657989    0.10697222   -0.01382677 -0.2529089119\n",
       "570 -1.02789913 -0.05273849   -0.37317791    0.08126259  0.0752587545\n",
       "573 -0.09373423 -0.37677436   -1.01337808    0.17635195 -0.9429024669\n",
       "574 -0.40512253 -0.79802100   -0.85332804   -1.15489907 -0.3033962452\n",
       "575 -0.71651083  0.66014043    1.22732253    0.08126259  1.4636604200\n",
       "576 -0.71651083 -0.11754567   -2.13372839    1.69778169 -0.7830259115\n",
       "577  0.84043067 -0.47398513   -2.13372839   -0.86963100 -0.2192506897\n",
       "585  1.46320726  0.04447227    0.42707231   -0.48927356  3.7355904181\n",
       "589 -0.09373423  1.72945881    1.22732253   -0.20400549 -0.0004722455\n",
       "592 -0.40512253 -0.34437078    0.58712235    1.98304976 -0.1351051342\n",
       "594 -0.40512253 -1.31647840   -1.49352821   -0.67945228 -0.3454690230\n",
       "595  0.84043067  0.01206868    0.10697222    1.50760297  0.6222048651\n",
       "596 -1.02789913  2.11830186    0.90722244   -1.44016715  0.2435498654\n",
       "598 -0.71651083 -1.08965329   -3.73422882   -0.96472036 -1.1027790223\n",
       "600 -0.71651083 -0.44158154   -2.61387852   -1.05980971 -0.3033962452\n",
       "604  1.15181896  0.88696554    0.58712235   -0.01382677 -0.2529089119\n",
       "607 -0.71651083  1.89147675    0.58712235    1.22233489  1.1523218647\n",
       "608 -0.71651083 -0.99244252   -0.69327800   -0.39418420 -0.9681461335\n",
       "609 -1.02789913  0.95177272    0.90722244    0.93706682  0.9756161982\n",
       "610 -0.71651083 -0.37677436   -0.69327800   -1.53525651  0.2183061988\n",
       "611 -0.09373423 -0.53879230   -1.33347817   -0.77454164  0.0163568656\n",
       "612 -0.09373423  1.66465164   -1.01337808   -0.67945228  0.3192808654\n",
       "613  1.15181896  1.47023011    1.38737257    1.22233489  1.3879294200\n",
       "615  2.39737216  0.49812249    0.26702227   -0.29909485 -0.1014469120\n",
       "618 -0.40512253 -1.77012862   -0.69327800   -1.53525651 -1.1869245778\n",
       "621 -0.40512253 -0.34437078    1.22732253    1.22233489  0.0331859767\n",
       "624 -1.02789913 -0.92763535   -0.05307782   -0.20400549 -0.3454690230\n",
       "626  0.21765407 -1.05724970    1.38737257    1.69778169 -0.8587569114\n",
       "632 -1.02789913 -0.66840665    0.58712235    1.03215618 -0.5558329117\n",
       "634 -0.71651083  0.17408662    0.90722244   -1.15489907  0.2267207543\n",
       "638 -0.40512253 -0.92763535    0.42707231   -1.05980971 -0.7577822448\n",
       "639  1.15181896 -0.83042459    0.42707231    0.27144131 -0.5474183561\n",
       "640 -0.71651083 -0.73321383    0.26702227   -1.63034587 -0.9260733558\n",
       "641 -1.02789913 -0.66840665    1.22732253   -1.15489907 -0.4296145784\n",
       "645 -0.09373423 -0.63600306    0.10697222    0.08126259 -0.0341304677\n",
       "646 -0.40512253  1.11379065    0.26702227    0.55670938  2.3892615303\n",
       "647 -0.71651083  1.43782653    0.26702227   -1.15489907 -0.1014469120\n",
       "648 -1.02789913  1.82666957   -1.65357826    0.65179874  0.0247714212\n",
       "649  2.39737216  0.43331532    1.06727248    0.55670938 -0.2192506897\n",
       "651 -0.71651083 -1.02484611   -1.33347817   -0.39418420 -0.4716873562\n",
       "652 -0.71651083 -0.18235284   -0.85332804   -0.58436292 -0.4212000229\n",
       "653  0.52904237  0.01206868    0.26702227    1.03215618 -0.6652221338\n",
       "655 -0.71651083 -0.53879230   -0.05307782   -0.10891613 -0.1771779120\n",
       "656 -0.40512253  1.04898348   -1.49352821   -0.20400549  3.2307170852\n",
       "657 -0.40512253 -0.70081024   -1.01337808    0.55670938 -0.5558329117\n",
       "658 -0.71651083 -0.08514208    0.74717240    1.79287105  0.3697681987\n",
       "660 -0.09373423 -1.38128557    0.90722244    0.17635195 -0.7241240226\n",
       "663  1.46320726  1.43782653    2.82782296    1.60269233  0.6306194207\n",
       "664  1.77459556  0.72494760    0.74717240    1.60269233 -0.2192506897\n",
       "666 -0.71651083 -0.34437078    0.74717240    1.50760297 -0.2024215786\n",
       "669  0.84043067 -0.79802100   -1.01337808    0.36653067  0.2856226432\n",
       "670  1.77459556  1.01657989    0.58712235    0.08126259 -0.4716873562\n",
       "671  0.84043067  1.37301935   -0.21312786   -0.29909485  0.1005024211\n",
       "673  2.08598386 -1.77012862    2.82782296   -0.58436292 -0.9008296892\n",
       "674 -0.09373423  0.01206868    2.34767283    0.55670938  0.7063504206\n",
       "680 -0.40512253 -0.70081024   -1.01337808   -1.15489907  0.9167143093\n",
       "681 -0.40512253 -2.15897167   -1.17342813   -0.10891613 -0.9344879114\n",
       "683 -1.02789913 -0.89523176   -0.53322795    0.93706682 -0.4296145784\n",
       "686 -0.40512253  0.20649021    0.26702227   -0.29909485  0.4118409764\n",
       "689 -0.71651083  0.56292967    0.26702227   -0.29909485  0.2014770877\n",
       "690 -0.71651083  0.69254402    0.90722244    1.60269233  0.2014770877\n",
       "693 -0.40512253 -0.05273849   -0.05307782    0.27144131 -0.5137601339\n",
       "694  1.15181896  0.20649021   -0.21312786    1.88796040 -0.2613234675\n",
       "696  1.15181896  0.62773684    1.54742262   -0.48927356  2.7258437523\n",
       "697 -0.09373423  1.50263370    0.26702227   -0.96472036 -0.2613234675\n",
       "699  0.21765407  0.14168303    1.38737257   -1.72543523 -0.0088868010\n",
       "701 -0.40512253 -0.02033490    0.42707231   -0.20400549  0.3697681987\n",
       "705  0.21765407 -0.40917795    0.42707231   -0.86963100 -0.4716873562\n",
       "708 -0.40512253  0.14168303   -1.97367834   -0.77454164  1.5057331977\n",
       "710 -0.40512253 -0.96003894   -0.53322795    0.27144131  0.0331859767\n",
       "711 -0.09373423  1.14619424   -0.53322795   -1.53525651  1.9432900863\n",
       "712  0.52904237  0.10927944    0.58712235   -0.20400549 -1.1280226890\n",
       "714 -1.02789913  0.36850814   -1.01337808   -0.86963100  1.1354927536\n",
       "716  1.15181896  2.08589827   -1.65357826    0.36653067  1.9853628640\n",
       "717 -0.09373423  1.63224805    0.58712235    0.93706682  0.2435498654\n",
       "719 -0.71651083 -0.47398513   -0.85332804    1.60269233  0.1846479766\n",
       "722 -0.71651083 -0.27956360   -0.37317791    0.65179874  0.3697681987\n",
       "723 -0.71651083  0.85456195   -0.21312786   -0.01382677 -0.2444943564\n",
       "724  0.52904237 -0.18235284    1.22732253    0.08126259 -0.4296145784\n",
       "727 -0.71651083 -0.21475643    0.58712235   -0.01382677  0.2014770877\n",
       "731 -0.09373423  0.23889379    0.58712235   -0.58436292 -0.6483930227\n",
       "733 -0.40512253  1.66465164    1.38737257    0.74688810 -0.3033962452\n",
       "734 -0.40512253 -0.53879230   -1.17342813   -0.20400549  0.0752587545\n",
       "737 -1.02789913  0.10927944    1.22732253   -0.20400549 -0.3033962452\n",
       "739 -0.40512253 -0.76561741   -0.85332804   -1.15489907  0.0331859767\n",
       "741  2.39737216 -0.08514208    0.74717240    0.74688810 -0.0509595788\n",
       "742 -0.09373423 -0.66840665   -2.13372839   -0.86963100 -0.5221746895\n",
       "743 -0.71651083 -0.44158154   -1.01337808   -1.05980971 -0.3370544674\n",
       "745  3.02014876  0.98417630    1.38737257    0.74688810 -0.1351051342\n",
       "746  2.70876046 -0.73321383    1.06727248    0.36653067 -0.4296145784\n",
       "748 -0.71651083 -1.34888198    0.26702227    1.12724554 -0.8335132448\n",
       "749 -0.09373423  2.08589827   -0.05307782   -0.67945228  0.3697681987\n",
       "752 -0.71651083 -0.05273849    0.58712235    0.93706682 -0.6904658004\n",
       "754 -1.02789913  1.89147675    1.38737257    1.41251361  2.9782804187\n",
       "756 -0.71651083  0.17408662    1.38737257    0.93706682 -0.3875418007\n",
       "761 -0.40512253 -1.12205687   -1.01337808   -0.29909485 -1.1785100223\n",
       "764  2.08598386 -0.70081024    0.42707231    1.79287105  0.2014770877\n",
       "766  0.52904237 -0.05273849    0.10697222   -0.58436292 -0.3707126896\n",
       "             bmi          dpf         age\n",
       "4   -0.709514270 -1.030559308 -0.96706323\n",
       "5    1.424909094  5.108582247  0.20931780\n",
       "7   -0.296859086 -0.796108358 -0.47690447\n",
       "9   -0.368006532 -1.056609414  2.16995285\n",
       "14  -0.424924488 -0.361939931  2.75814336\n",
       "15  -1.036792519  0.185112287  1.97388934\n",
       "17   1.809105300  0.080911864  0.01325429\n",
       "19   1.453368072 -0.984248010  0.20931780\n",
       "20   0.215402521  0.017233828  0.11128605\n",
       "21   0.884188509  0.523763660 -0.37887272\n",
       "25   0.499992303 -0.778741621  1.97388934\n",
       "26  -0.282629597 -0.920569974  0.99357182\n",
       "28  -1.406759236 -0.104333331 -0.86903148\n",
       "29  -1.549054126 -0.804791726  2.56207986\n",
       "32  -0.211482152  0.949248718 -0.28084096\n",
       "33  -1.179087410 -0.741113691 -0.86903148\n",
       "36  -1.292923323  1.282111179  0.20931780\n",
       "40   0.571139748  2.509360599  2.46404810\n",
       "41   0.130025587 -0.729535866 -0.47690447\n",
       "44   1.752187343  0.572969415  2.26798460\n",
       "51  -1.947479821 -0.092755506 -0.86903148\n",
       "52  -1.264464345  0.008550460 -0.47690447\n",
       "53  -1.236005366 -0.524029477 -0.08477746\n",
       "54   0.087337119 -0.162222455  2.66011161\n",
       "55   0.229632010  0.564286046  1.09160357\n",
       "57   0.656516683 -0.778741621  0.99357182\n",
       "58   1.951400190  1.270533354  0.01325429\n",
       "60   1.197237269 -1.013192571 -0.86903148\n",
       "64  -1.093710475  0.509291379 -0.67296797\n",
       "69  -1.919020843 -0.547185127 -0.57493622\n",
       "70  -0.595678357 -0.966881272 -0.37887272\n",
       "71  -0.026498793  0.995560017 -0.28084096\n",
       "72  -0.638366824 -0.324312001 -0.47690447\n",
       "74   0.286549967 -0.845314113 -0.77099973\n",
       "83  -0.538760401  0.706114399  0.50341306\n",
       "86  -0.097646239  0.506396923 -0.37887272\n",
       "88   0.770352596 -0.576129688 -0.47690447\n",
       "89   0.571139748 -1.071081695  1.18963532\n",
       "92  -0.154564195 -0.231689403  0.30734955\n",
       "93   1.937170701 -0.758480428  1.09160357\n",
       "95  -1.193316899  0.688747662 -0.96706323\n",
       "96   0.115796097 -0.775847165  0.89554007\n",
       "98  -1.805184930 -0.579024145 -0.86903148\n",
       "99  -0.624137335 -0.483507091 -0.77099973\n",
       "100  2.364055374 -0.573235232  0.01325429\n",
       "104 -0.922956606 -0.694802392 -0.67296797\n",
       "106 -0.624137335  0.804525909 -0.96706323\n",
       "108 -0.510301423 -0.683224567  0.60144481\n",
       "109  0.172714054 -0.541396214 -0.57493622\n",
       "110  0.613828216 -0.799002814 -0.67296797\n",
       "111  0.030419163 -0.937936711 -0.67296797\n",
       "112  0.130025587  0.057756215  1.48373058\n",
       "113 -0.268400108 -0.958197904 -0.77099973\n",
       "115 -0.368006532  0.188006743  0.79750831\n",
       "120 -1.406759236 -0.868469762 -0.96706323\n",
       "121  2.862087492  0.682958750 -0.57493622\n",
       "123  0.073107630 -0.344573194 -0.77099973\n",
       "126  3.118218296 -0.078283226 -0.47690447\n",
       "127  1.396450116 -0.205639297 -0.08477746\n",
       "128  0.030419163 -0.758480428 -0.77099973\n",
       "129  0.201173032 -0.347467650  0.89554007\n",
       "131 -0.481842444 -0.469034810  0.20931780\n",
       "133  0.201173032 -0.483507091 -0.08477746\n",
       "135 -1.705578506  0.358779657 -0.47690447\n",
       "136  0.101566608 -1.259221347  0.01325429\n",
       "137 -0.325318064  0.214056849 -0.96706323\n",
       "138 -0.624137335  0.025917197 -0.86903148\n",
       "140  0.542680770 -1.053714958 -0.28084096\n",
       "143 -0.083416750 -0.593496425 -0.86903148\n",
       "145 -0.040728283 -0.827947376 -0.77099973\n",
       "148 -0.368006532  2.538305160  0.30734955\n",
       "151  0.613828216 -0.359045475 -0.67296797\n",
       "153  0.172714054  1.927574907  1.09160357\n",
       "154  1.069171867  0.474557905 -0.77099973\n",
       "157 -1.207546388  0.329835096 -0.96706323\n",
       "158 -1.122169454  0.897148507 -0.77099973\n",
       "159 -0.581448868 -0.851103025 -0.86903148\n",
       "160  1.111860334  0.850837208  1.58176233\n",
       "162  0.585369238 -0.923464430  1.38569883\n",
       "163  1.581433474 -1.030559308 -0.37887272\n",
       "166 -0.453383466  0.575863871  0.99357182\n",
       "170 -0.666825803 -0.081177682 -0.18280921\n",
       "172  0.329238434  0.054861759 -0.18280921\n",
       "174  1.481827050  0.448507799 -0.77099973\n",
       "175 -0.481842444 -0.442984704  0.20931780\n",
       "176 -0.054957772  0.567180502  0.50341306\n",
       "178  4.839986476 -0.590601969 -0.47690447\n",
       "182  0.258090988  0.584547239 -0.77099973\n",
       "187 -0.424924488  0.266157060  2.85617511\n",
       "188 -0.154564195  2.309643122  0.20931780\n",
       "189 -0.737973248  0.338518464  0.01325429\n",
       "190 -0.211482152 -0.469034810 -0.57493622\n",
       "192  0.001960185 -0.431406879  0.89554007\n",
       "196  0.898417998 -0.370623300 -0.18280921\n",
       "198 -1.449447703  0.448507799 -0.77099973\n",
       "199  0.243861499  1.105549352 -0.47690447\n",
       "200 -0.311088575 -1.079765063 -0.18280921\n",
       "204 -1.805184930 -0.833736288 -0.37887272\n",
       "205  0.656516683 -0.576129688  2.36601635\n",
       "207  0.628057705  0.237212498  2.56207986\n",
       "209  0.016189674 -0.677435655 -0.96706323\n",
       "214  1.353761649 -0.266422877 -0.67296797\n",
       "215  0.158484565 -0.761374884  0.50341306\n",
       "216  1.239925736  0.633752995  0.69947656\n",
       "217  0.386156390 -0.026183014 -0.57493622\n",
       "218 -0.439153977 -0.170905823  0.11128605\n",
       "221  0.215402521  1.588923534 -0.96706323\n",
       "224 -0.609907846  0.474557905  2.95420687\n",
       "225 -1.349841279  0.413774325 -0.47690447\n",
       "226  0.215402521 -1.221593416 -0.86903148\n",
       "229  0.514221792  5.227254951  0.01325429\n",
       "230  1.723728365 -1.256326890 -0.67296797\n",
       "232  1.866023256 -0.825052920  1.48373058\n",
       "233 -1.093710475  0.173534462 -0.86903148\n",
       "235 -0.481842444 -0.665857830 -0.77099973\n",
       "237  0.400385879  0.182217831  1.97388934\n",
       "242  0.001960185 -0.223006034 -0.86903148\n",
       "244 -0.851809161  2.300959754  0.20931780\n",
       "245  0.727664128 -0.561657407 -0.18280921\n",
       "248  2.734022091 -0.278000702 -0.77099973\n",
       "249  0.329238434 -0.697696848  0.30734955\n",
       "253 -1.236005366 -0.793213902 -0.67296797\n",
       "255 -0.780661715  1.166332931  1.28766707\n",
       "259 -1.022563030  0.381935307 -0.67296797\n",
       "260  0.030419163  2.402265720  1.97388934\n",
       "261 -0.311088575 -0.648491093  0.30734955\n",
       "266  0.073107630  1.371839320  1.18963532\n",
       "272 -1.122169454 -1.143443099 -0.96706323\n",
       "274  0.016189674 -0.292472983 -0.96706323\n",
       "276  1.054942378  0.445613343 -0.57493622\n",
       "278 -0.752202737 -0.199850385 -0.77099973\n",
       "280 -1.107939965  1.036082403 -0.86903148\n",
       "282  0.400385879 -0.703485760  0.79750831\n",
       "283 -0.097646239 -0.755585971  0.60144481\n",
       "286 -1.008333541  0.358779657  1.97388934\n",
       "287  0.798811574  0.277734884  0.30734955\n",
       "288  1.780646321  0.824787102 -0.18280921\n",
       "289 -1.748266974 -0.529818389 -0.47690447\n",
       "290  0.428844858 -0.752691515  0.20931780\n",
       "291  0.542680770 -0.257739509 -0.96706323\n",
       "292  0.499992303  0.677169837 -0.57493622\n",
       "293  1.453368072  2.028880873  0.01325429\n",
       "294  1.054942378  0.260368147 -0.67296797\n",
       "296  0.343467923  0.489030186 -0.28084096\n",
       "297 -0.723743759 -0.538501758 -0.18280921\n",
       "298 -0.339547554 -0.008816277 -0.67296797\n",
       "299  0.499992303 -0.321417545  1.48373058\n",
       "302 -0.211482152 -0.292472983 -0.57493622\n",
       "303  0.386156390 -1.062398326  0.40538130\n",
       "306  0.941106465 -0.891625412 -0.18280921\n",
       "307 -1.079480986 -0.570340776  1.58176233\n",
       "308 -1.179087410 -1.100026257 -0.96706323\n",
       "309 -0.368006532  2.512255055 -0.57493622\n",
       "310 -0.026498793  1.018715666 -0.08477746\n",
       "312  0.898417998  0.237212498 -0.86903148\n",
       "313 -0.922956606 -0.260633965 -0.37887272\n",
       "314 -0.510301423  0.297996078 -0.57493622\n",
       "316  0.144255076 -0.602179794 -0.47690447\n",
       "317 -1.961709310 -0.691907935 -0.08477746\n",
       "319  0.713434639 -1.079765063 -0.28084096\n",
       "321 -0.794891204  0.011444916  0.01325429\n",
       "324 -0.894497628  0.601913977  1.18963532\n",
       "326 -1.065251497 -1.157915380 -0.67296797\n",
       "327  0.286549967  0.489030186 -0.08477746\n",
       "329  1.766416832 -1.146337556 -0.77099973\n",
       "330 -0.325318064 -1.160809836  0.60144481\n",
       "332 -0.054957772 -1.033453765 -0.57493622\n",
       "335 -1.307152812 -0.761374884 -0.86903148\n",
       "336  2.107924571 -0.764269340 -0.47690447\n",
       "339  0.158484565  1.070815878  0.20931780\n",
       "341 -1.022563030 -0.147750174 -0.86903148\n",
       "342 -1.022563030  0.434035518  0.50341306\n",
       "346  0.770352596 -0.503768284  1.77782584\n",
       "347 -0.624137335  0.379040851 -0.86903148\n",
       "349 -1.605972083 -0.706380216 -0.47690447\n",
       "354 -0.837579672  0.164851094 -0.67296797\n",
       "357  0.030419163  1.270533354 -0.28084096\n",
       "359  0.315008945 -0.419829055  1.67979408\n",
       "360  0.485762814  1.018715666 -0.18280921\n",
       "361 -0.268400108  0.173534462 -0.18280921\n",
       "365  0.258090988 -0.399567861 -0.08477746\n",
       "366  0.130025587 -0.069599857 -0.08477746\n",
       "369 -0.794891204 -0.628229900 -0.86903148\n",
       "370 -0.040728283 -0.836630744  1.38569883\n",
       "371  0.756123107  4.671519364 -0.57493622\n",
       "373  0.386156390  0.063545127 -0.96706323\n",
       "374  0.258090988 -0.862680850 -0.57493622\n",
       "375  0.443074347  0.847942752 -0.28084096\n",
       "376  0.869959019  0.014339372  2.66011161\n",
       "377 -1.122169454 -0.648491093 -0.86903148\n",
       "378  0.585369238 -0.040655295 -0.86903148\n",
       "380  1.467597561  1.441306268  0.40538130\n",
       "381 -0.325318064  0.862415033 -0.67296797\n",
       "383 -1.093710475  1.227116511 -0.96706323\n",
       "384 -1.136398943  2.156236945 -0.57493622\n",
       "385 -1.250234855 -0.874258675 -0.57493622\n",
       "386 -1.534824637 -0.920569974 -0.67296797\n",
       "389 -0.154564195 -0.205639297  2.66011161\n",
       "390 -0.211482152  1.232905424 -0.28084096\n",
       "391 -0.154564195 -0.228794947  1.09160357\n",
       "393 -1.335611790 -0.387990037 -0.96706323\n",
       "394 -1.563283616 -0.173800279  0.60144481\n",
       "396 -0.766432226  3.117196396 -0.57493622\n",
       "397 -1.193316899  1.218433143  0.79750831\n",
       "403  0.272320477 -0.686119023  0.40538130\n",
       "406  1.282614203 -0.008816277 -0.47690447\n",
       "410  1.325302670  0.517974747 -0.28084096\n",
       "412  0.186943543  0.014339372 -0.57493622\n",
       "413  1.325302670  1.600501358 -0.86903148\n",
       "414 -0.979874563 -0.772952708 -0.96706323\n",
       "415  0.215402521  0.031706109 -0.96706323\n",
       "416  0.371926901 -0.767163796 -0.86903148\n",
       "420 -0.951415585 -0.880047587 -0.28084096\n",
       "421  1.737957854 -0.046444208 -0.47690447\n",
       "422 -1.008333541  0.109856426 -0.96706323\n",
       "423  1.069171867 -0.078283226 -0.96706323\n",
       "425  1.396450116 -0.020394102  0.50341306\n",
       "426  0.556910259 -0.749797059  0.01325429\n",
       "428  0.144255076 -0.564551864  0.69947656\n",
       "429  1.069171867 -0.691907935 -0.47690447\n",
       "430  0.272320477 -0.839525201  1.18963532\n",
       "432 -0.382236021  0.080911864  0.69947656\n",
       "433 -0.439153977  0.011444916 -0.86903148\n",
       "442 -0.126105217 -0.075388769 -0.86903148\n",
       "443  0.016189674 -0.848208569 -0.67296797\n",
       "446  3.744315816  5.490650463 -0.57493622\n",
       "447 -1.107939965  0.390618675 -0.28084096\n",
       "448  0.485762814 -0.558762951 -0.47690447\n",
       "449  0.073107630 -0.037760839 -0.86903148\n",
       "450 -0.368006532 -0.689013479 -0.47690447\n",
       "451 -1.691349017 -0.312734176 -0.77099973\n",
       "453  0.969565443 -0.411145686 -0.57493622\n",
       "455  0.670746172 -0.072494313 -0.67296797\n",
       "458 -0.410694999 -0.460351441 -0.67296797\n",
       "459  0.642287194  1.383417145  1.97388934\n",
       "460 -1.022563030 -0.182483648  4.91484192\n",
       "461 -1.748266974  0.607702889  1.67979408\n",
       "463  0.315008945  0.526658116  0.79750831\n",
       "466 -1.605972083 -0.205639297 -0.96706323\n",
       "467 -0.752202737 -0.735324778 -0.86903148\n",
       "468  0.528451281  0.222740217 -0.57493622\n",
       "470  1.851793767  0.138800988 -0.37887272\n",
       "477  0.087337119  0.544024853 -0.18280921\n",
       "478 -1.321382301 -0.165116911  0.01325429\n",
       "479 -1.022563030 -1.045031589  0.79750831\n",
       "481  0.343467923 -0.518240565  0.40538130\n",
       "483 -0.752202737 -0.628229900 -0.28084096\n",
       "484  0.727664128 -0.839525201 -0.77099973\n",
       "486  1.311073181 -0.457456985 -0.67296797\n",
       "487  1.083401356  0.037495022 -0.96706323\n",
       "488  1.908711723  1.840741221  2.66011161\n",
       "491  0.528451281  0.306679446 -0.67296797\n",
       "494 -0.595678357  1.797324378  1.38569883\n",
       "498 -0.424924488  0.069334040 -0.57493622\n",
       "499 -1.136398943 -1.042137133  2.36601635\n",
       "500 -0.538760401  0.914515244  0.79750831\n",
       "501 -1.122169454 -0.607968706 -0.96706323\n",
       "504  0.030419163  0.622175170  0.99357182\n",
       "507  0.485762814 -0.605074250  0.40538130\n",
       "508 -0.638366824  0.489030186 -0.96706323\n",
       "509 -0.382236021  1.287900091 -0.96706323\n",
       "512 -1.563283616 -0.914781061 -0.96706323\n",
       "515 -1.065251497 -1.068187239 -0.67296797\n",
       "516 -0.211482152 -0.738219234 -0.28084096\n",
       "517 -0.396465510  0.717692224  2.16995285\n",
       "520 -1.919020843  0.170640006  2.85617511\n",
       "521 -1.150628432 -0.972670185 -0.57493622\n",
       "522  0.016189674 -0.631124356 -0.47690447\n",
       "527 -2.118233690 -0.648491093 -0.96706323\n",
       "528 -0.965645074 -1.204226679 -0.67296797\n",
       "529 -0.325318064 -0.086966594 -0.86903148\n",
       "531 -0.467612955  0.561391590 -0.86903148\n",
       "533  1.168778290  1.140282826 -0.18280921\n",
       "535  0.030419163  2.107031190 -0.67296797\n",
       "539  0.457303836  0.813209278 -0.77099973\n",
       "540  0.471533325  1.287900091  0.11128605\n",
       "541  0.898417998  0.399302044  1.18963532\n",
       "542 -0.097646239  0.075122952 -0.37887272\n",
       "544  0.912647487 -1.053714958 -0.57493622\n",
       "545 -0.154564195 -0.457456985 -0.18280921\n",
       "546  0.201173032 -0.289578527  0.60144481\n",
       "547  1.496056540  1.478934199  2.16995285\n",
       "548  0.001960185 -1.050820502 -0.28084096\n",
       "549 -0.040728283 -0.526923933  1.87585759\n",
       "552 -0.168793684  0.196690111 -0.57493622\n",
       "554 -0.453383466 -0.292472983 -0.77099973\n",
       "555  0.542680770 -0.150644630 -0.28084096\n",
       "556 -1.079480986 -1.047926046  0.60144481\n",
       "562  1.168778290 -0.060916488 -0.28084096\n",
       "563  0.642287194 -0.353256563 -0.67296797\n",
       "564 -0.880268139 -0.075388769  0.11128605\n",
       "566 -0.994104052  0.651119732 -0.86903148\n",
       "567  0.784582085 -0.321417545 -0.96706323\n",
       "568 -0.154564195 -1.267904715  1.48373058\n",
       "569 -0.254170619 -0.535607302  0.60144481\n",
       "570  0.172714054 -0.926358886  0.20931780\n",
       "573 -0.510301423 -0.269317333 -0.86903148\n",
       "574  0.229632010 -0.940831167 -0.86903148\n",
       "575 -0.424924488  1.067921421 -0.77099973\n",
       "576  0.343467923 -0.703485760 -0.57493622\n",
       "577 -1.292923323  0.839259383  0.40538130\n",
       "585 -0.624137335  0.474557905  2.07192109\n",
       "589  0.030419163  1.826268940  2.07192109\n",
       "592  0.898417998 -1.007403659 -0.67296797\n",
       "594 -0.652596314  3.403747558 -0.57493622\n",
       "595  0.073107630  0.607702889  0.30734955\n",
       "596 -0.154564195  0.460085624 -0.86903148\n",
       "598 -0.752202737  0.104067514 -0.96706323\n",
       "600 -1.420988725 -0.335889825 -0.47690447\n",
       "604  0.300779456  0.489030186  2.26798460\n",
       "607  0.983794932  2.127292383 -0.86903148\n",
       "608 -1.933250332 -0.118805612 -0.57493622\n",
       "609  1.197237269 -0.732430322 -0.37887272\n",
       "610 -1.292923323 -1.114498538 -0.77099973\n",
       "611 -0.311088575 -0.668752286 -0.67296797\n",
       "612 -0.026498793  0.202479024  0.50341306\n",
       "613  0.727664128  0.764003523  0.89554007\n",
       "615  0.428844858  0.098278601  1.87585759\n",
       "618 -1.847873397 -0.770058252 -0.77099973\n",
       "621  0.756123107 -0.801897270 -0.28084096\n",
       "624  1.481827050 -0.509557196 -0.96706323\n",
       "626  0.656516683 -0.466140354 -0.18280921\n",
       "632  0.201173032 -0.825052920 -0.67296797\n",
       "634 -0.794891204 -1.181071030 -0.86903148\n",
       "638 -0.211482152  0.364568570 -0.77099973\n",
       "639  1.111860334  1.007137842  0.11128605\n",
       "640 -1.933250332 -1.082659520 -0.28084096\n",
       "641 -0.538760401  0.497713554 -0.37887272\n",
       "645 -0.780661715  0.599019520 -0.37887272\n",
       "646  0.898417998 -1.126076362 -0.08477746\n",
       "647 -1.378300257 -0.220111578  0.20931780\n",
       "648  0.670746172 -0.196955929 -0.86903148\n",
       "649 -0.681055292 -0.761374884  1.09160357\n",
       "651 -1.122169454 -0.836630744 -0.77099973\n",
       "652  0.101566608 -0.165116911 -0.37887272\n",
       "653  0.144255076 -0.735324778 -0.28084096\n",
       "655  0.158484565 -1.102920713 -0.86903148\n",
       "656  0.798811574 -0.819264007 -0.57493622\n",
       "657 -1.605972083 -1.065292783 -0.86903148\n",
       "658  0.827270552  1.849424590  0.99357182\n",
       "660  0.158484565  2.225703893 -0.37887272\n",
       "663  0.642287194 -1.036348221  1.18963532\n",
       "664  0.684975661  0.329835096  0.89554007\n",
       "666  0.243861499 -0.885836499 -0.67296797\n",
       "669  0.130025587 -0.269317333  1.18963532\n",
       "670 -0.311088575 -1.039242677  1.38569883\n",
       "671  0.073107630  0.312468359  1.77782584\n",
       "673  0.343467923 -0.689013479  1.58176233\n",
       "674  3.445496545  1.033187947 -0.86903148\n",
       "680 -1.264464345  0.263262604 -0.77099973\n",
       "681 -1.264464345 -0.552974039 -0.86903148\n",
       "683  1.638351430 -0.454562529 -0.86903148\n",
       "686  0.016189674  0.196690111 -0.57493622\n",
       "689 -1.278693834  0.882676226 -0.77099973\n",
       "690  1.851793767 -0.544290670  1.48373058\n",
       "693  0.855729530  1.050554684 -0.77099973\n",
       "694  0.770352596 -0.243267228  1.18963532\n",
       "696 -0.382236021 -1.143443099  1.18963532\n",
       "697 -0.453383466 -0.738219234  0.01325429\n",
       "699  0.201173032  0.216951305 -0.28084096\n",
       "701  0.400385879 -0.115911156 -0.47690447\n",
       "705 -0.666825803 -1.172387661 -0.37887272\n",
       "708  0.186943543 -1.004509203 -0.86903148\n",
       "710  0.699205150  0.436929974 -0.77099973\n",
       "711 -0.268400108 -0.660068918 -0.67296797\n",
       "712 -0.496071934 -0.243267228  0.89554007\n",
       "714 -0.951415585 -0.495084915 -0.96706323\n",
       "716  0.115796097  0.876887314  0.30734955\n",
       "717  0.101566608  1.293689003  0.01325429\n",
       "719  0.343467923 -0.312734176 -0.67296797\n",
       "722  0.713434639 -0.677435655 -0.96706323\n",
       "723 -0.538760401 -0.503768284  1.09160357\n",
       "724  0.855729530 -0.787424989  1.09160357\n",
       "727  0.428844858 -0.078283226 -0.57493622\n",
       "731 -0.666825803 -0.579024145  0.30734955\n",
       "733  1.624121941  0.355885201 -0.67296797\n",
       "734 -0.581448868 -0.280895158 -0.86903148\n",
       "737 -0.809120694 -0.023288558 -0.96706323\n",
       "739  0.499992303 -0.202744841 -0.96706323\n",
       "741  1.311073181  0.758214610  1.67979408\n",
       "742 -0.325318064 -0.356151019 -0.47690447\n",
       "743 -0.652596314 -0.880047587 -0.86903148\n",
       "745  1.069171867  1.884158064  0.79750831\n",
       "746 -0.439153977 -0.101438875  1.48373058\n",
       "748  1.880252745  1.658390482  0.11128605\n",
       "749  0.471533325 -0.332995369  0.50341306\n",
       "752  0.841500041 -0.758480428 -0.28084096\n",
       "754  1.453368072 -0.871364219 -0.47690447\n",
       "756  0.485762814  1.545506691  0.60144481\n",
       "761 -0.666825803  0.703219943 -0.86903148\n",
       "764 -0.026498793 -1.018981484  3.15027037\n",
       "766 -0.979874563 -0.804791726 -0.08477746\n",
       "attr(,\"assign\")\n",
       "[1] 1 2 3 4 5 6 7 8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.matrix(outcome ~ . - 1, data = diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assign that alongside our **output** variable, in this case `outcome`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preparing the inputs\n",
    "x <- model.matrix(outcome ~ . - 1, data = diabetes)\n",
    "y <- diabetes$outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the `rstanarm` package, which builds off the venerable [Stan](http://mc-stan.org/) C++ package. Let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install.packages('rstanarm', repos='http://cran.us.r-project.org', type='source')\n",
    "#devtools::install_github(\"stan-dev/rstanarm\", local = FALSE)\n",
    "\n",
    "# For some reason, the rstanarm package has compilation errors when installed via Jupyter\n",
    "# So I installed it via Terminal instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "Warning message:\n",
      ": package ‘Rcpp’ was built under R version 3.2.5Warning message:\n",
      ": replacing previous import by ‘stats::cov2cor’ when loading ‘rstanarm’rstanarm (Version 2.13.1, packaged: 2016-11-20 16:59:31 UTC)\n",
      "- Do not expect the default priors to remain the same in future rstanarm versions.\n",
      "Thus, R scripts should specify priors explicitly, even if they are just the defaults.\n",
      "- For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores())\n"
     ]
    }
   ],
   "source": [
    "# Load the package\n",
    "library(rstanarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayesian version of logistic regression model can be estimated using the `stan_glm` function inside the package. The `_glm` bit stands for `generalized linear models`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for stan_glm {rstanarm}\"><tr><td>stan_glm {rstanarm}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Bayesian generalized linear models via Stan</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Generalized linear modeling with optional prior distributions for \n",
       "the coefficients, intercept, and nuisance parameter.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "stan_glm(formula, family = gaussian(), data, weights, subset,\n",
       "  na.action = NULL, offset = NULL, model = TRUE, x = FALSE, y = TRUE,\n",
       "  contrasts = NULL, ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "  \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE,\n",
       "  sparse = FALSE)\n",
       "\n",
       "stan_glm.nb(formula, data, weights, subset, na.action = NULL, offset = NULL,\n",
       "  model = TRUE, x = FALSE, y = TRUE, contrasts = NULL, link = \"log\",\n",
       "  ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "  \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE)\n",
       "\n",
       "stan_glm.fit(x, y, weights = rep(1, NROW(x)), offset = rep(0, NROW(x)),\n",
       "  family = gaussian(), ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), group = list(), prior_PD = FALSE,\n",
       "  algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),\n",
       "  adapt_delta = NULL, QR = FALSE, sparse = FALSE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula, data, subset</code></td>\n",
       "<td>\n",
       "<p>Same as <code>glm</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>family</code></td>\n",
       "<td>\n",
       "<p>Same as <code>glm</code>, except negative binomial GLMs\n",
       "are also possible using the <code>neg_binomial_2</code> family object.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action, contrasts</code></td>\n",
       "<td>\n",
       "<p>Same as <code>glm</code>, but\n",
       "rarely specified.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model, offset, weights</code></td>\n",
       "<td>\n",
       "<p>Same as <code>glm</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>x, y</code></td>\n",
       "<td>\n",
       "<p>In <code>stan_glm, stan_glm.nb</code>, logical scalars indicating whether to\n",
       "return the design matrix and response vector. In <code>stan_glm.fit</code>,\n",
       "a design matrix and response vector.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Further arguments passed to the function in the <span class=\"pkg\">rstan</span> \n",
       "package (<code>sampling</code>, <code>vb</code>, or \n",
       "<code>optimizing</code>), corresponding to the estimation method \n",
       "named by <code>algorithm</code>. For example, if <code>algorithm</code> is\n",
       "<code>\"sampling\"</code> it is possibly to specify <code>iter</code>, <code>chains</code>,\n",
       "<code>cores</code>, <code>refresh</code>, etc.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior</code></td>\n",
       "<td>\n",
       "<p>The prior distribution for the regression coefficients. \n",
       "<code>prior</code> can be a call to <code>normal</code>, <code>student_t</code>, \n",
       "<code>cauchy</code>, <code>hs</code> or <code>hs_plus</code>. See <code>priors</code> for \n",
       "details. To omit a prior &mdash;i.e., to use a flat (improper) uniform prior&mdash;\n",
       "<code>prior</code> can be set to <code>NULL</code>, although this is rarely a good \n",
       "idea. (<strong>Note:</strong> unless <code>QR=TRUE</code>, if the <code>scaled</code> argument\n",
       "to <code>prior_options</code> is left at its default and recommended value\n",
       "of <code>TRUE</code>, then the scale(s) of <code>prior</code> may be modified\n",
       "internally based on the scales of the predictors, as in the <span class=\"pkg\">arm</span>\n",
       "package. See <code>priors</code> for details on the rescaling and \n",
       "<code>prior_summary</code> for a summary of the priors used for a\n",
       "particular model.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior_intercept</code></td>\n",
       "<td>\n",
       "<p>The prior distribution for the intercept. \n",
       "<code>prior_intercept</code> can be a call to <code>normal</code>, <code>student_t</code> or \n",
       "<code>cauchy</code>. See <code>priors</code> for details. To to omit a prior \n",
       "&mdash;i.e., to use a flat (improper) uniform prior&mdash; set \n",
       "<code>prior_intercept</code> to <code>NULL</code>. (<strong>Note:</strong> if a dense \n",
       "representation of the design matrix is utilized &mdash;i.e., if the\n",
       "<code>sparse</code> argument is left at its default value of <code>FALSE</code>&mdash; then\n",
       "the prior distribution for the intercept is set so it applies to the value\n",
       "when all predictors are centered.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior_ops</code></td>\n",
       "<td>\n",
       "<p>Additional options related to prior distributions. Can \n",
       "be <code>NULL</code> to omit a prior on the dispersion and see \n",
       "<code>prior_options</code> otherwise.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior_PD</code></td>\n",
       "<td>\n",
       "<p>A logical scalar (defaulting to <code>FALSE</code>) indicating\n",
       "whether to draw from the prior predictive distribution instead of\n",
       "conditioning on the outcome.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>algorithm</code></td>\n",
       "<td>\n",
       "<p>A string (possibly abbreviated) indicating the \n",
       "estimation approach to use. Can be <code>\"sampling\"</code> for MCMC (the\n",
       "default), <code>\"optimizing\"</code> for optimization, <code>\"meanfield\"</code> for\n",
       "variational inference with independent normal distributions, or\n",
       "<code>\"fullrank\"</code> for variational inference with a multivariate normal\n",
       "distribution. See <code>rstanarm-package</code> for more details on the\n",
       "estimation algorithms. NOTE: not all fitting functions support all four\n",
       "algorithms.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>adapt_delta</code></td>\n",
       "<td>\n",
       "<p>Only relevant if <code>algorithm=\"sampling\"</code>. See \n",
       "<code>adapt_delta</code> for details.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>QR</code></td>\n",
       "<td>\n",
       "<p>A logical scalar (defaulting to <code>FALSE</code>) but if <code>TRUE</code>\n",
       "applies a scaled <code>qr</code> decomposition to the design matrix, \n",
       "<i>X = Q* R*</i>, where \n",
       "<i>Q* = Q (n-1)^0.5</i> and\n",
       "<i>R* = (n-1)^(-0.5) R</i>. The coefficients\n",
       "relative to <i>Q*</i> are obtained and then premultiplied by the\n",
       "inverse of <i>R*</i> to obtain coefficients relative to the\n",
       "original predictors, <i>X</i>. These transformations do not change the \n",
       "likelihood of the data but are recommended for computational reasons when \n",
       "there are multiple predictors. However, because the coefficients relative\n",
       "to <i>Q*</i> are not very interpretable it is hard to specify an \n",
       "informative prior. Setting <code>QR=TRUE</code> is therefore only recommended \n",
       "if you do not have an informative prior for the regression coefficients.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>sparse</code></td>\n",
       "<td>\n",
       "<p>A logical scalar (defaulting to <code>FALSE</code>) indicating\n",
       "whether to use a sparse representation of the design (X) matrix. \n",
       "Setting this to <code>TRUE</code> will likely be twice as slow, even if the\n",
       "design matrix has a considerable number of zeros, but it may allow the\n",
       "model to be estimated when the computer has too little RAM to\n",
       "utilize a dense design matrix. If <code>TRUE</code>, the the design matrix\n",
       "is not centered (since that would destroy the sparsity) and it is\n",
       "not possible to specify both <code>QR = TRUE</code> and <code>sparse = TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>link</code></td>\n",
       "<td>\n",
       "<p>For <code>stan_glm.nb</code> only, the link function to use. See \n",
       "<code>neg_binomial_2</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>group</code></td>\n",
       "<td>\n",
       "<p>A list, possibly of length zero (the default), but otherwise\n",
       "having the structure of that produced by <code>mkReTrms</code> to\n",
       "indicate the group-specific part of the model. In addition, this list must\n",
       "have elements for the <code>regularization</code>, <code>concentration</code> \n",
       "<code>shape</code>, and <code>scale</code> components of a <code>decov</code>\n",
       "prior for the covariance matrices among the group-specific coefficients.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The <code>stan_glm</code> function is similar in syntax to \n",
       "<code>glm</code> but rather than performing maximum likelihood \n",
       "estimation of generalized linear models, full Bayesian estimation is \n",
       "performed (if <code>algorithm</code> is <code>\"sampling\"</code>) via MCMC. The Bayesian\n",
       "model adds independent priors on the coefficients of the GLM. The \n",
       "<code>stan_glm</code> function calls the workhorse <code>stan_glm.fit</code> function, \n",
       "but it is also possible to call the latter directly.\n",
       "</p>\n",
       "<p>The <code>stan_glm.nb</code> function, which takes the extra argument\n",
       "<code>link</code>, is a simple wrapper for <code>stan_glm</code> with <code>family =\n",
       "  neg_binomial_2(link)</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A stanreg object is returned \n",
       "for <code>stan_glm, stan_glm.nb</code>.\n",
       "</p>\n",
       "<p>A stanfit object (or a slightly modified \n",
       "stanfit object) is returned if <code>stan_glm.fit</code> is called directly.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Gelman, A. and Hill, J. (2007). <em>Data Analysis Using\n",
       "Regression and Multilevel/Hierarchical Models.</em> Cambridge University Press,\n",
       "Cambridge, UK. (Ch. 3-6)\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>stanreg-methods</code> and \n",
       "<code>glm</code>.\n",
       "</p>\n",
       "<p>The various vignettes for <code>stan_glm</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "if (!grepl(\"^sparc\",  R.version$platform)) {\n",
       "### Linear regression\n",
       "fit &lt;- stan_glm(mpg / 10 ~ ., data = mtcars, QR = TRUE,\n",
       "                algorithm = \"fullrank\") # only to make example fast enoug\n",
       "plot(fit, prob = 0.5)\n",
       "plot(fit, prob = 0.5, pars = \"beta\")\n",
       "}\n",
       "\n",
       "### Logistic regression\n",
       "head(wells)\n",
       "wells$dist100 &lt;- wells$dist / 100\n",
       "fit2 &lt;- stan_glm(\n",
       "  switch ~ dist100 + arsenic, \n",
       "  data = wells, \n",
       "  family = binomial(link = \"logit\"), \n",
       "  prior = student_t(df = 7, location = 0, scale = 2.5), \n",
       "  prior_intercept = normal(0, 10)\n",
       ")\n",
       "print(fit2)\n",
       "prior_summary(fit2)\n",
       "\n",
       "plot(fit2, plotfun = \"areas\", prob = 0.9, # ?bayesplot::mcmc_areas\n",
       "     pars = c(\"(Intercept)\", \"arsenic\"))\n",
       "pp_check(fit2, plotfun = \"error_binned\")  # ?bayesplot::ppc_error_binned\n",
       "\n",
       "\n",
       "### Poisson regression (example from help(\"glm\")) \n",
       "counts &lt;- c(18,17,15,20,10,20,25,13,12)\n",
       "outcome &lt;- gl(3,1,9)\n",
       "treatment &lt;- gl(3,3)\n",
       "fit3 &lt;- stan_glm(counts ~ outcome + treatment, family = poisson(link=\"log\"),\n",
       "                 prior = normal(0, 1), prior_intercept = normal(0, 5))\n",
       "print(fit3)\n",
       "\n",
       "bayesplot::color_scheme_set(\"green\")\n",
       "plot(fit3)\n",
       "plot(fit3, regex_pars = c(\"outcome\", \"treatment\"))\n",
       "plot(fit3, plotfun = \"combo\", regex_pars = \"treatment\") # ?bayesplot::mcmc_combo\n",
       "\n",
       "### Gamma regression (example from help(\"glm\"))\n",
       "clotting &lt;- data.frame(log_u = log(c(5,10,15,20,30,40,60,80,100)),\n",
       "                       lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "                       lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "fit4 &lt;- stan_glm(lot1 ~ log_u, data = clotting, family = Gamma) \n",
       "print(fit4, digits = 2)                 \n",
       "fit5 &lt;- update(fit4, formula = lot2 ~ log_u)\n",
       "\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>rstanarm</em> version 2.13.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{stan\\_glm}{Bayesian generalized linear models via Stan}{stan.Rul.glm}\n",
       "\\methaliasA{stan\\_glm.fit}{stan\\_glm}{stan.Rul.glm.fit}\n",
       "\\methaliasA{stan\\_glm.nb}{stan\\_glm}{stan.Rul.glm.nb}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Generalized linear modeling with optional prior distributions for \n",
       "the coefficients, intercept, and nuisance parameter.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "stan_glm(formula, family = gaussian(), data, weights, subset,\n",
       "  na.action = NULL, offset = NULL, model = TRUE, x = FALSE, y = TRUE,\n",
       "  contrasts = NULL, ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "  \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE,\n",
       "  sparse = FALSE)\n",
       "\n",
       "stan_glm.nb(formula, data, weights, subset, na.action = NULL, offset = NULL,\n",
       "  model = TRUE, x = FALSE, y = TRUE, contrasts = NULL, link = \"log\",\n",
       "  ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "  \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE)\n",
       "\n",
       "stan_glm.fit(x, y, weights = rep(1, NROW(x)), offset = rep(0, NROW(x)),\n",
       "  family = gaussian(), ..., prior = normal(), prior_intercept = normal(),\n",
       "  prior_ops = prior_options(), group = list(), prior_PD = FALSE,\n",
       "  algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),\n",
       "  adapt_delta = NULL, QR = FALSE, sparse = FALSE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula, data, subset}] Same as \\code{\\LinkA{glm}{glm}}.\n",
       "\n",
       "\\item[\\code{family}] Same as \\code{\\LinkA{glm}{glm}}, except negative binomial GLMs\n",
       "are also possible using the \\code{\\LinkA{neg\\_binomial\\_2}{neg.Rul.binomial.Rul.2}} family object.\n",
       "\n",
       "\\item[\\code{na.action, contrasts}] Same as \\code{\\LinkA{glm}{glm}}, but\n",
       "rarely specified.\n",
       "\n",
       "\\item[\\code{model, offset, weights}] Same as \\code{\\LinkA{glm}{glm}}.\n",
       "\n",
       "\\item[\\code{x, y}] In \\code{stan\\_glm, stan\\_glm.nb}, logical scalars indicating whether to\n",
       "return the design matrix and response vector. In \\code{stan\\_glm.fit},\n",
       "a design matrix and response vector.\n",
       "\n",
       "\\item[\\code{...}] Further arguments passed to the function in the \\pkg{rstan} \n",
       "package (\\code{\\LinkA{sampling}{sampling}}, \\code{\\LinkA{vb}{vb}}, or \n",
       "\\code{\\LinkA{optimizing}{optimizing}}), corresponding to the estimation method \n",
       "named by \\code{algorithm}. For example, if \\code{algorithm} is\n",
       "\\code{\"sampling\"} it is possibly to specify \\code{iter}, \\code{chains},\n",
       "\\code{cores}, \\code{refresh}, etc.\n",
       "\n",
       "\\item[\\code{prior}] The prior distribution for the regression coefficients. \n",
       "\\code{prior} can be a call to \\code{normal}, \\code{student\\_t}, \n",
       "\\code{cauchy}, \\code{hs} or \\code{hs\\_plus}. See \\code{\\LinkA{priors}{priors}} for \n",
       "details. To omit a prior ---i.e., to use a flat (improper) uniform prior---\n",
       "\\code{prior} can be set to \\code{NULL}, although this is rarely a good \n",
       "idea. (\\strong{Note:} unless \\code{QR=TRUE}, if the \\code{scaled} argument\n",
       "to \\code{\\LinkA{prior\\_options}{prior.Rul.options}} is left at its default and recommended value\n",
       "of \\code{TRUE}, then the scale(s) of \\code{prior} may be modified\n",
       "internally based on the scales of the predictors, as in the \\pkg{arm}\n",
       "package. See \\code{\\LinkA{priors}{priors}} for details on the rescaling and \n",
       "\\code{\\LinkA{prior\\_summary}{prior.Rul.summary}} for a summary of the priors used for a\n",
       "particular model.)\n",
       "\n",
       "\\item[\\code{prior\\_intercept}] The prior distribution for the intercept. \n",
       "\\code{prior\\_intercept} can be a call to \\code{normal}, \\code{student\\_t} or \n",
       "\\code{cauchy}. See \\code{\\LinkA{priors}{priors}} for details. To to omit a prior \n",
       "---i.e., to use a flat (improper) uniform prior--- set \n",
       "\\code{prior\\_intercept} to \\code{NULL}. (\\strong{Note:} if a dense \n",
       "representation of the design matrix is utilized ---i.e., if the\n",
       "\\code{sparse} argument is left at its default value of \\code{FALSE}--- then\n",
       "the prior distribution for the intercept is set so it applies to the value\n",
       "when all predictors are centered.)\n",
       "\n",
       "\\item[\\code{prior\\_ops}] Additional options related to prior distributions. Can \n",
       "be \\code{NULL} to omit a prior on the dispersion and see \n",
       "\\code{\\LinkA{prior\\_options}{prior.Rul.options}} otherwise.\n",
       "\n",
       "\\item[\\code{prior\\_PD}] A logical scalar (defaulting to \\code{FALSE}) indicating\n",
       "whether to draw from the prior predictive distribution instead of\n",
       "conditioning on the outcome.\n",
       "\n",
       "\\item[\\code{algorithm}] A string (possibly abbreviated) indicating the \n",
       "estimation approach to use. Can be \\code{\"sampling\"} for MCMC (the\n",
       "default), \\code{\"optimizing\"} for optimization, \\code{\"meanfield\"} for\n",
       "variational inference with independent normal distributions, or\n",
       "\\code{\"fullrank\"} for variational inference with a multivariate normal\n",
       "distribution. See \\code{\\LinkA{rstanarm-package}{rstanarm.Rdash.package}} for more details on the\n",
       "estimation algorithms. NOTE: not all fitting functions support all four\n",
       "algorithms.\n",
       "\n",
       "\\item[\\code{adapt\\_delta}] Only relevant if \\code{algorithm=\"sampling\"}. See \n",
       "\\code{\\LinkA{adapt\\_delta}{adapt.Rul.delta}} for details.\n",
       "\n",
       "\\item[\\code{QR}] A logical scalar (defaulting to \\code{FALSE}) but if \\code{TRUE}\n",
       "applies a scaled \\code{\\LinkA{qr}{qr}} decomposition to the design matrix, \n",
       "\\eqn{X = Q^\\ast R^\\ast}{}, where \n",
       "\\eqn{Q^\\ast = Q \\sqrt{n-1}}{} and\n",
       "\\eqn{R^\\ast = \\frac{1}{\\sqrt{n-1}} R}{}. The coefficients\n",
       "relative to \\eqn{Q^\\ast}{} are obtained and then premultiplied by the\n",
       "inverse of \\eqn{R^{\\ast}}{} to obtain coefficients relative to the\n",
       "original predictors, \\eqn{X}{}. These transformations do not change the \n",
       "likelihood of the data but are recommended for computational reasons when \n",
       "there are multiple predictors. However, because the coefficients relative\n",
       "to \\eqn{Q^\\ast}{} are not very interpretable it is hard to specify an \n",
       "informative prior. Setting \\code{QR=TRUE} is therefore only recommended \n",
       "if you do not have an informative prior for the regression coefficients.\n",
       "\n",
       "\\item[\\code{sparse}] A logical scalar (defaulting to \\code{FALSE}) indicating\n",
       "whether to use a sparse representation of the design (X) matrix. \n",
       "Setting this to \\code{TRUE} will likely be twice as slow, even if the\n",
       "design matrix has a considerable number of zeros, but it may allow the\n",
       "model to be estimated when the computer has too little RAM to\n",
       "utilize a dense design matrix. If \\code{TRUE}, the the design matrix\n",
       "is not centered (since that would destroy the sparsity) and it is\n",
       "not possible to specify both \\code{QR = TRUE} and \\code{sparse = TRUE}.\n",
       "\n",
       "\\item[\\code{link}] For \\code{stan\\_glm.nb} only, the link function to use. See \n",
       "\\code{\\LinkA{neg\\_binomial\\_2}{neg.Rul.binomial.Rul.2}}.\n",
       "\n",
       "\\item[\\code{group}] A list, possibly of length zero (the default), but otherwise\n",
       "having the structure of that produced by \\code{\\LinkA{mkReTrms}{mkReTrms}} to\n",
       "indicate the group-specific part of the model. In addition, this list must\n",
       "have elements for the \\code{regularization}, \\code{concentration} \n",
       "\\code{shape}, and \\code{scale} components of a \\code{\\LinkA{decov}{decov}}\n",
       "prior for the covariance matrices among the group-specific coefficients.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The \\code{stan\\_glm} function is similar in syntax to \n",
       "\\code{\\LinkA{glm}{glm}} but rather than performing maximum likelihood \n",
       "estimation of generalized linear models, full Bayesian estimation is \n",
       "performed (if \\code{algorithm} is \\code{\"sampling\"}) via MCMC. The Bayesian\n",
       "model adds independent priors on the coefficients of the GLM. The \n",
       "\\code{stan\\_glm} function calls the workhorse \\code{stan\\_glm.fit} function, \n",
       "but it is also possible to call the latter directly.\n",
       "\n",
       "The \\code{stan\\_glm.nb} function, which takes the extra argument\n",
       "\\code{link}, is a simple wrapper for \\code{stan\\_glm} with \\code{family =\n",
       "  \\LinkA{neg\\_binomial\\_2}{neg.Rul.binomial.Rul.2}(link)}.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A \\LinkA{stanreg}{stanreg.Rdash.objects} object is returned \n",
       "for \\code{stan\\_glm, stan\\_glm.nb}.\n",
       "\n",
       "A \\LinkA{stanfit}{stanfit.Rdash.class} object (or a slightly modified \n",
       "stanfit object) is returned if \\code{stan\\_glm.fit} is called directly.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Gelman, A. and Hill, J. (2007). \\emph{Data Analysis Using\n",
       "Regression and Multilevel/Hierarchical Models.} Cambridge University Press,\n",
       "Cambridge, UK. (Ch. 3-6)\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{stanreg-methods}{stanreg.Rdash.methods}} and \n",
       "\\code{\\LinkA{glm}{glm}}.\n",
       "\n",
       "The various vignettes for \\code{stan\\_glm}.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "if (!grepl(\"^sparc\",  R.version$platform)) {\n",
       "### Linear regression\n",
       "fit <- stan_glm(mpg / 10 ~ ., data = mtcars, QR = TRUE,\n",
       "                algorithm = \"fullrank\") # only to make example fast enoug\n",
       "plot(fit, prob = 0.5)\n",
       "plot(fit, prob = 0.5, pars = \"beta\")\n",
       "}\n",
       "\n",
       "### Logistic regression\n",
       "head(wells)\n",
       "wells$dist100 <- wells$dist / 100\n",
       "fit2 <- stan_glm(\n",
       "  switch ~ dist100 + arsenic, \n",
       "  data = wells, \n",
       "  family = binomial(link = \"logit\"), \n",
       "  prior = student_t(df = 7, location = 0, scale = 2.5), \n",
       "  prior_intercept = normal(0, 10)\n",
       ")\n",
       "print(fit2)\n",
       "prior_summary(fit2)\n",
       "\n",
       "plot(fit2, plotfun = \"areas\", prob = 0.9, # ?bayesplot::mcmc_areas\n",
       "     pars = c(\"(Intercept)\", \"arsenic\"))\n",
       "pp_check(fit2, plotfun = \"error_binned\")  # ?bayesplot::ppc_error_binned\n",
       "\n",
       "\n",
       "### Poisson regression (example from help(\"glm\")) \n",
       "counts <- c(18,17,15,20,10,20,25,13,12)\n",
       "outcome <- gl(3,1,9)\n",
       "treatment <- gl(3,3)\n",
       "fit3 <- stan_glm(counts ~ outcome + treatment, family = poisson(link=\"log\"),\n",
       "                 prior = normal(0, 1), prior_intercept = normal(0, 5))\n",
       "print(fit3)\n",
       "\n",
       "bayesplot::color_scheme_set(\"green\")\n",
       "plot(fit3)\n",
       "plot(fit3, regex_pars = c(\"outcome\", \"treatment\"))\n",
       "plot(fit3, plotfun = \"combo\", regex_pars = \"treatment\") # ?bayesplot::mcmc_combo\n",
       "\n",
       "### Gamma regression (example from help(\"glm\"))\n",
       "clotting <- data.frame(log_u = log(c(5,10,15,20,30,40,60,80,100)),\n",
       "                       lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "                       lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "fit4 <- stan_glm(lot1 ~ log_u, data = clotting, family = Gamma) \n",
       "print(fit4, digits = 2)                 \n",
       "fit5 <- update(fit4, formula = lot2 ~ log_u)\n",
       "\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "stan_glm               package:rstanarm                R Documentation\n",
       "\n",
       "_\bB_\ba_\by_\be_\bs_\bi_\ba_\bn _\bg_\be_\bn_\be_\br_\ba_\bl_\bi_\bz_\be_\bd _\bl_\bi_\bn_\be_\ba_\br _\bm_\bo_\bd_\be_\bl_\bs _\bv_\bi_\ba _\bS_\bt_\ba_\bn\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Generalized linear modeling with optional prior distributions for\n",
       "     the coefficients, intercept, and nuisance parameter.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     stan_glm(formula, family = gaussian(), data, weights, subset,\n",
       "       na.action = NULL, offset = NULL, model = TRUE, x = FALSE, y = TRUE,\n",
       "       contrasts = NULL, ..., prior = normal(), prior_intercept = normal(),\n",
       "       prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "       \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE,\n",
       "       sparse = FALSE)\n",
       "     \n",
       "     stan_glm.nb(formula, data, weights, subset, na.action = NULL, offset = NULL,\n",
       "       model = TRUE, x = FALSE, y = TRUE, contrasts = NULL, link = \"log\",\n",
       "       ..., prior = normal(), prior_intercept = normal(),\n",
       "       prior_ops = prior_options(), prior_PD = FALSE, algorithm = c(\"sampling\",\n",
       "       \"optimizing\", \"meanfield\", \"fullrank\"), adapt_delta = NULL, QR = FALSE)\n",
       "     \n",
       "     stan_glm.fit(x, y, weights = rep(1, NROW(x)), offset = rep(0, NROW(x)),\n",
       "       family = gaussian(), ..., prior = normal(), prior_intercept = normal(),\n",
       "       prior_ops = prior_options(), group = list(), prior_PD = FALSE,\n",
       "       algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),\n",
       "       adapt_delta = NULL, QR = FALSE, sparse = FALSE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "formula, data, subset: Same as ‘glm’.\n",
       "\n",
       "  family: Same as ‘glm’, except negative binomial GLMs are also\n",
       "          possible using the ‘neg_binomial_2’ family object.\n",
       "\n",
       "na.action, contrasts: Same as ‘glm’, but rarely specified.\n",
       "\n",
       "model, offset, weights: Same as ‘glm’.\n",
       "\n",
       "    x, y: In ‘stan_glm, stan_glm.nb’, logical scalars indicating\n",
       "          whether to return the design matrix and response vector. In\n",
       "          ‘stan_glm.fit’, a design matrix and response vector.\n",
       "\n",
       "     ...: Further arguments passed to the function in the ‘rstan’\n",
       "          package (‘sampling’, ‘vb’, or ‘optimizing’), corresponding to\n",
       "          the estimation method named by ‘algorithm’. For example, if\n",
       "          ‘algorithm’ is ‘\"sampling\"’ it is possibly to specify ‘iter’,\n",
       "          ‘chains’, ‘cores’, ‘refresh’, etc.\n",
       "\n",
       "   prior: The prior distribution for the regression coefficients.\n",
       "          ‘prior’ can be a call to ‘normal’, ‘student_t’, ‘cauchy’,\n",
       "          ‘hs’ or ‘hs_plus’. See ‘priors’ for details. To omit a prior\n",
       "          -i.e., to use a flat (improper) uniform prior- ‘prior’ can be\n",
       "          set to ‘NULL’, although this is rarely a good idea. (*Note:*\n",
       "          unless ‘QR=TRUE’, if the ‘scaled’ argument to ‘prior_options’\n",
       "          is left at its default and recommended value of ‘TRUE’, then\n",
       "          the scale(s) of ‘prior’ may be modified internally based on\n",
       "          the scales of the predictors, as in the ‘arm’ package. See\n",
       "          ‘priors’ for details on the rescaling and ‘prior_summary’ for\n",
       "          a summary of the priors used for a particular model.)\n",
       "\n",
       "prior_intercept: The prior distribution for the intercept.\n",
       "          ‘prior_intercept’ can be a call to ‘normal’, ‘student_t’ or\n",
       "          ‘cauchy’. See ‘priors’ for details. To to omit a prior -i.e.,\n",
       "          to use a flat (improper) uniform prior- set ‘prior_intercept’\n",
       "          to ‘NULL’. (*Note:* if a dense representation of the design\n",
       "          matrix is utilized -i.e., if the ‘sparse’ argument is left at\n",
       "          its default value of ‘FALSE’- then the prior distribution for\n",
       "          the intercept is set so it applies to the value when all\n",
       "          predictors are centered.)\n",
       "\n",
       "prior_ops: Additional options related to prior distributions. Can be\n",
       "          ‘NULL’ to omit a prior on the dispersion and see\n",
       "          ‘prior_options’ otherwise.\n",
       "\n",
       "prior_PD: A logical scalar (defaulting to ‘FALSE’) indicating whether\n",
       "          to draw from the prior predictive distribution instead of\n",
       "          conditioning on the outcome.\n",
       "\n",
       "algorithm: A string (possibly abbreviated) indicating the estimation\n",
       "          approach to use. Can be ‘\"sampling\"’ for MCMC (the default),\n",
       "          ‘\"optimizing\"’ for optimization, ‘\"meanfield\"’ for\n",
       "          variational inference with independent normal distributions,\n",
       "          or ‘\"fullrank\"’ for variational inference with a multivariate\n",
       "          normal distribution. See ‘rstanarm-package’ for more details\n",
       "          on the estimation algorithms. NOTE: not all fitting functions\n",
       "          support all four algorithms.\n",
       "\n",
       "adapt_delta: Only relevant if ‘algorithm=\"sampling\"’. See ‘adapt_delta’\n",
       "          for details.\n",
       "\n",
       "      QR: A logical scalar (defaulting to ‘FALSE’) but if ‘TRUE’\n",
       "          applies a scaled ‘qr’ decomposition to the design matrix, X =\n",
       "          Q* R*, where Q* = Q (n-1)^0.5 and R* = (n-1)^(-0.5) R. The\n",
       "          coefficients relative to Q* are obtained and then\n",
       "          premultiplied by the inverse of R* to obtain coefficients\n",
       "          relative to the original predictors, X. These transformations\n",
       "          do not change the likelihood of the data but are recommended\n",
       "          for computational reasons when there are multiple predictors.\n",
       "          However, because the coefficients relative to Q* are not very\n",
       "          interpretable it is hard to specify an informative prior.\n",
       "          Setting ‘QR=TRUE’ is therefore only recommended if you do not\n",
       "          have an informative prior for the regression coefficients.\n",
       "\n",
       "  sparse: A logical scalar (defaulting to ‘FALSE’) indicating whether\n",
       "          to use a sparse representation of the design (X) matrix.\n",
       "          Setting this to ‘TRUE’ will likely be twice as slow, even if\n",
       "          the design matrix has a considerable number of zeros, but it\n",
       "          may allow the model to be estimated when the computer has too\n",
       "          little RAM to utilize a dense design matrix. If ‘TRUE’, the\n",
       "          the design matrix is not centered (since that would destroy\n",
       "          the sparsity) and it is not possible to specify both ‘QR =\n",
       "          TRUE’ and ‘sparse = TRUE’.\n",
       "\n",
       "    link: For ‘stan_glm.nb’ only, the link function to use. See\n",
       "          ‘neg_binomial_2’.\n",
       "\n",
       "   group: A list, possibly of length zero (the default), but otherwise\n",
       "          having the structure of that produced by ‘mkReTrms’ to\n",
       "          indicate the group-specific part of the model. In addition,\n",
       "          this list must have elements for the ‘regularization’,\n",
       "          ‘concentration’ ‘shape’, and ‘scale’ components of a ‘decov’\n",
       "          prior for the covariance matrices among the group-specific\n",
       "          coefficients.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The ‘stan_glm’ function is similar in syntax to ‘glm’ but rather\n",
       "     than performing maximum likelihood estimation of generalized\n",
       "     linear models, full Bayesian estimation is performed (if\n",
       "     ‘algorithm’ is ‘\"sampling\"’) via MCMC. The Bayesian model adds\n",
       "     independent priors on the coefficients of the GLM. The ‘stan_glm’\n",
       "     function calls the workhorse ‘stan_glm.fit’ function, but it is\n",
       "     also possible to call the latter directly.\n",
       "\n",
       "     The ‘stan_glm.nb’ function, which takes the extra argument ‘link’,\n",
       "     is a simple wrapper for ‘stan_glm’ with ‘family =\n",
       "     neg_binomial_2(link)’.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A stanreg object is returned for ‘stan_glm, stan_glm.nb’.\n",
       "\n",
       "     A stanfit object (or a slightly modified stanfit object) is\n",
       "     returned if ‘stan_glm.fit’ is called directly.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Gelman, A. and Hill, J. (2007). _Data Analysis Using Regression\n",
       "     and Multilevel/Hierarchical Models._ Cambridge University Press,\n",
       "     Cambridge, UK. (Ch. 3-6)\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘stanreg-methods’ and ‘glm’.\n",
       "\n",
       "     The various vignettes for ‘stan_glm’.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     if (!grepl(\"^sparc\",  R.version$platform)) {\n",
       "     ### Linear regression\n",
       "     fit <- stan_glm(mpg / 10 ~ ., data = mtcars, QR = TRUE,\n",
       "                     algorithm = \"fullrank\") # only to make example fast enoug\n",
       "     plot(fit, prob = 0.5)\n",
       "     plot(fit, prob = 0.5, pars = \"beta\")\n",
       "     }\n",
       "     \n",
       "     ### Logistic regression\n",
       "     head(wells)\n",
       "     wells$dist100 <- wells$dist / 100\n",
       "     fit2 <- stan_glm(\n",
       "       switch ~ dist100 + arsenic, \n",
       "       data = wells, \n",
       "       family = binomial(link = \"logit\"), \n",
       "       prior = student_t(df = 7, location = 0, scale = 2.5), \n",
       "       prior_intercept = normal(0, 10)\n",
       "     )\n",
       "     print(fit2)\n",
       "     prior_summary(fit2)\n",
       "     \n",
       "     plot(fit2, plotfun = \"areas\", prob = 0.9, # ?bayesplot::mcmc_areas\n",
       "          pars = c(\"(Intercept)\", \"arsenic\"))\n",
       "     pp_check(fit2, plotfun = \"error_binned\")  # ?bayesplot::ppc_error_binned\n",
       "     \n",
       "     \n",
       "     ### Poisson regression (example from help(\"glm\")) \n",
       "     counts <- c(18,17,15,20,10,20,25,13,12)\n",
       "     outcome <- gl(3,1,9)\n",
       "     treatment <- gl(3,3)\n",
       "     fit3 <- stan_glm(counts ~ outcome + treatment, family = poisson(link=\"log\"),\n",
       "                      prior = normal(0, 1), prior_intercept = normal(0, 5))\n",
       "     print(fit3)\n",
       "     \n",
       "     bayesplot::color_scheme_set(\"green\")\n",
       "     plot(fit3)\n",
       "     plot(fit3, regex_pars = c(\"outcome\", \"treatment\"))\n",
       "     plot(fit3, plotfun = \"combo\", regex_pars = \"treatment\") # ?bayesplot::mcmc_combo\n",
       "     \n",
       "     ### Gamma regression (example from help(\"glm\"))\n",
       "     clotting <- data.frame(log_u = log(c(5,10,15,20,30,40,60,80,100)),\n",
       "                            lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "                            lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "     fit4 <- stan_glm(lot1 ~ log_u, data = clotting, family = Gamma) \n",
       "     print(fit4, digits = 2)                 \n",
       "     fit5 <- update(fit4, formula = lot2 ~ log_u)\n",
       "     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?stan_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  pregnancies         glucose        bloodpressure      skinthickness     \n",
       " Min.   :-1.0279   Min.   :-2.1590   Min.   :-3.73423   Min.   :-2.10579  \n",
       " 1st Qu.:-0.7165   1st Qu.:-0.7656   1st Qu.:-0.69328   1st Qu.:-0.77454  \n",
       " Median :-0.4051   Median :-0.1175   Median :-0.05308   Median :-0.01383  \n",
       " Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.00000  \n",
       " 3rd Qu.: 0.5290   3rd Qu.: 0.6601   3rd Qu.: 0.58712   3rd Qu.: 0.74689  \n",
       " Max.   : 4.2657   Max.   : 2.4423   Max.   : 3.14792   Max.   : 3.21921  \n",
       "    insulin             bmi                dpf               age         \n",
       " Min.   :-1.1953   Min.   :-2.11823   Min.   :-1.2679   Min.   :-0.9671  \n",
       " 1st Qu.:-0.6673   1st Qu.:-0.66683   1st Qu.:-0.7332   1st Qu.:-0.7710  \n",
       " Median :-0.2571   Median : 0.01619   Median :-0.2129   Median :-0.3789  \n",
       " Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000  \n",
       " 3rd Qu.: 0.2856   3rd Qu.: 0.57114   3rd Qu.: 0.4746   3rd Qu.: 0.5034  \n",
       " Max.   : 5.8056   Max.   : 4.83999   Max.   : 5.4906   Max.   : 4.9148  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use a **Student t-prior** with *7 degrees of freedom* from the 8 input columns, a location (mean) of 0 after normalization, and a default scale of 2.5, which, as discussed above, is a \n",
    "**reasonable default prior distribution when coefficients should be close to zero but have some chance of being large**. \n",
    "\n",
    "The `formula`, `data` and `family` arguments to `stan_glm` are specified in exactly the same way as for `glm`. We've also added the `seed` (for reproducibility of the random elements). \n",
    "\n",
    "You can read about other possible arguments in the\n",
    "`stan_glm` documentation (`help(stan_glm, package = 'rstanarm')`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1).\n",
      "\n",
      "Chain 1, Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 1, Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 1, Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 1, Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 1, Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 1, Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 1, Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 1, Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 1, Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 1, Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 1, Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 1, Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      " Elapsed Time: 1.01587 seconds (Warm-up)\n",
      "               1.03251 seconds (Sampling)\n",
      "               2.04838 seconds (Total)\n",
      "\n",
      "\n",
      "SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2).\n",
      "\n",
      "Chain 2, Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 2, Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 2, Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 2, Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 2, Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 2, Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 2, Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 2, Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 2, Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 2, Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 2, Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 2, Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      " Elapsed Time: 0.99612 seconds (Warm-up)\n",
      "               1.15676 seconds (Sampling)\n",
      "               2.15288 seconds (Total)\n",
      "\n",
      "\n",
      "SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 3).\n",
      "\n",
      "Chain 3, Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 3, Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 3, Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 3, Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 3, Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 3, Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 3, Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 3, Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 3, Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 3, Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 3, Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 3, Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      " Elapsed Time: 1.00742 seconds (Warm-up)\n",
      "               0.949994 seconds (Sampling)\n",
      "               1.95742 seconds (Total)\n",
      "\n",
      "\n",
      "SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 4).\n",
      "\n",
      "Chain 4, Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Chain 4, Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Chain 4, Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Chain 4, Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Chain 4, Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Chain 4, Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Chain 4, Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Chain 4, Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Chain 4, Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Chain 4, Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Chain 4, Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Chain 4, Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      " Elapsed Time: 1.05672 seconds (Warm-up)\n",
      "               1.1115 seconds (Sampling)\n",
      "               2.16822 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_prior <- student_t(df = 7)\n",
    "# There are 8 columns in the input matrix\n",
    "\n",
    "post1 <- stan_glm(outcome ~ ., data = diabetes,\n",
    "                 family = binomial(link = \"logit\"), \n",
    "                 prior = t_prior, prior_intercept = t_prior,\n",
    "                 seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stan_glm** returns the posterior distribution for the parameters describing the uncertainty related to unknown parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ci_level: 0.95 (95% intervals)\n",
      "outer_level: 1 (100% intervals)\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(con, \"rb\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(con, \"rb\"): cannot open the connection\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEDWlDQ1BJQ0MgUHJvZmlsZQAA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\naZAZBFYAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/svg+xml": {
       "isolated": true
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab a plotting library (ggplot2) \n",
    "library(ggplot2)\n",
    "\n",
    "# Get rstan again, because we need a special plot\n",
    "library(rstan)\n",
    "\n",
    "# Plot the posterior (need_stanplot from rstan, regular ggplot2 doesn't have this function)\n",
    "pplot<- stan_plot(post1, ci_level = 0.95, outer_level = 1, show_density = TRUE)\n",
    "\n",
    "# Add a 0 line for reference\n",
    "pplot+ geom_vline(xintercept = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have up here is the **posterrior** distribution of parameters, with the uncertainty estimates as described by their medians. \n",
    "\n",
    "A coeffecient that **we believe are very influential** on the binary `diabetes$outcome` appears to be `glucose`, `pregnancies`, and, to a lesser extent possibly `bmi`, `dpf`, and `age`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract corresponding posterior median estimates using `coef` function and  to get a sense for the uncertainty in our estimates we can use the `posterior_interval` function to get Bayesian uncertainty intervals. \n",
    "\n",
    "The uncertainty intervals are computed by finding the relevant quantiles of the draws from the posterior distribution. For example, to compute median and 90% intervals we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-1.02</dd>\n",
       "\t<dt>pregnancies</dt>\n",
       "\t\t<dd>0.27</dd>\n",
       "\t<dt>glucose</dt>\n",
       "\t\t<dd>1.19</dd>\n",
       "\t<dt>bloodpressure</dt>\n",
       "\t\t<dd>-0.01</dd>\n",
       "\t<dt>skinthickness</dt>\n",
       "\t\t<dd>0.13</dd>\n",
       "\t<dt>insulin</dt>\n",
       "\t\t<dd>-0.09</dd>\n",
       "\t<dt>bmi</dt>\n",
       "\t\t<dd>0.49</dd>\n",
       "\t<dt>dpf</dt>\n",
       "\t\t<dd>0.4</dd>\n",
       "\t<dt>age</dt>\n",
       "\t\t<dd>0.35</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -1.02\n",
       "\\item[pregnancies] 0.27\n",
       "\\item[glucose] 1.19\n",
       "\\item[bloodpressure] -0.01\n",
       "\\item[skinthickness] 0.13\n",
       "\\item[insulin] -0.09\n",
       "\\item[bmi] 0.49\n",
       "\\item[dpf] 0.4\n",
       "\\item[age] 0.35\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -1.02pregnancies\n",
       ":   0.27glucose\n",
       ":   1.19bloodpressure\n",
       ":   -0.01skinthickness\n",
       ":   0.13insulin\n",
       ":   -0.09bmi\n",
       ":   0.49dpf\n",
       ":   0.4age\n",
       ":   0.35\n",
       "\n"
      ],
      "text/plain": [
       "  (Intercept)   pregnancies       glucose bloodpressure skinthickness \n",
       "        -1.02          0.27          1.19         -0.01          0.13 \n",
       "      insulin           bmi           dpf           age \n",
       "        -0.09          0.49          0.40          0.35 "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>2.5%</th><th scope=col>97.5%</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>-1.29</td><td>-0.75</td></tr>\n",
       "\t<tr><th scope=row>pregnancies</th><td>-0.07</td><td> 0.60</td></tr>\n",
       "\t<tr><th scope=row>glucose</th><td>0.87</td><td>1.54</td></tr>\n",
       "\t<tr><th scope=row>bloodpressure</th><td>-0.30</td><td> 0.28</td></tr>\n",
       "\t<tr><th scope=row>skinthickness</th><td>-0.21</td><td> 0.47</td></tr>\n",
       "\t<tr><th scope=row>insulin</th><td>-0.39</td><td> 0.22</td></tr>\n",
       "\t<tr><th scope=row>bmi</th><td>0.13</td><td>0.85</td></tr>\n",
       "\t<tr><th scope=row>dpf</th><td>0.12</td><td>0.69</td></tr>\n",
       "\t<tr><th scope=row>age</th><td>0.00</td><td>0.73</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5% & 97.5%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & -1.29 & -0.75\\\\\n",
       "\tpregnancies & -0.07 &  0.60\\\\\n",
       "\tglucose & 0.87 & 1.54\\\\\n",
       "\tbloodpressure & -0.30 &  0.28\\\\\n",
       "\tskinthickness & -0.21 &  0.47\\\\\n",
       "\tinsulin & -0.39 &  0.22\\\\\n",
       "\tbmi & 0.13 & 0.85\\\\\n",
       "\tdpf & 0.12 & 0.69\\\\\n",
       "\tage & 0.00 & 0.73\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -1.29\n",
       "2. -0.07\n",
       "3. 0.87\n",
       "4. -0.3\n",
       "5. -0.21\n",
       "6. -0.39\n",
       "7. 0.13\n",
       "8. 0.12\n",
       "9. 0\n",
       "10. -0.75\n",
       "11. 0.6\n",
       "12. 1.54\n",
       "13. 0.28\n",
       "14. 0.47\n",
       "15. 0.22\n",
       "16. 0.85\n",
       "17. 0.69\n",
       "18. 0.73\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "               2.5% 97.5%\n",
       "(Intercept)   -1.29 -0.75\n",
       "pregnancies   -0.07  0.60\n",
       "glucose        0.87  1.54\n",
       "bloodpressure -0.30  0.28\n",
       "skinthickness -0.21  0.47\n",
       "insulin       -0.39  0.22\n",
       "bmi            0.13  0.85\n",
       "dpf            0.12  0.69\n",
       "age            0.00  0.73"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(coef(post1), 2)\n",
    "round(posterior_interval(post1, prob = 0.95), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on `posterior_interval` and interpreting the parameter estimates from a Bayesian\n",
    "model see Step 2 in the [\"How to Use the __rstanarm__ Package\"][1] vignette.\n",
    "\n",
    "[1]: https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__rstanarm__ supports __loo__ package which implements fast [Pareto smoothed leave-one-out cross-validation (PSIS-LOO)][1] to compute expected log predictive density (elpd):\n",
    "\n",
    "[1]: https://arxiv.org/abs/1507.04544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": package ‘loo’ was built under R version 3.2.4This is loo version 0.1.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 4000 by 392 log-likelihood matrix\n",
       "\n",
       "         Estimate   SE\n",
       "elpd_loo   -181.6 11.9\n",
       "p_loo        10.2  1.3\n",
       "looic       363.2 23.7\n",
       "\n",
       "All Pareto k estimates OK (k < 0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(loo)\n",
    "(loo1 <- loo(post1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that PSIS-LOO result is reliable as all Pareto k estimates are small (k< 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more easily interpretable predictive performance measures, we next compute posterior predictive probabilities and use them to compute classification errors, ROC and AUC (some of these will be later included in loo package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicted probabilities\n",
    "linpred <- posterior_linpred(post1)\n",
    "preds <- posterior_linpred(post1, transform=TRUE)\n",
    "pred <- colMeans(preds)\n",
    "pr <- as.integer(pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": package ‘caret’ was built under R version 3.2.5"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for ‘caret’\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for ‘caret’\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): could not find function \"confusionMatrix\"\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): could not find function \"confusionMatrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.737"
      ],
      "text/latex": [
       "0.737"
      ],
      "text/markdown": [
       "0.737"
      ],
      "text/plain": [
       "[1] 0.737"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "0.66"
      ],
      "text/latex": [
       "0.66"
      ],
      "text/markdown": [
       "0.66"
      ],
      "text/plain": [
       "[1] 0.66"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot performance measures\n",
    "library(caret)\n",
    "\n",
    "# confusion matrix\n",
    "confusionMatrix(pr, y)[2:3]\n",
    "# posterior classification accuracy\n",
    "round(mean(xor(pr,as.integer(y))),3)\n",
    "# posterior balanced classification accuracy\n",
    "round((mean(xor(pr[y==0]>0.5,as.integer(y[y==0])))+mean(xor(pr[y==1]>0.5,as.integer(y[y==1]))))/2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive performance above is overoptimistic. To better estimate the predictive performance for new not yet seen data we next use leave-one-out cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PSIS-LOO weights\n",
    "log_lik=log_lik(post1, parameter_name = \"log_lik\")\n",
    "psis=psislw(-log_lik)\n",
    "#plot(psis$pareto_k)\n",
    "#plot(psis$lw_smooth[,1],linpred[,1])\n",
    "# LOO predictive probabilities\n",
    "ploo=colSums(preds*exp(psis$lw_smooth))\n",
    "# LOO classification accuracy\n",
    "round(mean(xor(ploo>0.5,as.integer(y))),3)\n",
    "# LOO balanced classification accuracy\n",
    "round((mean(xor(ploo[y==0]>0.5,as.integer(y[y==0])))+mean(xor(ploo[y==1]>0.5,as.integer(y[y==1]))))/2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it happens that all predicted classes are same as with posterior predictions. We can see the small difference in posterior predictive probabilities and LOO proabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(pred,ploo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also sompute ROC and AUC using posterior or LOO probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute AUCs\n",
    "library(pROC)\n",
    "plot.roc(y,pred,percent=TRUE,col=\"#1c61b6\",  print.auc=TRUE)\n",
    "plot.roc(y,ploo,percent=TRUE,col=\"#008600\",  print.auc=TRUE, print.auc.y=40, add=TRUE)\n",
    "\n",
    "legend(\"bottomright\", legend=c(\"Posterior ROC\", \"LOO ROC\"), col=c(\"#1c61b6\", \"#008600\"), lwd=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
